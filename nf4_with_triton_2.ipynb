{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryan8912/Unsolth.ai-challenage/blob/main/nf4_with_triton_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMf2KrDMtTMX",
        "outputId": "e65b8431-02cd-4852-ce27-aa2f1431c66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzOcxXtZoYp0",
        "outputId": "9a0463d8-f8e6-4278-eeb8-05823385c969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running NF4 dequantization benchmarks with BitsAndBytes config...\n",
            "\n",
            "Initializing dequantizers...\n",
            "\n",
            "Benchmarking NF4 Dequantization with BitsAndBytes config:\n",
            "============================================================\n",
            "Config: BitsAndBytesConfig {\n",
            "  \"_load_in_4bit\": true,\n",
            "  \"_load_in_8bit\": false,\n",
            "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "  \"bnb_4bit_quant_type\": \"nf4\",\n",
            "  \"bnb_4bit_use_double_quant\": true,\n",
            "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "  \"llm_int8_has_fp16_weight\": false,\n",
            "  \"llm_int8_skip_modules\": null,\n",
            "  \"llm_int8_threshold\": 6.0,\n",
            "  \"load_in_4bit\": true,\n",
            "  \"load_in_8bit\": false,\n",
            "  \"quant_method\": \"bitsandbytes\"\n",
            "}\n",
            "\n",
            "Using compilation: True\n",
            "------------------------------------------------------------\n",
            "       Shape |  Normal (ms) | Compiled (ms) |  Speedup\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py:1604: UserWarning: Tesla T4 does not support bfloat16 compilation natively, skipping\n",
            "  warnings.warn(\n",
            "W0223 05:56:12.076000 612 torch/_dynamo/convert_frame.py:844] [4/1050] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.076000 612 torch/_dynamo/convert_frame.py:844] [4/1050]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.076000 612 torch/_dynamo/convert_frame.py:844] [4/1050]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.076000 612 torch/_dynamo/convert_frame.py:844] [4/1050] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.076000 612 torch/_dynamo/convert_frame.py:844] [4/1050] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.082000 612 torch/_dynamo/convert_frame.py:844] [4/1051] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.082000 612 torch/_dynamo/convert_frame.py:844] [4/1051]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.082000 612 torch/_dynamo/convert_frame.py:844] [4/1051]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.082000 612 torch/_dynamo/convert_frame.py:844] [4/1051] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.082000 612 torch/_dynamo/convert_frame.py:844] [4/1051] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.085000 612 torch/_dynamo/convert_frame.py:844] [4/1052] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.085000 612 torch/_dynamo/convert_frame.py:844] [4/1052]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.085000 612 torch/_dynamo/convert_frame.py:844] [4/1052]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.085000 612 torch/_dynamo/convert_frame.py:844] [4/1052] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.085000 612 torch/_dynamo/convert_frame.py:844] [4/1052] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.090000 612 torch/_dynamo/convert_frame.py:844] [4/1053] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.090000 612 torch/_dynamo/convert_frame.py:844] [4/1053]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.090000 612 torch/_dynamo/convert_frame.py:844] [4/1053]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.090000 612 torch/_dynamo/convert_frame.py:844] [4/1053] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.090000 612 torch/_dynamo/convert_frame.py:844] [4/1053] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.096000 612 torch/_dynamo/convert_frame.py:844] [4/1054] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.096000 612 torch/_dynamo/convert_frame.py:844] [4/1054]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.096000 612 torch/_dynamo/convert_frame.py:844] [4/1054]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.096000 612 torch/_dynamo/convert_frame.py:844] [4/1054] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.096000 612 torch/_dynamo/convert_frame.py:844] [4/1054] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.101000 612 torch/_dynamo/convert_frame.py:844] [4/1055] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.101000 612 torch/_dynamo/convert_frame.py:844] [4/1055]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.101000 612 torch/_dynamo/convert_frame.py:844] [4/1055]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.101000 612 torch/_dynamo/convert_frame.py:844] [4/1055] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.101000 612 torch/_dynamo/convert_frame.py:844] [4/1055] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.105000 612 torch/_dynamo/convert_frame.py:844] [4/1056] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.105000 612 torch/_dynamo/convert_frame.py:844] [4/1056]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.105000 612 torch/_dynamo/convert_frame.py:844] [4/1056]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.105000 612 torch/_dynamo/convert_frame.py:844] [4/1056] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.105000 612 torch/_dynamo/convert_frame.py:844] [4/1056] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.108000 612 torch/_dynamo/convert_frame.py:844] [4/1057] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.108000 612 torch/_dynamo/convert_frame.py:844] [4/1057]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.108000 612 torch/_dynamo/convert_frame.py:844] [4/1057]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.108000 612 torch/_dynamo/convert_frame.py:844] [4/1057] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.108000 612 torch/_dynamo/convert_frame.py:844] [4/1057] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.111000 612 torch/_dynamo/convert_frame.py:844] [4/1058] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.111000 612 torch/_dynamo/convert_frame.py:844] [4/1058]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.111000 612 torch/_dynamo/convert_frame.py:844] [4/1058]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.111000 612 torch/_dynamo/convert_frame.py:844] [4/1058] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.111000 612 torch/_dynamo/convert_frame.py:844] [4/1058] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.116000 612 torch/_dynamo/convert_frame.py:844] [4/1059] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.116000 612 torch/_dynamo/convert_frame.py:844] [4/1059]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.116000 612 torch/_dynamo/convert_frame.py:844] [4/1059]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.116000 612 torch/_dynamo/convert_frame.py:844] [4/1059] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.116000 612 torch/_dynamo/convert_frame.py:844] [4/1059] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.123000 612 torch/_dynamo/convert_frame.py:844] [4/1060] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.123000 612 torch/_dynamo/convert_frame.py:844] [4/1060]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.123000 612 torch/_dynamo/convert_frame.py:844] [4/1060]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.123000 612 torch/_dynamo/convert_frame.py:844] [4/1060] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.123000 612 torch/_dynamo/convert_frame.py:844] [4/1060] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.128000 612 torch/_dynamo/convert_frame.py:844] [4/1061] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.128000 612 torch/_dynamo/convert_frame.py:844] [4/1061]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.128000 612 torch/_dynamo/convert_frame.py:844] [4/1061]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.128000 612 torch/_dynamo/convert_frame.py:844] [4/1061] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.128000 612 torch/_dynamo/convert_frame.py:844] [4/1061] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.134000 612 torch/_dynamo/convert_frame.py:844] [4/1062] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.134000 612 torch/_dynamo/convert_frame.py:844] [4/1062]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.134000 612 torch/_dynamo/convert_frame.py:844] [4/1062]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.134000 612 torch/_dynamo/convert_frame.py:844] [4/1062] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.134000 612 torch/_dynamo/convert_frame.py:844] [4/1062] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.139000 612 torch/_dynamo/convert_frame.py:844] [4/1063] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.139000 612 torch/_dynamo/convert_frame.py:844] [4/1063]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.139000 612 torch/_dynamo/convert_frame.py:844] [4/1063]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.139000 612 torch/_dynamo/convert_frame.py:844] [4/1063] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.139000 612 torch/_dynamo/convert_frame.py:844] [4/1063] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.144000 612 torch/_dynamo/convert_frame.py:844] [4/1064] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.144000 612 torch/_dynamo/convert_frame.py:844] [4/1064]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.144000 612 torch/_dynamo/convert_frame.py:844] [4/1064]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.144000 612 torch/_dynamo/convert_frame.py:844] [4/1064] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.144000 612 torch/_dynamo/convert_frame.py:844] [4/1064] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.149000 612 torch/_dynamo/convert_frame.py:844] [4/1065] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.149000 612 torch/_dynamo/convert_frame.py:844] [4/1065]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.149000 612 torch/_dynamo/convert_frame.py:844] [4/1065]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.149000 612 torch/_dynamo/convert_frame.py:844] [4/1065] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.149000 612 torch/_dynamo/convert_frame.py:844] [4/1065] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.153000 612 torch/_dynamo/convert_frame.py:844] [4/1066] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.153000 612 torch/_dynamo/convert_frame.py:844] [4/1066]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.153000 612 torch/_dynamo/convert_frame.py:844] [4/1066]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.153000 612 torch/_dynamo/convert_frame.py:844] [4/1066] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.153000 612 torch/_dynamo/convert_frame.py:844] [4/1066] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.158000 612 torch/_dynamo/convert_frame.py:844] [4/1067] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.158000 612 torch/_dynamo/convert_frame.py:844] [4/1067]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.158000 612 torch/_dynamo/convert_frame.py:844] [4/1067]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.158000 612 torch/_dynamo/convert_frame.py:844] [4/1067] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.158000 612 torch/_dynamo/convert_frame.py:844] [4/1067] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.163000 612 torch/_dynamo/convert_frame.py:844] [4/1068] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.163000 612 torch/_dynamo/convert_frame.py:844] [4/1068]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.163000 612 torch/_dynamo/convert_frame.py:844] [4/1068]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.163000 612 torch/_dynamo/convert_frame.py:844] [4/1068] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.163000 612 torch/_dynamo/convert_frame.py:844] [4/1068] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.168000 612 torch/_dynamo/convert_frame.py:844] [4/1069] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.168000 612 torch/_dynamo/convert_frame.py:844] [4/1069]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.168000 612 torch/_dynamo/convert_frame.py:844] [4/1069]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.168000 612 torch/_dynamo/convert_frame.py:844] [4/1069] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.168000 612 torch/_dynamo/convert_frame.py:844] [4/1069] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.172000 612 torch/_dynamo/convert_frame.py:844] [4/1070] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.172000 612 torch/_dynamo/convert_frame.py:844] [4/1070]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.172000 612 torch/_dynamo/convert_frame.py:844] [4/1070]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.172000 612 torch/_dynamo/convert_frame.py:844] [4/1070] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.172000 612 torch/_dynamo/convert_frame.py:844] [4/1070] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.177000 612 torch/_dynamo/convert_frame.py:844] [4/1071] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.177000 612 torch/_dynamo/convert_frame.py:844] [4/1071]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.177000 612 torch/_dynamo/convert_frame.py:844] [4/1071]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.177000 612 torch/_dynamo/convert_frame.py:844] [4/1071] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.177000 612 torch/_dynamo/convert_frame.py:844] [4/1071] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.182000 612 torch/_dynamo/convert_frame.py:844] [4/1072] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.182000 612 torch/_dynamo/convert_frame.py:844] [4/1072]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.182000 612 torch/_dynamo/convert_frame.py:844] [4/1072]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.182000 612 torch/_dynamo/convert_frame.py:844] [4/1072] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.182000 612 torch/_dynamo/convert_frame.py:844] [4/1072] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.187000 612 torch/_dynamo/convert_frame.py:844] [4/1073] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.187000 612 torch/_dynamo/convert_frame.py:844] [4/1073]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.187000 612 torch/_dynamo/convert_frame.py:844] [4/1073]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.187000 612 torch/_dynamo/convert_frame.py:844] [4/1073] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.187000 612 torch/_dynamo/convert_frame.py:844] [4/1073] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.193000 612 torch/_dynamo/convert_frame.py:844] [4/1074] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.193000 612 torch/_dynamo/convert_frame.py:844] [4/1074]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.193000 612 torch/_dynamo/convert_frame.py:844] [4/1074]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.193000 612 torch/_dynamo/convert_frame.py:844] [4/1074] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.193000 612 torch/_dynamo/convert_frame.py:844] [4/1074] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.201000 612 torch/_dynamo/convert_frame.py:844] [4/1075] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.201000 612 torch/_dynamo/convert_frame.py:844] [4/1075]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.201000 612 torch/_dynamo/convert_frame.py:844] [4/1075]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.201000 612 torch/_dynamo/convert_frame.py:844] [4/1075] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.201000 612 torch/_dynamo/convert_frame.py:844] [4/1075] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.207000 612 torch/_dynamo/convert_frame.py:844] [4/1076] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.207000 612 torch/_dynamo/convert_frame.py:844] [4/1076]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.207000 612 torch/_dynamo/convert_frame.py:844] [4/1076]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.207000 612 torch/_dynamo/convert_frame.py:844] [4/1076] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.207000 612 torch/_dynamo/convert_frame.py:844] [4/1076] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.212000 612 torch/_dynamo/convert_frame.py:844] [4/1077] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.212000 612 torch/_dynamo/convert_frame.py:844] [4/1077]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.212000 612 torch/_dynamo/convert_frame.py:844] [4/1077]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.212000 612 torch/_dynamo/convert_frame.py:844] [4/1077] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.212000 612 torch/_dynamo/convert_frame.py:844] [4/1077] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.216000 612 torch/_dynamo/convert_frame.py:844] [4/1078] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.216000 612 torch/_dynamo/convert_frame.py:844] [4/1078]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.216000 612 torch/_dynamo/convert_frame.py:844] [4/1078]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.216000 612 torch/_dynamo/convert_frame.py:844] [4/1078] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.216000 612 torch/_dynamo/convert_frame.py:844] [4/1078] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.221000 612 torch/_dynamo/convert_frame.py:844] [4/1079] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.221000 612 torch/_dynamo/convert_frame.py:844] [4/1079]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.221000 612 torch/_dynamo/convert_frame.py:844] [4/1079]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.221000 612 torch/_dynamo/convert_frame.py:844] [4/1079] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.221000 612 torch/_dynamo/convert_frame.py:844] [4/1079] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.225000 612 torch/_dynamo/convert_frame.py:844] [4/1080] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.225000 612 torch/_dynamo/convert_frame.py:844] [4/1080]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.225000 612 torch/_dynamo/convert_frame.py:844] [4/1080]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.225000 612 torch/_dynamo/convert_frame.py:844] [4/1080] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.225000 612 torch/_dynamo/convert_frame.py:844] [4/1080] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.230000 612 torch/_dynamo/convert_frame.py:844] [4/1081] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.230000 612 torch/_dynamo/convert_frame.py:844] [4/1081]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.230000 612 torch/_dynamo/convert_frame.py:844] [4/1081]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.230000 612 torch/_dynamo/convert_frame.py:844] [4/1081] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.230000 612 torch/_dynamo/convert_frame.py:844] [4/1081] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.234000 612 torch/_dynamo/convert_frame.py:844] [4/1082] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.234000 612 torch/_dynamo/convert_frame.py:844] [4/1082]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.234000 612 torch/_dynamo/convert_frame.py:844] [4/1082]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.234000 612 torch/_dynamo/convert_frame.py:844] [4/1082] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.234000 612 torch/_dynamo/convert_frame.py:844] [4/1082] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.239000 612 torch/_dynamo/convert_frame.py:844] [4/1083] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.239000 612 torch/_dynamo/convert_frame.py:844] [4/1083]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.239000 612 torch/_dynamo/convert_frame.py:844] [4/1083]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.239000 612 torch/_dynamo/convert_frame.py:844] [4/1083] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.239000 612 torch/_dynamo/convert_frame.py:844] [4/1083] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.243000 612 torch/_dynamo/convert_frame.py:844] [4/1084] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.243000 612 torch/_dynamo/convert_frame.py:844] [4/1084]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.243000 612 torch/_dynamo/convert_frame.py:844] [4/1084]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.243000 612 torch/_dynamo/convert_frame.py:844] [4/1084] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.243000 612 torch/_dynamo/convert_frame.py:844] [4/1084] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.249000 612 torch/_dynamo/convert_frame.py:844] [4/1085] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.249000 612 torch/_dynamo/convert_frame.py:844] [4/1085]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.249000 612 torch/_dynamo/convert_frame.py:844] [4/1085]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.249000 612 torch/_dynamo/convert_frame.py:844] [4/1085] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.249000 612 torch/_dynamo/convert_frame.py:844] [4/1085] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.253000 612 torch/_dynamo/convert_frame.py:844] [4/1086] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.253000 612 torch/_dynamo/convert_frame.py:844] [4/1086]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.253000 612 torch/_dynamo/convert_frame.py:844] [4/1086]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.253000 612 torch/_dynamo/convert_frame.py:844] [4/1086] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.253000 612 torch/_dynamo/convert_frame.py:844] [4/1086] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.258000 612 torch/_dynamo/convert_frame.py:844] [4/1087] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.258000 612 torch/_dynamo/convert_frame.py:844] [4/1087]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.258000 612 torch/_dynamo/convert_frame.py:844] [4/1087]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.258000 612 torch/_dynamo/convert_frame.py:844] [4/1087] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.258000 612 torch/_dynamo/convert_frame.py:844] [4/1087] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.262000 612 torch/_dynamo/convert_frame.py:844] [4/1088] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.262000 612 torch/_dynamo/convert_frame.py:844] [4/1088]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.262000 612 torch/_dynamo/convert_frame.py:844] [4/1088]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.262000 612 torch/_dynamo/convert_frame.py:844] [4/1088] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.262000 612 torch/_dynamo/convert_frame.py:844] [4/1088] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.267000 612 torch/_dynamo/convert_frame.py:844] [4/1089] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.267000 612 torch/_dynamo/convert_frame.py:844] [4/1089]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.267000 612 torch/_dynamo/convert_frame.py:844] [4/1089]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.267000 612 torch/_dynamo/convert_frame.py:844] [4/1089] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.267000 612 torch/_dynamo/convert_frame.py:844] [4/1089] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.273000 612 torch/_dynamo/convert_frame.py:844] [4/1090] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.273000 612 torch/_dynamo/convert_frame.py:844] [4/1090]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.273000 612 torch/_dynamo/convert_frame.py:844] [4/1090]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.273000 612 torch/_dynamo/convert_frame.py:844] [4/1090] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.273000 612 torch/_dynamo/convert_frame.py:844] [4/1090] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.290000 612 torch/_dynamo/convert_frame.py:844] [4/1091] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.290000 612 torch/_dynamo/convert_frame.py:844] [4/1091]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.290000 612 torch/_dynamo/convert_frame.py:844] [4/1091]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.290000 612 torch/_dynamo/convert_frame.py:844] [4/1091] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.290000 612 torch/_dynamo/convert_frame.py:844] [4/1091] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.301000 612 torch/_dynamo/convert_frame.py:844] [4/1092] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.301000 612 torch/_dynamo/convert_frame.py:844] [4/1092]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.301000 612 torch/_dynamo/convert_frame.py:844] [4/1092]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.301000 612 torch/_dynamo/convert_frame.py:844] [4/1092] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.301000 612 torch/_dynamo/convert_frame.py:844] [4/1092] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.305000 612 torch/_dynamo/convert_frame.py:844] [4/1093] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.305000 612 torch/_dynamo/convert_frame.py:844] [4/1093]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.305000 612 torch/_dynamo/convert_frame.py:844] [4/1093]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.305000 612 torch/_dynamo/convert_frame.py:844] [4/1093] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.305000 612 torch/_dynamo/convert_frame.py:844] [4/1093] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.312000 612 torch/_dynamo/convert_frame.py:844] [4/1094] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.312000 612 torch/_dynamo/convert_frame.py:844] [4/1094]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.312000 612 torch/_dynamo/convert_frame.py:844] [4/1094]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.312000 612 torch/_dynamo/convert_frame.py:844] [4/1094] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.312000 612 torch/_dynamo/convert_frame.py:844] [4/1094] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.319000 612 torch/_dynamo/convert_frame.py:844] [4/1095] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.319000 612 torch/_dynamo/convert_frame.py:844] [4/1095]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.319000 612 torch/_dynamo/convert_frame.py:844] [4/1095]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.319000 612 torch/_dynamo/convert_frame.py:844] [4/1095] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.319000 612 torch/_dynamo/convert_frame.py:844] [4/1095] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.326000 612 torch/_dynamo/convert_frame.py:844] [4/1096] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.326000 612 torch/_dynamo/convert_frame.py:844] [4/1096]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.326000 612 torch/_dynamo/convert_frame.py:844] [4/1096]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.326000 612 torch/_dynamo/convert_frame.py:844] [4/1096] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.326000 612 torch/_dynamo/convert_frame.py:844] [4/1096] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.330000 612 torch/_dynamo/convert_frame.py:844] [4/1097] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.330000 612 torch/_dynamo/convert_frame.py:844] [4/1097]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.330000 612 torch/_dynamo/convert_frame.py:844] [4/1097]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.330000 612 torch/_dynamo/convert_frame.py:844] [4/1097] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.330000 612 torch/_dynamo/convert_frame.py:844] [4/1097] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.339000 612 torch/_dynamo/convert_frame.py:844] [4/1098] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.339000 612 torch/_dynamo/convert_frame.py:844] [4/1098]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.339000 612 torch/_dynamo/convert_frame.py:844] [4/1098]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.339000 612 torch/_dynamo/convert_frame.py:844] [4/1098] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.339000 612 torch/_dynamo/convert_frame.py:844] [4/1098] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.357000 612 torch/_dynamo/convert_frame.py:844] [4/1099] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.357000 612 torch/_dynamo/convert_frame.py:844] [4/1099]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.357000 612 torch/_dynamo/convert_frame.py:844] [4/1099]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.357000 612 torch/_dynamo/convert_frame.py:844] [4/1099] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.357000 612 torch/_dynamo/convert_frame.py:844] [4/1099] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.362000 612 torch/_dynamo/convert_frame.py:844] [4/1100] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.362000 612 torch/_dynamo/convert_frame.py:844] [4/1100]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.362000 612 torch/_dynamo/convert_frame.py:844] [4/1100]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.362000 612 torch/_dynamo/convert_frame.py:844] [4/1100] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.362000 612 torch/_dynamo/convert_frame.py:844] [4/1100] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.371000 612 torch/_dynamo/convert_frame.py:844] [4/1101] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.371000 612 torch/_dynamo/convert_frame.py:844] [4/1101]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.371000 612 torch/_dynamo/convert_frame.py:844] [4/1101]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.371000 612 torch/_dynamo/convert_frame.py:844] [4/1101] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.371000 612 torch/_dynamo/convert_frame.py:844] [4/1101] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.376000 612 torch/_dynamo/convert_frame.py:844] [4/1102] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.376000 612 torch/_dynamo/convert_frame.py:844] [4/1102]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.376000 612 torch/_dynamo/convert_frame.py:844] [4/1102]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.376000 612 torch/_dynamo/convert_frame.py:844] [4/1102] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.376000 612 torch/_dynamo/convert_frame.py:844] [4/1102] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.381000 612 torch/_dynamo/convert_frame.py:844] [4/1103] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.381000 612 torch/_dynamo/convert_frame.py:844] [4/1103]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.381000 612 torch/_dynamo/convert_frame.py:844] [4/1103]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.381000 612 torch/_dynamo/convert_frame.py:844] [4/1103] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.381000 612 torch/_dynamo/convert_frame.py:844] [4/1103] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.385000 612 torch/_dynamo/convert_frame.py:844] [4/1104] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.385000 612 torch/_dynamo/convert_frame.py:844] [4/1104]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.385000 612 torch/_dynamo/convert_frame.py:844] [4/1104]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.385000 612 torch/_dynamo/convert_frame.py:844] [4/1104] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.385000 612 torch/_dynamo/convert_frame.py:844] [4/1104] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.389000 612 torch/_dynamo/convert_frame.py:844] [4/1105] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.389000 612 torch/_dynamo/convert_frame.py:844] [4/1105]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.389000 612 torch/_dynamo/convert_frame.py:844] [4/1105]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.389000 612 torch/_dynamo/convert_frame.py:844] [4/1105] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.389000 612 torch/_dynamo/convert_frame.py:844] [4/1105] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.395000 612 torch/_dynamo/convert_frame.py:844] [4/1106] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.395000 612 torch/_dynamo/convert_frame.py:844] [4/1106]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.395000 612 torch/_dynamo/convert_frame.py:844] [4/1106]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.395000 612 torch/_dynamo/convert_frame.py:844] [4/1106] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.395000 612 torch/_dynamo/convert_frame.py:844] [4/1106] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.412000 612 torch/_dynamo/convert_frame.py:844] [4/1107] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.412000 612 torch/_dynamo/convert_frame.py:844] [4/1107]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.412000 612 torch/_dynamo/convert_frame.py:844] [4/1107]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.412000 612 torch/_dynamo/convert_frame.py:844] [4/1107] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.412000 612 torch/_dynamo/convert_frame.py:844] [4/1107] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.418000 612 torch/_dynamo/convert_frame.py:844] [4/1108] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.418000 612 torch/_dynamo/convert_frame.py:844] [4/1108]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.418000 612 torch/_dynamo/convert_frame.py:844] [4/1108]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.418000 612 torch/_dynamo/convert_frame.py:844] [4/1108] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.418000 612 torch/_dynamo/convert_frame.py:844] [4/1108] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.430000 612 torch/_dynamo/convert_frame.py:844] [4/1109] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.430000 612 torch/_dynamo/convert_frame.py:844] [4/1109]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.430000 612 torch/_dynamo/convert_frame.py:844] [4/1109]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.430000 612 torch/_dynamo/convert_frame.py:844] [4/1109] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.430000 612 torch/_dynamo/convert_frame.py:844] [4/1109] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.434000 612 torch/_dynamo/convert_frame.py:844] [4/1110] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.434000 612 torch/_dynamo/convert_frame.py:844] [4/1110]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.434000 612 torch/_dynamo/convert_frame.py:844] [4/1110]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.434000 612 torch/_dynamo/convert_frame.py:844] [4/1110] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.434000 612 torch/_dynamo/convert_frame.py:844] [4/1110] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.451000 612 torch/_dynamo/convert_frame.py:844] [4/1111] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.451000 612 torch/_dynamo/convert_frame.py:844] [4/1111]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.451000 612 torch/_dynamo/convert_frame.py:844] [4/1111]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.451000 612 torch/_dynamo/convert_frame.py:844] [4/1111] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.451000 612 torch/_dynamo/convert_frame.py:844] [4/1111] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.454000 612 torch/_dynamo/convert_frame.py:844] [4/1112] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.454000 612 torch/_dynamo/convert_frame.py:844] [4/1112]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.454000 612 torch/_dynamo/convert_frame.py:844] [4/1112]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.454000 612 torch/_dynamo/convert_frame.py:844] [4/1112] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.454000 612 torch/_dynamo/convert_frame.py:844] [4/1112] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.468000 612 torch/_dynamo/convert_frame.py:844] [4/1113] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.468000 612 torch/_dynamo/convert_frame.py:844] [4/1113]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.468000 612 torch/_dynamo/convert_frame.py:844] [4/1113]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.468000 612 torch/_dynamo/convert_frame.py:844] [4/1113] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.468000 612 torch/_dynamo/convert_frame.py:844] [4/1113] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.480000 612 torch/_dynamo/convert_frame.py:844] [4/1114] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.480000 612 torch/_dynamo/convert_frame.py:844] [4/1114]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.480000 612 torch/_dynamo/convert_frame.py:844] [4/1114]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.480000 612 torch/_dynamo/convert_frame.py:844] [4/1114] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.480000 612 torch/_dynamo/convert_frame.py:844] [4/1114] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.491000 612 torch/_dynamo/convert_frame.py:844] [4/1115] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.491000 612 torch/_dynamo/convert_frame.py:844] [4/1115]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.491000 612 torch/_dynamo/convert_frame.py:844] [4/1115]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.491000 612 torch/_dynamo/convert_frame.py:844] [4/1115] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.491000 612 torch/_dynamo/convert_frame.py:844] [4/1115] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.512000 612 torch/_dynamo/convert_frame.py:844] [4/1116] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.512000 612 torch/_dynamo/convert_frame.py:844] [4/1116]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.512000 612 torch/_dynamo/convert_frame.py:844] [4/1116]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.512000 612 torch/_dynamo/convert_frame.py:844] [4/1116] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.512000 612 torch/_dynamo/convert_frame.py:844] [4/1116] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.518000 612 torch/_dynamo/convert_frame.py:844] [4/1117] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.518000 612 torch/_dynamo/convert_frame.py:844] [4/1117]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.518000 612 torch/_dynamo/convert_frame.py:844] [4/1117]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.518000 612 torch/_dynamo/convert_frame.py:844] [4/1117] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.518000 612 torch/_dynamo/convert_frame.py:844] [4/1117] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.527000 612 torch/_dynamo/convert_frame.py:844] [4/1118] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.527000 612 torch/_dynamo/convert_frame.py:844] [4/1118]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.527000 612 torch/_dynamo/convert_frame.py:844] [4/1118]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.527000 612 torch/_dynamo/convert_frame.py:844] [4/1118] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.527000 612 torch/_dynamo/convert_frame.py:844] [4/1118] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.540000 612 torch/_dynamo/convert_frame.py:844] [4/1119] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.540000 612 torch/_dynamo/convert_frame.py:844] [4/1119]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.540000 612 torch/_dynamo/convert_frame.py:844] [4/1119]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.540000 612 torch/_dynamo/convert_frame.py:844] [4/1119] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.540000 612 torch/_dynamo/convert_frame.py:844] [4/1119] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.545000 612 torch/_dynamo/convert_frame.py:844] [4/1120] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.545000 612 torch/_dynamo/convert_frame.py:844] [4/1120]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.545000 612 torch/_dynamo/convert_frame.py:844] [4/1120]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.545000 612 torch/_dynamo/convert_frame.py:844] [4/1120] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.545000 612 torch/_dynamo/convert_frame.py:844] [4/1120] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.556000 612 torch/_dynamo/convert_frame.py:844] [4/1121] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.556000 612 torch/_dynamo/convert_frame.py:844] [4/1121]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.556000 612 torch/_dynamo/convert_frame.py:844] [4/1121]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.556000 612 torch/_dynamo/convert_frame.py:844] [4/1121] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.556000 612 torch/_dynamo/convert_frame.py:844] [4/1121] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.568000 612 torch/_dynamo/convert_frame.py:844] [4/1122] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.568000 612 torch/_dynamo/convert_frame.py:844] [4/1122]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.568000 612 torch/_dynamo/convert_frame.py:844] [4/1122]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.568000 612 torch/_dynamo/convert_frame.py:844] [4/1122] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.568000 612 torch/_dynamo/convert_frame.py:844] [4/1122] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.577000 612 torch/_dynamo/convert_frame.py:844] [4/1123] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.577000 612 torch/_dynamo/convert_frame.py:844] [4/1123]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.577000 612 torch/_dynamo/convert_frame.py:844] [4/1123]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.577000 612 torch/_dynamo/convert_frame.py:844] [4/1123] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.577000 612 torch/_dynamo/convert_frame.py:844] [4/1123] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.583000 612 torch/_dynamo/convert_frame.py:844] [4/1124] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.583000 612 torch/_dynamo/convert_frame.py:844] [4/1124]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.583000 612 torch/_dynamo/convert_frame.py:844] [4/1124]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.583000 612 torch/_dynamo/convert_frame.py:844] [4/1124] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.583000 612 torch/_dynamo/convert_frame.py:844] [4/1124] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.591000 612 torch/_dynamo/convert_frame.py:844] [4/1125] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.591000 612 torch/_dynamo/convert_frame.py:844] [4/1125]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.591000 612 torch/_dynamo/convert_frame.py:844] [4/1125]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.591000 612 torch/_dynamo/convert_frame.py:844] [4/1125] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.591000 612 torch/_dynamo/convert_frame.py:844] [4/1125] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.594000 612 torch/_dynamo/convert_frame.py:844] [4/1126] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.594000 612 torch/_dynamo/convert_frame.py:844] [4/1126]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.594000 612 torch/_dynamo/convert_frame.py:844] [4/1126]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.594000 612 torch/_dynamo/convert_frame.py:844] [4/1126] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.594000 612 torch/_dynamo/convert_frame.py:844] [4/1126] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.597000 612 torch/_dynamo/convert_frame.py:844] [4/1127] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.597000 612 torch/_dynamo/convert_frame.py:844] [4/1127]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.597000 612 torch/_dynamo/convert_frame.py:844] [4/1127]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.597000 612 torch/_dynamo/convert_frame.py:844] [4/1127] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.597000 612 torch/_dynamo/convert_frame.py:844] [4/1127] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.600000 612 torch/_dynamo/convert_frame.py:844] [4/1128] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.600000 612 torch/_dynamo/convert_frame.py:844] [4/1128]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.600000 612 torch/_dynamo/convert_frame.py:844] [4/1128]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.600000 612 torch/_dynamo/convert_frame.py:844] [4/1128] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.600000 612 torch/_dynamo/convert_frame.py:844] [4/1128] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.603000 612 torch/_dynamo/convert_frame.py:844] [4/1129] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.603000 612 torch/_dynamo/convert_frame.py:844] [4/1129]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.603000 612 torch/_dynamo/convert_frame.py:844] [4/1129]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.603000 612 torch/_dynamo/convert_frame.py:844] [4/1129] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.603000 612 torch/_dynamo/convert_frame.py:844] [4/1129] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.606000 612 torch/_dynamo/convert_frame.py:844] [4/1130] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.606000 612 torch/_dynamo/convert_frame.py:844] [4/1130]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.606000 612 torch/_dynamo/convert_frame.py:844] [4/1130]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.606000 612 torch/_dynamo/convert_frame.py:844] [4/1130] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.606000 612 torch/_dynamo/convert_frame.py:844] [4/1130] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.609000 612 torch/_dynamo/convert_frame.py:844] [4/1131] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.609000 612 torch/_dynamo/convert_frame.py:844] [4/1131]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.609000 612 torch/_dynamo/convert_frame.py:844] [4/1131]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.609000 612 torch/_dynamo/convert_frame.py:844] [4/1131] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.609000 612 torch/_dynamo/convert_frame.py:844] [4/1131] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.612000 612 torch/_dynamo/convert_frame.py:844] [4/1132] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.612000 612 torch/_dynamo/convert_frame.py:844] [4/1132]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.612000 612 torch/_dynamo/convert_frame.py:844] [4/1132]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.612000 612 torch/_dynamo/convert_frame.py:844] [4/1132] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.612000 612 torch/_dynamo/convert_frame.py:844] [4/1132] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.615000 612 torch/_dynamo/convert_frame.py:844] [4/1133] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.615000 612 torch/_dynamo/convert_frame.py:844] [4/1133]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.615000 612 torch/_dynamo/convert_frame.py:844] [4/1133]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.615000 612 torch/_dynamo/convert_frame.py:844] [4/1133] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.615000 612 torch/_dynamo/convert_frame.py:844] [4/1133] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.617000 612 torch/_dynamo/convert_frame.py:844] [4/1134] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.617000 612 torch/_dynamo/convert_frame.py:844] [4/1134]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.617000 612 torch/_dynamo/convert_frame.py:844] [4/1134]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.617000 612 torch/_dynamo/convert_frame.py:844] [4/1134] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.617000 612 torch/_dynamo/convert_frame.py:844] [4/1134] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.620000 612 torch/_dynamo/convert_frame.py:844] [4/1135] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.620000 612 torch/_dynamo/convert_frame.py:844] [4/1135]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.620000 612 torch/_dynamo/convert_frame.py:844] [4/1135]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.620000 612 torch/_dynamo/convert_frame.py:844] [4/1135] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.620000 612 torch/_dynamo/convert_frame.py:844] [4/1135] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.623000 612 torch/_dynamo/convert_frame.py:844] [4/1136] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.623000 612 torch/_dynamo/convert_frame.py:844] [4/1136]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.623000 612 torch/_dynamo/convert_frame.py:844] [4/1136]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.623000 612 torch/_dynamo/convert_frame.py:844] [4/1136] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.623000 612 torch/_dynamo/convert_frame.py:844] [4/1136] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.627000 612 torch/_dynamo/convert_frame.py:844] [4/1137] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.627000 612 torch/_dynamo/convert_frame.py:844] [4/1137]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.627000 612 torch/_dynamo/convert_frame.py:844] [4/1137]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.627000 612 torch/_dynamo/convert_frame.py:844] [4/1137] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.627000 612 torch/_dynamo/convert_frame.py:844] [4/1137] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.629000 612 torch/_dynamo/convert_frame.py:844] [4/1138] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.629000 612 torch/_dynamo/convert_frame.py:844] [4/1138]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.629000 612 torch/_dynamo/convert_frame.py:844] [4/1138]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.629000 612 torch/_dynamo/convert_frame.py:844] [4/1138] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.629000 612 torch/_dynamo/convert_frame.py:844] [4/1138] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.632000 612 torch/_dynamo/convert_frame.py:844] [4/1139] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.632000 612 torch/_dynamo/convert_frame.py:844] [4/1139]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.632000 612 torch/_dynamo/convert_frame.py:844] [4/1139]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.632000 612 torch/_dynamo/convert_frame.py:844] [4/1139] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.632000 612 torch/_dynamo/convert_frame.py:844] [4/1139] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.636000 612 torch/_dynamo/convert_frame.py:844] [4/1140] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.636000 612 torch/_dynamo/convert_frame.py:844] [4/1140]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.636000 612 torch/_dynamo/convert_frame.py:844] [4/1140]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.636000 612 torch/_dynamo/convert_frame.py:844] [4/1140] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.636000 612 torch/_dynamo/convert_frame.py:844] [4/1140] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.639000 612 torch/_dynamo/convert_frame.py:844] [4/1141] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.639000 612 torch/_dynamo/convert_frame.py:844] [4/1141]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.639000 612 torch/_dynamo/convert_frame.py:844] [4/1141]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.639000 612 torch/_dynamo/convert_frame.py:844] [4/1141] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.639000 612 torch/_dynamo/convert_frame.py:844] [4/1141] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.642000 612 torch/_dynamo/convert_frame.py:844] [4/1142] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.642000 612 torch/_dynamo/convert_frame.py:844] [4/1142]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.642000 612 torch/_dynamo/convert_frame.py:844] [4/1142]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.642000 612 torch/_dynamo/convert_frame.py:844] [4/1142] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.642000 612 torch/_dynamo/convert_frame.py:844] [4/1142] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.644000 612 torch/_dynamo/convert_frame.py:844] [4/1143] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.644000 612 torch/_dynamo/convert_frame.py:844] [4/1143]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.644000 612 torch/_dynamo/convert_frame.py:844] [4/1143]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.644000 612 torch/_dynamo/convert_frame.py:844] [4/1143] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.644000 612 torch/_dynamo/convert_frame.py:844] [4/1143] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.647000 612 torch/_dynamo/convert_frame.py:844] [4/1144] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.647000 612 torch/_dynamo/convert_frame.py:844] [4/1144]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.647000 612 torch/_dynamo/convert_frame.py:844] [4/1144]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.647000 612 torch/_dynamo/convert_frame.py:844] [4/1144] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.647000 612 torch/_dynamo/convert_frame.py:844] [4/1144] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.660000 612 torch/_dynamo/convert_frame.py:844] [4/1145] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.660000 612 torch/_dynamo/convert_frame.py:844] [4/1145]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.660000 612 torch/_dynamo/convert_frame.py:844] [4/1145]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.660000 612 torch/_dynamo/convert_frame.py:844] [4/1145] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.660000 612 torch/_dynamo/convert_frame.py:844] [4/1145] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.664000 612 torch/_dynamo/convert_frame.py:844] [4/1146] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.664000 612 torch/_dynamo/convert_frame.py:844] [4/1146]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.664000 612 torch/_dynamo/convert_frame.py:844] [4/1146]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.664000 612 torch/_dynamo/convert_frame.py:844] [4/1146] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.664000 612 torch/_dynamo/convert_frame.py:844] [4/1146] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.669000 612 torch/_dynamo/convert_frame.py:844] [4/1147] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.669000 612 torch/_dynamo/convert_frame.py:844] [4/1147]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.669000 612 torch/_dynamo/convert_frame.py:844] [4/1147]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.669000 612 torch/_dynamo/convert_frame.py:844] [4/1147] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.669000 612 torch/_dynamo/convert_frame.py:844] [4/1147] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.674000 612 torch/_dynamo/convert_frame.py:844] [4/1148] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.674000 612 torch/_dynamo/convert_frame.py:844] [4/1148]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.674000 612 torch/_dynamo/convert_frame.py:844] [4/1148]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.674000 612 torch/_dynamo/convert_frame.py:844] [4/1148] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.674000 612 torch/_dynamo/convert_frame.py:844] [4/1148] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.679000 612 torch/_dynamo/convert_frame.py:844] [4/1149] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.679000 612 torch/_dynamo/convert_frame.py:844] [4/1149]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.679000 612 torch/_dynamo/convert_frame.py:844] [4/1149]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.679000 612 torch/_dynamo/convert_frame.py:844] [4/1149] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.679000 612 torch/_dynamo/convert_frame.py:844] [4/1149] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.682000 612 torch/_dynamo/convert_frame.py:844] [4/1150] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.682000 612 torch/_dynamo/convert_frame.py:844] [4/1150]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.682000 612 torch/_dynamo/convert_frame.py:844] [4/1150]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.682000 612 torch/_dynamo/convert_frame.py:844] [4/1150] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.682000 612 torch/_dynamo/convert_frame.py:844] [4/1150] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.688000 612 torch/_dynamo/convert_frame.py:844] [4/1151] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.688000 612 torch/_dynamo/convert_frame.py:844] [4/1151]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.688000 612 torch/_dynamo/convert_frame.py:844] [4/1151]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.688000 612 torch/_dynamo/convert_frame.py:844] [4/1151] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.688000 612 torch/_dynamo/convert_frame.py:844] [4/1151] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.691000 612 torch/_dynamo/convert_frame.py:844] [4/1152] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.691000 612 torch/_dynamo/convert_frame.py:844] [4/1152]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.691000 612 torch/_dynamo/convert_frame.py:844] [4/1152]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.691000 612 torch/_dynamo/convert_frame.py:844] [4/1152] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.691000 612 torch/_dynamo/convert_frame.py:844] [4/1152] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.693000 612 torch/_dynamo/convert_frame.py:844] [4/1153] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.693000 612 torch/_dynamo/convert_frame.py:844] [4/1153]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.693000 612 torch/_dynamo/convert_frame.py:844] [4/1153]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.693000 612 torch/_dynamo/convert_frame.py:844] [4/1153] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.693000 612 torch/_dynamo/convert_frame.py:844] [4/1153] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.696000 612 torch/_dynamo/convert_frame.py:844] [4/1154] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.696000 612 torch/_dynamo/convert_frame.py:844] [4/1154]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.696000 612 torch/_dynamo/convert_frame.py:844] [4/1154]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.696000 612 torch/_dynamo/convert_frame.py:844] [4/1154] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.696000 612 torch/_dynamo/convert_frame.py:844] [4/1154] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.699000 612 torch/_dynamo/convert_frame.py:844] [4/1155] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.699000 612 torch/_dynamo/convert_frame.py:844] [4/1155]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.699000 612 torch/_dynamo/convert_frame.py:844] [4/1155]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.699000 612 torch/_dynamo/convert_frame.py:844] [4/1155] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.699000 612 torch/_dynamo/convert_frame.py:844] [4/1155] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.702000 612 torch/_dynamo/convert_frame.py:844] [4/1156] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.702000 612 torch/_dynamo/convert_frame.py:844] [4/1156]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.702000 612 torch/_dynamo/convert_frame.py:844] [4/1156]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.702000 612 torch/_dynamo/convert_frame.py:844] [4/1156] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.702000 612 torch/_dynamo/convert_frame.py:844] [4/1156] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.706000 612 torch/_dynamo/convert_frame.py:844] [4/1157] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.706000 612 torch/_dynamo/convert_frame.py:844] [4/1157]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.706000 612 torch/_dynamo/convert_frame.py:844] [4/1157]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.706000 612 torch/_dynamo/convert_frame.py:844] [4/1157] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.706000 612 torch/_dynamo/convert_frame.py:844] [4/1157] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.709000 612 torch/_dynamo/convert_frame.py:844] [4/1158] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.709000 612 torch/_dynamo/convert_frame.py:844] [4/1158]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.709000 612 torch/_dynamo/convert_frame.py:844] [4/1158]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.709000 612 torch/_dynamo/convert_frame.py:844] [4/1158] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.709000 612 torch/_dynamo/convert_frame.py:844] [4/1158] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.715000 612 torch/_dynamo/convert_frame.py:844] [4/1159] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.715000 612 torch/_dynamo/convert_frame.py:844] [4/1159]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.715000 612 torch/_dynamo/convert_frame.py:844] [4/1159]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.715000 612 torch/_dynamo/convert_frame.py:844] [4/1159] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.715000 612 torch/_dynamo/convert_frame.py:844] [4/1159] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.720000 612 torch/_dynamo/convert_frame.py:844] [4/1160] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.720000 612 torch/_dynamo/convert_frame.py:844] [4/1160]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.720000 612 torch/_dynamo/convert_frame.py:844] [4/1160]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.720000 612 torch/_dynamo/convert_frame.py:844] [4/1160] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.720000 612 torch/_dynamo/convert_frame.py:844] [4/1160] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.725000 612 torch/_dynamo/convert_frame.py:844] [4/1161] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.725000 612 torch/_dynamo/convert_frame.py:844] [4/1161]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.725000 612 torch/_dynamo/convert_frame.py:844] [4/1161]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.725000 612 torch/_dynamo/convert_frame.py:844] [4/1161] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.725000 612 torch/_dynamo/convert_frame.py:844] [4/1161] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.729000 612 torch/_dynamo/convert_frame.py:844] [4/1162] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.729000 612 torch/_dynamo/convert_frame.py:844] [4/1162]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.729000 612 torch/_dynamo/convert_frame.py:844] [4/1162]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.729000 612 torch/_dynamo/convert_frame.py:844] [4/1162] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.729000 612 torch/_dynamo/convert_frame.py:844] [4/1162] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.734000 612 torch/_dynamo/convert_frame.py:844] [4/1163] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.734000 612 torch/_dynamo/convert_frame.py:844] [4/1163]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.734000 612 torch/_dynamo/convert_frame.py:844] [4/1163]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.734000 612 torch/_dynamo/convert_frame.py:844] [4/1163] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.734000 612 torch/_dynamo/convert_frame.py:844] [4/1163] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.739000 612 torch/_dynamo/convert_frame.py:844] [4/1164] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.739000 612 torch/_dynamo/convert_frame.py:844] [4/1164]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.739000 612 torch/_dynamo/convert_frame.py:844] [4/1164]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.739000 612 torch/_dynamo/convert_frame.py:844] [4/1164] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.739000 612 torch/_dynamo/convert_frame.py:844] [4/1164] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.743000 612 torch/_dynamo/convert_frame.py:844] [4/1165] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.743000 612 torch/_dynamo/convert_frame.py:844] [4/1165]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.743000 612 torch/_dynamo/convert_frame.py:844] [4/1165]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.743000 612 torch/_dynamo/convert_frame.py:844] [4/1165] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.743000 612 torch/_dynamo/convert_frame.py:844] [4/1165] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.747000 612 torch/_dynamo/convert_frame.py:844] [4/1166] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.747000 612 torch/_dynamo/convert_frame.py:844] [4/1166]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.747000 612 torch/_dynamo/convert_frame.py:844] [4/1166]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.747000 612 torch/_dynamo/convert_frame.py:844] [4/1166] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.747000 612 torch/_dynamo/convert_frame.py:844] [4/1166] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.751000 612 torch/_dynamo/convert_frame.py:844] [4/1167] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.751000 612 torch/_dynamo/convert_frame.py:844] [4/1167]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.751000 612 torch/_dynamo/convert_frame.py:844] [4/1167]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.751000 612 torch/_dynamo/convert_frame.py:844] [4/1167] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.751000 612 torch/_dynamo/convert_frame.py:844] [4/1167] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.753000 612 torch/_dynamo/convert_frame.py:844] [4/1168] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.753000 612 torch/_dynamo/convert_frame.py:844] [4/1168]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.753000 612 torch/_dynamo/convert_frame.py:844] [4/1168]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.753000 612 torch/_dynamo/convert_frame.py:844] [4/1168] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.753000 612 torch/_dynamo/convert_frame.py:844] [4/1168] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.757000 612 torch/_dynamo/convert_frame.py:844] [4/1169] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.757000 612 torch/_dynamo/convert_frame.py:844] [4/1169]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.757000 612 torch/_dynamo/convert_frame.py:844] [4/1169]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.757000 612 torch/_dynamo/convert_frame.py:844] [4/1169] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.757000 612 torch/_dynamo/convert_frame.py:844] [4/1169] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.761000 612 torch/_dynamo/convert_frame.py:844] [4/1170] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.761000 612 torch/_dynamo/convert_frame.py:844] [4/1170]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.761000 612 torch/_dynamo/convert_frame.py:844] [4/1170]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.761000 612 torch/_dynamo/convert_frame.py:844] [4/1170] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.761000 612 torch/_dynamo/convert_frame.py:844] [4/1170] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.763000 612 torch/_dynamo/convert_frame.py:844] [4/1171] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.763000 612 torch/_dynamo/convert_frame.py:844] [4/1171]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.763000 612 torch/_dynamo/convert_frame.py:844] [4/1171]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.763000 612 torch/_dynamo/convert_frame.py:844] [4/1171] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.763000 612 torch/_dynamo/convert_frame.py:844] [4/1171] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.766000 612 torch/_dynamo/convert_frame.py:844] [4/1172] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.766000 612 torch/_dynamo/convert_frame.py:844] [4/1172]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.766000 612 torch/_dynamo/convert_frame.py:844] [4/1172]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.766000 612 torch/_dynamo/convert_frame.py:844] [4/1172] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.766000 612 torch/_dynamo/convert_frame.py:844] [4/1172] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.769000 612 torch/_dynamo/convert_frame.py:844] [4/1173] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.769000 612 torch/_dynamo/convert_frame.py:844] [4/1173]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.769000 612 torch/_dynamo/convert_frame.py:844] [4/1173]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.769000 612 torch/_dynamo/convert_frame.py:844] [4/1173] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.769000 612 torch/_dynamo/convert_frame.py:844] [4/1173] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.772000 612 torch/_dynamo/convert_frame.py:844] [4/1174] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.772000 612 torch/_dynamo/convert_frame.py:844] [4/1174]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.772000 612 torch/_dynamo/convert_frame.py:844] [4/1174]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.772000 612 torch/_dynamo/convert_frame.py:844] [4/1174] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.772000 612 torch/_dynamo/convert_frame.py:844] [4/1174] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.775000 612 torch/_dynamo/convert_frame.py:844] [4/1175] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.775000 612 torch/_dynamo/convert_frame.py:844] [4/1175]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.775000 612 torch/_dynamo/convert_frame.py:844] [4/1175]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.775000 612 torch/_dynamo/convert_frame.py:844] [4/1175] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.775000 612 torch/_dynamo/convert_frame.py:844] [4/1175] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.778000 612 torch/_dynamo/convert_frame.py:844] [4/1176] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.778000 612 torch/_dynamo/convert_frame.py:844] [4/1176]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.778000 612 torch/_dynamo/convert_frame.py:844] [4/1176]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.778000 612 torch/_dynamo/convert_frame.py:844] [4/1176] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.778000 612 torch/_dynamo/convert_frame.py:844] [4/1176] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.781000 612 torch/_dynamo/convert_frame.py:844] [4/1177] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.781000 612 torch/_dynamo/convert_frame.py:844] [4/1177]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.781000 612 torch/_dynamo/convert_frame.py:844] [4/1177]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.781000 612 torch/_dynamo/convert_frame.py:844] [4/1177] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.781000 612 torch/_dynamo/convert_frame.py:844] [4/1177] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.785000 612 torch/_dynamo/convert_frame.py:844] [4/1178] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.785000 612 torch/_dynamo/convert_frame.py:844] [4/1178]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.785000 612 torch/_dynamo/convert_frame.py:844] [4/1178]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.785000 612 torch/_dynamo/convert_frame.py:844] [4/1178] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.785000 612 torch/_dynamo/convert_frame.py:844] [4/1178] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.787000 612 torch/_dynamo/convert_frame.py:844] [4/1179] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.787000 612 torch/_dynamo/convert_frame.py:844] [4/1179]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.787000 612 torch/_dynamo/convert_frame.py:844] [4/1179]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.787000 612 torch/_dynamo/convert_frame.py:844] [4/1179] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.787000 612 torch/_dynamo/convert_frame.py:844] [4/1179] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.790000 612 torch/_dynamo/convert_frame.py:844] [4/1180] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.790000 612 torch/_dynamo/convert_frame.py:844] [4/1180]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.790000 612 torch/_dynamo/convert_frame.py:844] [4/1180]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.790000 612 torch/_dynamo/convert_frame.py:844] [4/1180] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.790000 612 torch/_dynamo/convert_frame.py:844] [4/1180] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.792000 612 torch/_dynamo/convert_frame.py:844] [4/1181] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.792000 612 torch/_dynamo/convert_frame.py:844] [4/1181]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.792000 612 torch/_dynamo/convert_frame.py:844] [4/1181]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.792000 612 torch/_dynamo/convert_frame.py:844] [4/1181] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.792000 612 torch/_dynamo/convert_frame.py:844] [4/1181] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.795000 612 torch/_dynamo/convert_frame.py:844] [4/1182] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.795000 612 torch/_dynamo/convert_frame.py:844] [4/1182]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.795000 612 torch/_dynamo/convert_frame.py:844] [4/1182]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.795000 612 torch/_dynamo/convert_frame.py:844] [4/1182] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.795000 612 torch/_dynamo/convert_frame.py:844] [4/1182] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.798000 612 torch/_dynamo/convert_frame.py:844] [4/1183] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.798000 612 torch/_dynamo/convert_frame.py:844] [4/1183]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.798000 612 torch/_dynamo/convert_frame.py:844] [4/1183]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.798000 612 torch/_dynamo/convert_frame.py:844] [4/1183] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.798000 612 torch/_dynamo/convert_frame.py:844] [4/1183] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.800000 612 torch/_dynamo/convert_frame.py:844] [4/1184] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.800000 612 torch/_dynamo/convert_frame.py:844] [4/1184]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.800000 612 torch/_dynamo/convert_frame.py:844] [4/1184]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.800000 612 torch/_dynamo/convert_frame.py:844] [4/1184] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.800000 612 torch/_dynamo/convert_frame.py:844] [4/1184] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.803000 612 torch/_dynamo/convert_frame.py:844] [4/1185] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.803000 612 torch/_dynamo/convert_frame.py:844] [4/1185]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.803000 612 torch/_dynamo/convert_frame.py:844] [4/1185]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.803000 612 torch/_dynamo/convert_frame.py:844] [4/1185] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.803000 612 torch/_dynamo/convert_frame.py:844] [4/1185] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.807000 612 torch/_dynamo/convert_frame.py:844] [4/1186] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.807000 612 torch/_dynamo/convert_frame.py:844] [4/1186]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.807000 612 torch/_dynamo/convert_frame.py:844] [4/1186]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.807000 612 torch/_dynamo/convert_frame.py:844] [4/1186] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.807000 612 torch/_dynamo/convert_frame.py:844] [4/1186] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.813000 612 torch/_dynamo/convert_frame.py:844] [4/1187] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.813000 612 torch/_dynamo/convert_frame.py:844] [4/1187]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.813000 612 torch/_dynamo/convert_frame.py:844] [4/1187]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.813000 612 torch/_dynamo/convert_frame.py:844] [4/1187] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.813000 612 torch/_dynamo/convert_frame.py:844] [4/1187] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.816000 612 torch/_dynamo/convert_frame.py:844] [4/1188] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.816000 612 torch/_dynamo/convert_frame.py:844] [4/1188]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.816000 612 torch/_dynamo/convert_frame.py:844] [4/1188]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.816000 612 torch/_dynamo/convert_frame.py:844] [4/1188] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.816000 612 torch/_dynamo/convert_frame.py:844] [4/1188] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.819000 612 torch/_dynamo/convert_frame.py:844] [4/1189] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.819000 612 torch/_dynamo/convert_frame.py:844] [4/1189]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.819000 612 torch/_dynamo/convert_frame.py:844] [4/1189]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.819000 612 torch/_dynamo/convert_frame.py:844] [4/1189] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.819000 612 torch/_dynamo/convert_frame.py:844] [4/1189] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.821000 612 torch/_dynamo/convert_frame.py:844] [4/1190] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.821000 612 torch/_dynamo/convert_frame.py:844] [4/1190]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.821000 612 torch/_dynamo/convert_frame.py:844] [4/1190]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.821000 612 torch/_dynamo/convert_frame.py:844] [4/1190] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.821000 612 torch/_dynamo/convert_frame.py:844] [4/1190] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.824000 612 torch/_dynamo/convert_frame.py:844] [4/1191] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.824000 612 torch/_dynamo/convert_frame.py:844] [4/1191]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.824000 612 torch/_dynamo/convert_frame.py:844] [4/1191]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.824000 612 torch/_dynamo/convert_frame.py:844] [4/1191] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.824000 612 torch/_dynamo/convert_frame.py:844] [4/1191] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.828000 612 torch/_dynamo/convert_frame.py:844] [4/1192] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.828000 612 torch/_dynamo/convert_frame.py:844] [4/1192]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.828000 612 torch/_dynamo/convert_frame.py:844] [4/1192]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.828000 612 torch/_dynamo/convert_frame.py:844] [4/1192] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.828000 612 torch/_dynamo/convert_frame.py:844] [4/1192] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.831000 612 torch/_dynamo/convert_frame.py:844] [4/1193] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.831000 612 torch/_dynamo/convert_frame.py:844] [4/1193]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.831000 612 torch/_dynamo/convert_frame.py:844] [4/1193]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.831000 612 torch/_dynamo/convert_frame.py:844] [4/1193] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.831000 612 torch/_dynamo/convert_frame.py:844] [4/1193] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.834000 612 torch/_dynamo/convert_frame.py:844] [4/1194] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.834000 612 torch/_dynamo/convert_frame.py:844] [4/1194]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.834000 612 torch/_dynamo/convert_frame.py:844] [4/1194]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.834000 612 torch/_dynamo/convert_frame.py:844] [4/1194] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.834000 612 torch/_dynamo/convert_frame.py:844] [4/1194] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.838000 612 torch/_dynamo/convert_frame.py:844] [4/1195] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.838000 612 torch/_dynamo/convert_frame.py:844] [4/1195]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.838000 612 torch/_dynamo/convert_frame.py:844] [4/1195]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.838000 612 torch/_dynamo/convert_frame.py:844] [4/1195] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.838000 612 torch/_dynamo/convert_frame.py:844] [4/1195] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.841000 612 torch/_dynamo/convert_frame.py:844] [4/1196] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.841000 612 torch/_dynamo/convert_frame.py:844] [4/1196]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.841000 612 torch/_dynamo/convert_frame.py:844] [4/1196]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.841000 612 torch/_dynamo/convert_frame.py:844] [4/1196] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.841000 612 torch/_dynamo/convert_frame.py:844] [4/1196] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.845000 612 torch/_dynamo/convert_frame.py:844] [4/1197] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.845000 612 torch/_dynamo/convert_frame.py:844] [4/1197]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.845000 612 torch/_dynamo/convert_frame.py:844] [4/1197]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.845000 612 torch/_dynamo/convert_frame.py:844] [4/1197] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.845000 612 torch/_dynamo/convert_frame.py:844] [4/1197] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.848000 612 torch/_dynamo/convert_frame.py:844] [4/1198] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.848000 612 torch/_dynamo/convert_frame.py:844] [4/1198]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.848000 612 torch/_dynamo/convert_frame.py:844] [4/1198]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.848000 612 torch/_dynamo/convert_frame.py:844] [4/1198] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.848000 612 torch/_dynamo/convert_frame.py:844] [4/1198] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.851000 612 torch/_dynamo/convert_frame.py:844] [4/1199] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.851000 612 torch/_dynamo/convert_frame.py:844] [4/1199]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.851000 612 torch/_dynamo/convert_frame.py:844] [4/1199]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.851000 612 torch/_dynamo/convert_frame.py:844] [4/1199] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.851000 612 torch/_dynamo/convert_frame.py:844] [4/1199] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.854000 612 torch/_dynamo/convert_frame.py:844] [4/1200] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.854000 612 torch/_dynamo/convert_frame.py:844] [4/1200]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.854000 612 torch/_dynamo/convert_frame.py:844] [4/1200]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.854000 612 torch/_dynamo/convert_frame.py:844] [4/1200] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.854000 612 torch/_dynamo/convert_frame.py:844] [4/1200] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.857000 612 torch/_dynamo/convert_frame.py:844] [4/1201] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.857000 612 torch/_dynamo/convert_frame.py:844] [4/1201]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.857000 612 torch/_dynamo/convert_frame.py:844] [4/1201]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.857000 612 torch/_dynamo/convert_frame.py:844] [4/1201] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.857000 612 torch/_dynamo/convert_frame.py:844] [4/1201] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.860000 612 torch/_dynamo/convert_frame.py:844] [4/1202] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.860000 612 torch/_dynamo/convert_frame.py:844] [4/1202]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.860000 612 torch/_dynamo/convert_frame.py:844] [4/1202]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.860000 612 torch/_dynamo/convert_frame.py:844] [4/1202] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.860000 612 torch/_dynamo/convert_frame.py:844] [4/1202] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.862000 612 torch/_dynamo/convert_frame.py:844] [4/1203] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.862000 612 torch/_dynamo/convert_frame.py:844] [4/1203]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.862000 612 torch/_dynamo/convert_frame.py:844] [4/1203]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.862000 612 torch/_dynamo/convert_frame.py:844] [4/1203] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.862000 612 torch/_dynamo/convert_frame.py:844] [4/1203] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.866000 612 torch/_dynamo/convert_frame.py:844] [4/1204] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.866000 612 torch/_dynamo/convert_frame.py:844] [4/1204]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.866000 612 torch/_dynamo/convert_frame.py:844] [4/1204]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.866000 612 torch/_dynamo/convert_frame.py:844] [4/1204] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.866000 612 torch/_dynamo/convert_frame.py:844] [4/1204] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.869000 612 torch/_dynamo/convert_frame.py:844] [4/1205] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.869000 612 torch/_dynamo/convert_frame.py:844] [4/1205]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.869000 612 torch/_dynamo/convert_frame.py:844] [4/1205]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.869000 612 torch/_dynamo/convert_frame.py:844] [4/1205] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.869000 612 torch/_dynamo/convert_frame.py:844] [4/1205] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.871000 612 torch/_dynamo/convert_frame.py:844] [4/1206] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.871000 612 torch/_dynamo/convert_frame.py:844] [4/1206]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.871000 612 torch/_dynamo/convert_frame.py:844] [4/1206]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.871000 612 torch/_dynamo/convert_frame.py:844] [4/1206] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.871000 612 torch/_dynamo/convert_frame.py:844] [4/1206] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.874000 612 torch/_dynamo/convert_frame.py:844] [4/1207] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.874000 612 torch/_dynamo/convert_frame.py:844] [4/1207]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.874000 612 torch/_dynamo/convert_frame.py:844] [4/1207]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.874000 612 torch/_dynamo/convert_frame.py:844] [4/1207] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.874000 612 torch/_dynamo/convert_frame.py:844] [4/1207] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.877000 612 torch/_dynamo/convert_frame.py:844] [4/1208] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.877000 612 torch/_dynamo/convert_frame.py:844] [4/1208]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.877000 612 torch/_dynamo/convert_frame.py:844] [4/1208]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.877000 612 torch/_dynamo/convert_frame.py:844] [4/1208] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.877000 612 torch/_dynamo/convert_frame.py:844] [4/1208] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.883000 612 torch/_dynamo/convert_frame.py:844] [4/1209] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.883000 612 torch/_dynamo/convert_frame.py:844] [4/1209]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.883000 612 torch/_dynamo/convert_frame.py:844] [4/1209]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.883000 612 torch/_dynamo/convert_frame.py:844] [4/1209] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.883000 612 torch/_dynamo/convert_frame.py:844] [4/1209] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.886000 612 torch/_dynamo/convert_frame.py:844] [4/1210] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.886000 612 torch/_dynamo/convert_frame.py:844] [4/1210]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.886000 612 torch/_dynamo/convert_frame.py:844] [4/1210]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.886000 612 torch/_dynamo/convert_frame.py:844] [4/1210] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.886000 612 torch/_dynamo/convert_frame.py:844] [4/1210] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.889000 612 torch/_dynamo/convert_frame.py:844] [4/1211] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.889000 612 torch/_dynamo/convert_frame.py:844] [4/1211]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.889000 612 torch/_dynamo/convert_frame.py:844] [4/1211]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.889000 612 torch/_dynamo/convert_frame.py:844] [4/1211] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.889000 612 torch/_dynamo/convert_frame.py:844] [4/1211] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.891000 612 torch/_dynamo/convert_frame.py:844] [4/1212] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.891000 612 torch/_dynamo/convert_frame.py:844] [4/1212]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.891000 612 torch/_dynamo/convert_frame.py:844] [4/1212]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.891000 612 torch/_dynamo/convert_frame.py:844] [4/1212] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.891000 612 torch/_dynamo/convert_frame.py:844] [4/1212] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.894000 612 torch/_dynamo/convert_frame.py:844] [4/1213] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.894000 612 torch/_dynamo/convert_frame.py:844] [4/1213]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.894000 612 torch/_dynamo/convert_frame.py:844] [4/1213]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.894000 612 torch/_dynamo/convert_frame.py:844] [4/1213] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.894000 612 torch/_dynamo/convert_frame.py:844] [4/1213] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.897000 612 torch/_dynamo/convert_frame.py:844] [4/1214] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.897000 612 torch/_dynamo/convert_frame.py:844] [4/1214]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.897000 612 torch/_dynamo/convert_frame.py:844] [4/1214]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.897000 612 torch/_dynamo/convert_frame.py:844] [4/1214] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.897000 612 torch/_dynamo/convert_frame.py:844] [4/1214] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.899000 612 torch/_dynamo/convert_frame.py:844] [4/1215] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.899000 612 torch/_dynamo/convert_frame.py:844] [4/1215]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.899000 612 torch/_dynamo/convert_frame.py:844] [4/1215]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.899000 612 torch/_dynamo/convert_frame.py:844] [4/1215] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.899000 612 torch/_dynamo/convert_frame.py:844] [4/1215] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.902000 612 torch/_dynamo/convert_frame.py:844] [4/1216] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.902000 612 torch/_dynamo/convert_frame.py:844] [4/1216]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.902000 612 torch/_dynamo/convert_frame.py:844] [4/1216]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.902000 612 torch/_dynamo/convert_frame.py:844] [4/1216] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.902000 612 torch/_dynamo/convert_frame.py:844] [4/1216] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.905000 612 torch/_dynamo/convert_frame.py:844] [4/1217] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.905000 612 torch/_dynamo/convert_frame.py:844] [4/1217]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.905000 612 torch/_dynamo/convert_frame.py:844] [4/1217]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.905000 612 torch/_dynamo/convert_frame.py:844] [4/1217] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.905000 612 torch/_dynamo/convert_frame.py:844] [4/1217] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.908000 612 torch/_dynamo/convert_frame.py:844] [4/1218] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.908000 612 torch/_dynamo/convert_frame.py:844] [4/1218]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.908000 612 torch/_dynamo/convert_frame.py:844] [4/1218]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.908000 612 torch/_dynamo/convert_frame.py:844] [4/1218] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.908000 612 torch/_dynamo/convert_frame.py:844] [4/1218] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.911000 612 torch/_dynamo/convert_frame.py:844] [4/1219] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.911000 612 torch/_dynamo/convert_frame.py:844] [4/1219]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.911000 612 torch/_dynamo/convert_frame.py:844] [4/1219]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.911000 612 torch/_dynamo/convert_frame.py:844] [4/1219] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.911000 612 torch/_dynamo/convert_frame.py:844] [4/1219] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.913000 612 torch/_dynamo/convert_frame.py:844] [4/1220] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.913000 612 torch/_dynamo/convert_frame.py:844] [4/1220]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.913000 612 torch/_dynamo/convert_frame.py:844] [4/1220]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.913000 612 torch/_dynamo/convert_frame.py:844] [4/1220] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.913000 612 torch/_dynamo/convert_frame.py:844] [4/1220] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.916000 612 torch/_dynamo/convert_frame.py:844] [4/1221] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.916000 612 torch/_dynamo/convert_frame.py:844] [4/1221]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.916000 612 torch/_dynamo/convert_frame.py:844] [4/1221]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.916000 612 torch/_dynamo/convert_frame.py:844] [4/1221] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.916000 612 torch/_dynamo/convert_frame.py:844] [4/1221] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.920000 612 torch/_dynamo/convert_frame.py:844] [4/1222] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.920000 612 torch/_dynamo/convert_frame.py:844] [4/1222]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.920000 612 torch/_dynamo/convert_frame.py:844] [4/1222]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.920000 612 torch/_dynamo/convert_frame.py:844] [4/1222] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.920000 612 torch/_dynamo/convert_frame.py:844] [4/1222] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.923000 612 torch/_dynamo/convert_frame.py:844] [4/1223] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.923000 612 torch/_dynamo/convert_frame.py:844] [4/1223]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.923000 612 torch/_dynamo/convert_frame.py:844] [4/1223]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.923000 612 torch/_dynamo/convert_frame.py:844] [4/1223] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.923000 612 torch/_dynamo/convert_frame.py:844] [4/1223] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.925000 612 torch/_dynamo/convert_frame.py:844] [4/1224] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.925000 612 torch/_dynamo/convert_frame.py:844] [4/1224]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.925000 612 torch/_dynamo/convert_frame.py:844] [4/1224]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.925000 612 torch/_dynamo/convert_frame.py:844] [4/1224] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.925000 612 torch/_dynamo/convert_frame.py:844] [4/1224] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.928000 612 torch/_dynamo/convert_frame.py:844] [4/1225] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.928000 612 torch/_dynamo/convert_frame.py:844] [4/1225]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.928000 612 torch/_dynamo/convert_frame.py:844] [4/1225]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.928000 612 torch/_dynamo/convert_frame.py:844] [4/1225] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.928000 612 torch/_dynamo/convert_frame.py:844] [4/1225] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.931000 612 torch/_dynamo/convert_frame.py:844] [4/1226] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.931000 612 torch/_dynamo/convert_frame.py:844] [4/1226]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.931000 612 torch/_dynamo/convert_frame.py:844] [4/1226]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.931000 612 torch/_dynamo/convert_frame.py:844] [4/1226] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.931000 612 torch/_dynamo/convert_frame.py:844] [4/1226] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.933000 612 torch/_dynamo/convert_frame.py:844] [4/1227] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.933000 612 torch/_dynamo/convert_frame.py:844] [4/1227]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.933000 612 torch/_dynamo/convert_frame.py:844] [4/1227]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.933000 612 torch/_dynamo/convert_frame.py:844] [4/1227] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.933000 612 torch/_dynamo/convert_frame.py:844] [4/1227] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.936000 612 torch/_dynamo/convert_frame.py:844] [4/1228] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.936000 612 torch/_dynamo/convert_frame.py:844] [4/1228]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.936000 612 torch/_dynamo/convert_frame.py:844] [4/1228]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.936000 612 torch/_dynamo/convert_frame.py:844] [4/1228] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.936000 612 torch/_dynamo/convert_frame.py:844] [4/1228] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.939000 612 torch/_dynamo/convert_frame.py:844] [4/1229] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.939000 612 torch/_dynamo/convert_frame.py:844] [4/1229]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.939000 612 torch/_dynamo/convert_frame.py:844] [4/1229]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.939000 612 torch/_dynamo/convert_frame.py:844] [4/1229] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.939000 612 torch/_dynamo/convert_frame.py:844] [4/1229] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.942000 612 torch/_dynamo/convert_frame.py:844] [4/1230] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.942000 612 torch/_dynamo/convert_frame.py:844] [4/1230]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.942000 612 torch/_dynamo/convert_frame.py:844] [4/1230]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.942000 612 torch/_dynamo/convert_frame.py:844] [4/1230] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.942000 612 torch/_dynamo/convert_frame.py:844] [4/1230] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.945000 612 torch/_dynamo/convert_frame.py:844] [4/1231] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.945000 612 torch/_dynamo/convert_frame.py:844] [4/1231]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.945000 612 torch/_dynamo/convert_frame.py:844] [4/1231]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.945000 612 torch/_dynamo/convert_frame.py:844] [4/1231] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.945000 612 torch/_dynamo/convert_frame.py:844] [4/1231] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.949000 612 torch/_dynamo/convert_frame.py:844] [4/1232] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.949000 612 torch/_dynamo/convert_frame.py:844] [4/1232]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.949000 612 torch/_dynamo/convert_frame.py:844] [4/1232]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.949000 612 torch/_dynamo/convert_frame.py:844] [4/1232] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.949000 612 torch/_dynamo/convert_frame.py:844] [4/1232] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.952000 612 torch/_dynamo/convert_frame.py:844] [4/1233] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.952000 612 torch/_dynamo/convert_frame.py:844] [4/1233]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.952000 612 torch/_dynamo/convert_frame.py:844] [4/1233]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.952000 612 torch/_dynamo/convert_frame.py:844] [4/1233] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.952000 612 torch/_dynamo/convert_frame.py:844] [4/1233] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.955000 612 torch/_dynamo/convert_frame.py:844] [4/1234] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.955000 612 torch/_dynamo/convert_frame.py:844] [4/1234]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.955000 612 torch/_dynamo/convert_frame.py:844] [4/1234]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.955000 612 torch/_dynamo/convert_frame.py:844] [4/1234] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.955000 612 torch/_dynamo/convert_frame.py:844] [4/1234] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.958000 612 torch/_dynamo/convert_frame.py:844] [4/1235] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.958000 612 torch/_dynamo/convert_frame.py:844] [4/1235]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.958000 612 torch/_dynamo/convert_frame.py:844] [4/1235]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.958000 612 torch/_dynamo/convert_frame.py:844] [4/1235] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.958000 612 torch/_dynamo/convert_frame.py:844] [4/1235] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.961000 612 torch/_dynamo/convert_frame.py:844] [4/1236] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.961000 612 torch/_dynamo/convert_frame.py:844] [4/1236]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.961000 612 torch/_dynamo/convert_frame.py:844] [4/1236]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.961000 612 torch/_dynamo/convert_frame.py:844] [4/1236] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.961000 612 torch/_dynamo/convert_frame.py:844] [4/1236] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.963000 612 torch/_dynamo/convert_frame.py:844] [4/1237] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.963000 612 torch/_dynamo/convert_frame.py:844] [4/1237]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.963000 612 torch/_dynamo/convert_frame.py:844] [4/1237]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.963000 612 torch/_dynamo/convert_frame.py:844] [4/1237] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.963000 612 torch/_dynamo/convert_frame.py:844] [4/1237] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.967000 612 torch/_dynamo/convert_frame.py:844] [4/1238] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.967000 612 torch/_dynamo/convert_frame.py:844] [4/1238]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.967000 612 torch/_dynamo/convert_frame.py:844] [4/1238]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.967000 612 torch/_dynamo/convert_frame.py:844] [4/1238] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.967000 612 torch/_dynamo/convert_frame.py:844] [4/1238] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.970000 612 torch/_dynamo/convert_frame.py:844] [4/1239] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.970000 612 torch/_dynamo/convert_frame.py:844] [4/1239]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.970000 612 torch/_dynamo/convert_frame.py:844] [4/1239]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.970000 612 torch/_dynamo/convert_frame.py:844] [4/1239] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.970000 612 torch/_dynamo/convert_frame.py:844] [4/1239] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.972000 612 torch/_dynamo/convert_frame.py:844] [4/1240] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.972000 612 torch/_dynamo/convert_frame.py:844] [4/1240]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.972000 612 torch/_dynamo/convert_frame.py:844] [4/1240]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.972000 612 torch/_dynamo/convert_frame.py:844] [4/1240] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.972000 612 torch/_dynamo/convert_frame.py:844] [4/1240] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.975000 612 torch/_dynamo/convert_frame.py:844] [4/1241] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.975000 612 torch/_dynamo/convert_frame.py:844] [4/1241]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.975000 612 torch/_dynamo/convert_frame.py:844] [4/1241]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.975000 612 torch/_dynamo/convert_frame.py:844] [4/1241] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.975000 612 torch/_dynamo/convert_frame.py:844] [4/1241] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.978000 612 torch/_dynamo/convert_frame.py:844] [4/1242] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.978000 612 torch/_dynamo/convert_frame.py:844] [4/1242]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.978000 612 torch/_dynamo/convert_frame.py:844] [4/1242]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.978000 612 torch/_dynamo/convert_frame.py:844] [4/1242] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.978000 612 torch/_dynamo/convert_frame.py:844] [4/1242] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.982000 612 torch/_dynamo/convert_frame.py:844] [4/1243] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.982000 612 torch/_dynamo/convert_frame.py:844] [4/1243]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.982000 612 torch/_dynamo/convert_frame.py:844] [4/1243]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.982000 612 torch/_dynamo/convert_frame.py:844] [4/1243] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.982000 612 torch/_dynamo/convert_frame.py:844] [4/1243] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.984000 612 torch/_dynamo/convert_frame.py:844] [4/1244] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.984000 612 torch/_dynamo/convert_frame.py:844] [4/1244]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.984000 612 torch/_dynamo/convert_frame.py:844] [4/1244]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.984000 612 torch/_dynamo/convert_frame.py:844] [4/1244] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.984000 612 torch/_dynamo/convert_frame.py:844] [4/1244] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.987000 612 torch/_dynamo/convert_frame.py:844] [4/1245] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.987000 612 torch/_dynamo/convert_frame.py:844] [4/1245]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.987000 612 torch/_dynamo/convert_frame.py:844] [4/1245]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.987000 612 torch/_dynamo/convert_frame.py:844] [4/1245] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.987000 612 torch/_dynamo/convert_frame.py:844] [4/1245] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.990000 612 torch/_dynamo/convert_frame.py:844] [4/1246] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.990000 612 torch/_dynamo/convert_frame.py:844] [4/1246]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.990000 612 torch/_dynamo/convert_frame.py:844] [4/1246]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.990000 612 torch/_dynamo/convert_frame.py:844] [4/1246] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.990000 612 torch/_dynamo/convert_frame.py:844] [4/1246] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.993000 612 torch/_dynamo/convert_frame.py:844] [4/1247] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.993000 612 torch/_dynamo/convert_frame.py:844] [4/1247]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.993000 612 torch/_dynamo/convert_frame.py:844] [4/1247]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.993000 612 torch/_dynamo/convert_frame.py:844] [4/1247] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.993000 612 torch/_dynamo/convert_frame.py:844] [4/1247] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.996000 612 torch/_dynamo/convert_frame.py:844] [4/1248] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.996000 612 torch/_dynamo/convert_frame.py:844] [4/1248]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.996000 612 torch/_dynamo/convert_frame.py:844] [4/1248]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.996000 612 torch/_dynamo/convert_frame.py:844] [4/1248] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.996000 612 torch/_dynamo/convert_frame.py:844] [4/1248] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:12.999000 612 torch/_dynamo/convert_frame.py:844] [4/1249] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:12.999000 612 torch/_dynamo/convert_frame.py:844] [4/1249]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:12.999000 612 torch/_dynamo/convert_frame.py:844] [4/1249]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:12.999000 612 torch/_dynamo/convert_frame.py:844] [4/1249] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:12.999000 612 torch/_dynamo/convert_frame.py:844] [4/1249] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.002000 612 torch/_dynamo/convert_frame.py:844] [4/1250] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.002000 612 torch/_dynamo/convert_frame.py:844] [4/1250]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.002000 612 torch/_dynamo/convert_frame.py:844] [4/1250]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.002000 612 torch/_dynamo/convert_frame.py:844] [4/1250] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.002000 612 torch/_dynamo/convert_frame.py:844] [4/1250] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.004000 612 torch/_dynamo/convert_frame.py:844] [4/1251] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.004000 612 torch/_dynamo/convert_frame.py:844] [4/1251]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.004000 612 torch/_dynamo/convert_frame.py:844] [4/1251]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.004000 612 torch/_dynamo/convert_frame.py:844] [4/1251] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.004000 612 torch/_dynamo/convert_frame.py:844] [4/1251] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.008000 612 torch/_dynamo/convert_frame.py:844] [4/1252] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.008000 612 torch/_dynamo/convert_frame.py:844] [4/1252]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.008000 612 torch/_dynamo/convert_frame.py:844] [4/1252]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.008000 612 torch/_dynamo/convert_frame.py:844] [4/1252] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.008000 612 torch/_dynamo/convert_frame.py:844] [4/1252] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.011000 612 torch/_dynamo/convert_frame.py:844] [4/1253] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.011000 612 torch/_dynamo/convert_frame.py:844] [4/1253]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.011000 612 torch/_dynamo/convert_frame.py:844] [4/1253]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.011000 612 torch/_dynamo/convert_frame.py:844] [4/1253] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.011000 612 torch/_dynamo/convert_frame.py:844] [4/1253] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.015000 612 torch/_dynamo/convert_frame.py:844] [4/1254] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.015000 612 torch/_dynamo/convert_frame.py:844] [4/1254]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.015000 612 torch/_dynamo/convert_frame.py:844] [4/1254]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.015000 612 torch/_dynamo/convert_frame.py:844] [4/1254] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.015000 612 torch/_dynamo/convert_frame.py:844] [4/1254] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.018000 612 torch/_dynamo/convert_frame.py:844] [4/1255] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.018000 612 torch/_dynamo/convert_frame.py:844] [4/1255]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.018000 612 torch/_dynamo/convert_frame.py:844] [4/1255]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.018000 612 torch/_dynamo/convert_frame.py:844] [4/1255] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.018000 612 torch/_dynamo/convert_frame.py:844] [4/1255] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.022000 612 torch/_dynamo/convert_frame.py:844] [4/1256] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.022000 612 torch/_dynamo/convert_frame.py:844] [4/1256]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.022000 612 torch/_dynamo/convert_frame.py:844] [4/1256]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.022000 612 torch/_dynamo/convert_frame.py:844] [4/1256] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.022000 612 torch/_dynamo/convert_frame.py:844] [4/1256] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.024000 612 torch/_dynamo/convert_frame.py:844] [4/1257] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.024000 612 torch/_dynamo/convert_frame.py:844] [4/1257]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.024000 612 torch/_dynamo/convert_frame.py:844] [4/1257]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.024000 612 torch/_dynamo/convert_frame.py:844] [4/1257] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.024000 612 torch/_dynamo/convert_frame.py:844] [4/1257] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.028000 612 torch/_dynamo/convert_frame.py:844] [4/1258] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.028000 612 torch/_dynamo/convert_frame.py:844] [4/1258]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.028000 612 torch/_dynamo/convert_frame.py:844] [4/1258]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.028000 612 torch/_dynamo/convert_frame.py:844] [4/1258] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.028000 612 torch/_dynamo/convert_frame.py:844] [4/1258] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.031000 612 torch/_dynamo/convert_frame.py:844] [4/1259] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.031000 612 torch/_dynamo/convert_frame.py:844] [4/1259]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.031000 612 torch/_dynamo/convert_frame.py:844] [4/1259]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.031000 612 torch/_dynamo/convert_frame.py:844] [4/1259] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.031000 612 torch/_dynamo/convert_frame.py:844] [4/1259] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.034000 612 torch/_dynamo/convert_frame.py:844] [4/1260] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.034000 612 torch/_dynamo/convert_frame.py:844] [4/1260]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.034000 612 torch/_dynamo/convert_frame.py:844] [4/1260]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.034000 612 torch/_dynamo/convert_frame.py:844] [4/1260] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.034000 612 torch/_dynamo/convert_frame.py:844] [4/1260] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.037000 612 torch/_dynamo/convert_frame.py:844] [4/1261] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.037000 612 torch/_dynamo/convert_frame.py:844] [4/1261]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.037000 612 torch/_dynamo/convert_frame.py:844] [4/1261]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.037000 612 torch/_dynamo/convert_frame.py:844] [4/1261] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.037000 612 torch/_dynamo/convert_frame.py:844] [4/1261] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.041000 612 torch/_dynamo/convert_frame.py:844] [4/1262] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.041000 612 torch/_dynamo/convert_frame.py:844] [4/1262]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.041000 612 torch/_dynamo/convert_frame.py:844] [4/1262]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.041000 612 torch/_dynamo/convert_frame.py:844] [4/1262] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.041000 612 torch/_dynamo/convert_frame.py:844] [4/1262] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.044000 612 torch/_dynamo/convert_frame.py:844] [4/1263] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.044000 612 torch/_dynamo/convert_frame.py:844] [4/1263]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.044000 612 torch/_dynamo/convert_frame.py:844] [4/1263]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.044000 612 torch/_dynamo/convert_frame.py:844] [4/1263] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.044000 612 torch/_dynamo/convert_frame.py:844] [4/1263] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.046000 612 torch/_dynamo/convert_frame.py:844] [4/1264] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.046000 612 torch/_dynamo/convert_frame.py:844] [4/1264]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.046000 612 torch/_dynamo/convert_frame.py:844] [4/1264]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.046000 612 torch/_dynamo/convert_frame.py:844] [4/1264] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.046000 612 torch/_dynamo/convert_frame.py:844] [4/1264] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.048000 612 torch/_dynamo/convert_frame.py:844] [4/1265] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.048000 612 torch/_dynamo/convert_frame.py:844] [4/1265]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.048000 612 torch/_dynamo/convert_frame.py:844] [4/1265]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.048000 612 torch/_dynamo/convert_frame.py:844] [4/1265] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.048000 612 torch/_dynamo/convert_frame.py:844] [4/1265] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.051000 612 torch/_dynamo/convert_frame.py:844] [4/1266] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.051000 612 torch/_dynamo/convert_frame.py:844] [4/1266]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.051000 612 torch/_dynamo/convert_frame.py:844] [4/1266]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.051000 612 torch/_dynamo/convert_frame.py:844] [4/1266] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.051000 612 torch/_dynamo/convert_frame.py:844] [4/1266] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.054000 612 torch/_dynamo/convert_frame.py:844] [4/1267] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.054000 612 torch/_dynamo/convert_frame.py:844] [4/1267]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.054000 612 torch/_dynamo/convert_frame.py:844] [4/1267]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.054000 612 torch/_dynamo/convert_frame.py:844] [4/1267] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.054000 612 torch/_dynamo/convert_frame.py:844] [4/1267] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.056000 612 torch/_dynamo/convert_frame.py:844] [4/1268] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.056000 612 torch/_dynamo/convert_frame.py:844] [4/1268]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.056000 612 torch/_dynamo/convert_frame.py:844] [4/1268]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.056000 612 torch/_dynamo/convert_frame.py:844] [4/1268] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.056000 612 torch/_dynamo/convert_frame.py:844] [4/1268] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.059000 612 torch/_dynamo/convert_frame.py:844] [4/1269] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.059000 612 torch/_dynamo/convert_frame.py:844] [4/1269]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.059000 612 torch/_dynamo/convert_frame.py:844] [4/1269]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.059000 612 torch/_dynamo/convert_frame.py:844] [4/1269] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.059000 612 torch/_dynamo/convert_frame.py:844] [4/1269] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.062000 612 torch/_dynamo/convert_frame.py:844] [4/1270] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.062000 612 torch/_dynamo/convert_frame.py:844] [4/1270]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.062000 612 torch/_dynamo/convert_frame.py:844] [4/1270]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.062000 612 torch/_dynamo/convert_frame.py:844] [4/1270] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.062000 612 torch/_dynamo/convert_frame.py:844] [4/1270] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.065000 612 torch/_dynamo/convert_frame.py:844] [4/1271] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.065000 612 torch/_dynamo/convert_frame.py:844] [4/1271]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.065000 612 torch/_dynamo/convert_frame.py:844] [4/1271]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.065000 612 torch/_dynamo/convert_frame.py:844] [4/1271] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.065000 612 torch/_dynamo/convert_frame.py:844] [4/1271] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.068000 612 torch/_dynamo/convert_frame.py:844] [4/1272] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.068000 612 torch/_dynamo/convert_frame.py:844] [4/1272]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.068000 612 torch/_dynamo/convert_frame.py:844] [4/1272]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.068000 612 torch/_dynamo/convert_frame.py:844] [4/1272] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.068000 612 torch/_dynamo/convert_frame.py:844] [4/1272] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.071000 612 torch/_dynamo/convert_frame.py:844] [4/1273] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.071000 612 torch/_dynamo/convert_frame.py:844] [4/1273]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.071000 612 torch/_dynamo/convert_frame.py:844] [4/1273]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.071000 612 torch/_dynamo/convert_frame.py:844] [4/1273] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.071000 612 torch/_dynamo/convert_frame.py:844] [4/1273] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.074000 612 torch/_dynamo/convert_frame.py:844] [4/1274] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.074000 612 torch/_dynamo/convert_frame.py:844] [4/1274]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.074000 612 torch/_dynamo/convert_frame.py:844] [4/1274]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.074000 612 torch/_dynamo/convert_frame.py:844] [4/1274] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.074000 612 torch/_dynamo/convert_frame.py:844] [4/1274] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.077000 612 torch/_dynamo/convert_frame.py:844] [4/1275] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.077000 612 torch/_dynamo/convert_frame.py:844] [4/1275]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.077000 612 torch/_dynamo/convert_frame.py:844] [4/1275]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.077000 612 torch/_dynamo/convert_frame.py:844] [4/1275] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.077000 612 torch/_dynamo/convert_frame.py:844] [4/1275] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.080000 612 torch/_dynamo/convert_frame.py:844] [4/1276] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.080000 612 torch/_dynamo/convert_frame.py:844] [4/1276]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.080000 612 torch/_dynamo/convert_frame.py:844] [4/1276]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.080000 612 torch/_dynamo/convert_frame.py:844] [4/1276] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.080000 612 torch/_dynamo/convert_frame.py:844] [4/1276] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.082000 612 torch/_dynamo/convert_frame.py:844] [4/1277] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.082000 612 torch/_dynamo/convert_frame.py:844] [4/1277]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.082000 612 torch/_dynamo/convert_frame.py:844] [4/1277]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.082000 612 torch/_dynamo/convert_frame.py:844] [4/1277] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.082000 612 torch/_dynamo/convert_frame.py:844] [4/1277] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.086000 612 torch/_dynamo/convert_frame.py:844] [4/1278] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.086000 612 torch/_dynamo/convert_frame.py:844] [4/1278]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.086000 612 torch/_dynamo/convert_frame.py:844] [4/1278]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.086000 612 torch/_dynamo/convert_frame.py:844] [4/1278] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.086000 612 torch/_dynamo/convert_frame.py:844] [4/1278] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.089000 612 torch/_dynamo/convert_frame.py:844] [4/1279] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.089000 612 torch/_dynamo/convert_frame.py:844] [4/1279]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.089000 612 torch/_dynamo/convert_frame.py:844] [4/1279]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.089000 612 torch/_dynamo/convert_frame.py:844] [4/1279] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.089000 612 torch/_dynamo/convert_frame.py:844] [4/1279] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.092000 612 torch/_dynamo/convert_frame.py:844] [4/1280] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.092000 612 torch/_dynamo/convert_frame.py:844] [4/1280]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.092000 612 torch/_dynamo/convert_frame.py:844] [4/1280]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.092000 612 torch/_dynamo/convert_frame.py:844] [4/1280] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.092000 612 torch/_dynamo/convert_frame.py:844] [4/1280] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.094000 612 torch/_dynamo/convert_frame.py:844] [4/1281] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.094000 612 torch/_dynamo/convert_frame.py:844] [4/1281]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.094000 612 torch/_dynamo/convert_frame.py:844] [4/1281]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.094000 612 torch/_dynamo/convert_frame.py:844] [4/1281] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.094000 612 torch/_dynamo/convert_frame.py:844] [4/1281] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.102000 612 torch/_dynamo/convert_frame.py:844] [4/1282] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.102000 612 torch/_dynamo/convert_frame.py:844] [4/1282]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.102000 612 torch/_dynamo/convert_frame.py:844] [4/1282]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.102000 612 torch/_dynamo/convert_frame.py:844] [4/1282] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.102000 612 torch/_dynamo/convert_frame.py:844] [4/1282] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.108000 612 torch/_dynamo/convert_frame.py:844] [4/1283] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.108000 612 torch/_dynamo/convert_frame.py:844] [4/1283]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.108000 612 torch/_dynamo/convert_frame.py:844] [4/1283]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.108000 612 torch/_dynamo/convert_frame.py:844] [4/1283] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.108000 612 torch/_dynamo/convert_frame.py:844] [4/1283] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.112000 612 torch/_dynamo/convert_frame.py:844] [4/1284] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.112000 612 torch/_dynamo/convert_frame.py:844] [4/1284]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.112000 612 torch/_dynamo/convert_frame.py:844] [4/1284]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.112000 612 torch/_dynamo/convert_frame.py:844] [4/1284] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.112000 612 torch/_dynamo/convert_frame.py:844] [4/1284] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.115000 612 torch/_dynamo/convert_frame.py:844] [4/1285] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.115000 612 torch/_dynamo/convert_frame.py:844] [4/1285]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.115000 612 torch/_dynamo/convert_frame.py:844] [4/1285]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.115000 612 torch/_dynamo/convert_frame.py:844] [4/1285] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.115000 612 torch/_dynamo/convert_frame.py:844] [4/1285] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.122000 612 torch/_dynamo/convert_frame.py:844] [4/1286] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.122000 612 torch/_dynamo/convert_frame.py:844] [4/1286]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.122000 612 torch/_dynamo/convert_frame.py:844] [4/1286]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.122000 612 torch/_dynamo/convert_frame.py:844] [4/1286] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.122000 612 torch/_dynamo/convert_frame.py:844] [4/1286] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.125000 612 torch/_dynamo/convert_frame.py:844] [4/1287] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.125000 612 torch/_dynamo/convert_frame.py:844] [4/1287]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.125000 612 torch/_dynamo/convert_frame.py:844] [4/1287]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.125000 612 torch/_dynamo/convert_frame.py:844] [4/1287] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.125000 612 torch/_dynamo/convert_frame.py:844] [4/1287] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.133000 612 torch/_dynamo/convert_frame.py:844] [4/1288] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.133000 612 torch/_dynamo/convert_frame.py:844] [4/1288]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.133000 612 torch/_dynamo/convert_frame.py:844] [4/1288]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.133000 612 torch/_dynamo/convert_frame.py:844] [4/1288] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.133000 612 torch/_dynamo/convert_frame.py:844] [4/1288] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.140000 612 torch/_dynamo/convert_frame.py:844] [4/1289] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.140000 612 torch/_dynamo/convert_frame.py:844] [4/1289]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.140000 612 torch/_dynamo/convert_frame.py:844] [4/1289]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.140000 612 torch/_dynamo/convert_frame.py:844] [4/1289] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.140000 612 torch/_dynamo/convert_frame.py:844] [4/1289] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.143000 612 torch/_dynamo/convert_frame.py:844] [4/1290] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.143000 612 torch/_dynamo/convert_frame.py:844] [4/1290]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.143000 612 torch/_dynamo/convert_frame.py:844] [4/1290]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.143000 612 torch/_dynamo/convert_frame.py:844] [4/1290] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.143000 612 torch/_dynamo/convert_frame.py:844] [4/1290] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.149000 612 torch/_dynamo/convert_frame.py:844] [4/1291] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.149000 612 torch/_dynamo/convert_frame.py:844] [4/1291]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.149000 612 torch/_dynamo/convert_frame.py:844] [4/1291]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.149000 612 torch/_dynamo/convert_frame.py:844] [4/1291] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.149000 612 torch/_dynamo/convert_frame.py:844] [4/1291] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.152000 612 torch/_dynamo/convert_frame.py:844] [4/1292] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.152000 612 torch/_dynamo/convert_frame.py:844] [4/1292]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.152000 612 torch/_dynamo/convert_frame.py:844] [4/1292]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.152000 612 torch/_dynamo/convert_frame.py:844] [4/1292] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.152000 612 torch/_dynamo/convert_frame.py:844] [4/1292] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.157000 612 torch/_dynamo/convert_frame.py:844] [4/1293] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.157000 612 torch/_dynamo/convert_frame.py:844] [4/1293]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.157000 612 torch/_dynamo/convert_frame.py:844] [4/1293]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.157000 612 torch/_dynamo/convert_frame.py:844] [4/1293] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.157000 612 torch/_dynamo/convert_frame.py:844] [4/1293] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.160000 612 torch/_dynamo/convert_frame.py:844] [4/1294] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.160000 612 torch/_dynamo/convert_frame.py:844] [4/1294]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.160000 612 torch/_dynamo/convert_frame.py:844] [4/1294]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.160000 612 torch/_dynamo/convert_frame.py:844] [4/1294] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.160000 612 torch/_dynamo/convert_frame.py:844] [4/1294] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.166000 612 torch/_dynamo/convert_frame.py:844] [4/1295] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.166000 612 torch/_dynamo/convert_frame.py:844] [4/1295]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.166000 612 torch/_dynamo/convert_frame.py:844] [4/1295]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.166000 612 torch/_dynamo/convert_frame.py:844] [4/1295] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.166000 612 torch/_dynamo/convert_frame.py:844] [4/1295] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.169000 612 torch/_dynamo/convert_frame.py:844] [4/1296] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.169000 612 torch/_dynamo/convert_frame.py:844] [4/1296]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.169000 612 torch/_dynamo/convert_frame.py:844] [4/1296]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.169000 612 torch/_dynamo/convert_frame.py:844] [4/1296] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.169000 612 torch/_dynamo/convert_frame.py:844] [4/1296] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.175000 612 torch/_dynamo/convert_frame.py:844] [4/1297] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.175000 612 torch/_dynamo/convert_frame.py:844] [4/1297]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.175000 612 torch/_dynamo/convert_frame.py:844] [4/1297]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.175000 612 torch/_dynamo/convert_frame.py:844] [4/1297] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.175000 612 torch/_dynamo/convert_frame.py:844] [4/1297] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.178000 612 torch/_dynamo/convert_frame.py:844] [4/1298] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.178000 612 torch/_dynamo/convert_frame.py:844] [4/1298]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.178000 612 torch/_dynamo/convert_frame.py:844] [4/1298]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.178000 612 torch/_dynamo/convert_frame.py:844] [4/1298] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.178000 612 torch/_dynamo/convert_frame.py:844] [4/1298] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.184000 612 torch/_dynamo/convert_frame.py:844] [4/1299] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.184000 612 torch/_dynamo/convert_frame.py:844] [4/1299]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.184000 612 torch/_dynamo/convert_frame.py:844] [4/1299]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.184000 612 torch/_dynamo/convert_frame.py:844] [4/1299] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.184000 612 torch/_dynamo/convert_frame.py:844] [4/1299] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.193000 612 torch/_dynamo/convert_frame.py:844] [4/1300] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.193000 612 torch/_dynamo/convert_frame.py:844] [4/1300]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.193000 612 torch/_dynamo/convert_frame.py:844] [4/1300]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.193000 612 torch/_dynamo/convert_frame.py:844] [4/1300] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.193000 612 torch/_dynamo/convert_frame.py:844] [4/1300] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.196000 612 torch/_dynamo/convert_frame.py:844] [4/1301] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.196000 612 torch/_dynamo/convert_frame.py:844] [4/1301]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.196000 612 torch/_dynamo/convert_frame.py:844] [4/1301]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.196000 612 torch/_dynamo/convert_frame.py:844] [4/1301] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.196000 612 torch/_dynamo/convert_frame.py:844] [4/1301] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.198000 612 torch/_dynamo/convert_frame.py:844] [4/1302] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.198000 612 torch/_dynamo/convert_frame.py:844] [4/1302]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.198000 612 torch/_dynamo/convert_frame.py:844] [4/1302]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.198000 612 torch/_dynamo/convert_frame.py:844] [4/1302] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.198000 612 torch/_dynamo/convert_frame.py:844] [4/1302] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.205000 612 torch/_dynamo/convert_frame.py:844] [4/1303] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.205000 612 torch/_dynamo/convert_frame.py:844] [4/1303]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.205000 612 torch/_dynamo/convert_frame.py:844] [4/1303]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.205000 612 torch/_dynamo/convert_frame.py:844] [4/1303] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.205000 612 torch/_dynamo/convert_frame.py:844] [4/1303] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.208000 612 torch/_dynamo/convert_frame.py:844] [4/1304] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.208000 612 torch/_dynamo/convert_frame.py:844] [4/1304]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.208000 612 torch/_dynamo/convert_frame.py:844] [4/1304]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.208000 612 torch/_dynamo/convert_frame.py:844] [4/1304] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.208000 612 torch/_dynamo/convert_frame.py:844] [4/1304] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.214000 612 torch/_dynamo/convert_frame.py:844] [4/1305] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.214000 612 torch/_dynamo/convert_frame.py:844] [4/1305]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.214000 612 torch/_dynamo/convert_frame.py:844] [4/1305]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.214000 612 torch/_dynamo/convert_frame.py:844] [4/1305] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.214000 612 torch/_dynamo/convert_frame.py:844] [4/1305] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.220000 612 torch/_dynamo/convert_frame.py:844] [4/1306] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.220000 612 torch/_dynamo/convert_frame.py:844] [4/1306]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.220000 612 torch/_dynamo/convert_frame.py:844] [4/1306]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.220000 612 torch/_dynamo/convert_frame.py:844] [4/1306] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.220000 612 torch/_dynamo/convert_frame.py:844] [4/1306] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.223000 612 torch/_dynamo/convert_frame.py:844] [4/1307] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.223000 612 torch/_dynamo/convert_frame.py:844] [4/1307]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.223000 612 torch/_dynamo/convert_frame.py:844] [4/1307]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.223000 612 torch/_dynamo/convert_frame.py:844] [4/1307] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.223000 612 torch/_dynamo/convert_frame.py:844] [4/1307] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.229000 612 torch/_dynamo/convert_frame.py:844] [4/1308] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.229000 612 torch/_dynamo/convert_frame.py:844] [4/1308]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.229000 612 torch/_dynamo/convert_frame.py:844] [4/1308]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.229000 612 torch/_dynamo/convert_frame.py:844] [4/1308] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.229000 612 torch/_dynamo/convert_frame.py:844] [4/1308] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.232000 612 torch/_dynamo/convert_frame.py:844] [4/1309] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.232000 612 torch/_dynamo/convert_frame.py:844] [4/1309]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.232000 612 torch/_dynamo/convert_frame.py:844] [4/1309]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.232000 612 torch/_dynamo/convert_frame.py:844] [4/1309] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.232000 612 torch/_dynamo/convert_frame.py:844] [4/1309] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10x     10 |      5.966 |      3.139 |    1.90x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.240000 612 torch/_dynamo/convert_frame.py:844] [4/1310] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.240000 612 torch/_dynamo/convert_frame.py:844] [4/1310]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.240000 612 torch/_dynamo/convert_frame.py:844] [4/1310]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.240000 612 torch/_dynamo/convert_frame.py:844] [4/1310] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.240000 612 torch/_dynamo/convert_frame.py:844] [4/1310] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.243000 612 torch/_dynamo/convert_frame.py:844] [4/1311] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.243000 612 torch/_dynamo/convert_frame.py:844] [4/1311]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.243000 612 torch/_dynamo/convert_frame.py:844] [4/1311]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.243000 612 torch/_dynamo/convert_frame.py:844] [4/1311] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.243000 612 torch/_dynamo/convert_frame.py:844] [4/1311] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.250000 612 torch/_dynamo/convert_frame.py:844] [4/1312] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.250000 612 torch/_dynamo/convert_frame.py:844] [4/1312]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.250000 612 torch/_dynamo/convert_frame.py:844] [4/1312]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.250000 612 torch/_dynamo/convert_frame.py:844] [4/1312] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.250000 612 torch/_dynamo/convert_frame.py:844] [4/1312] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.253000 612 torch/_dynamo/convert_frame.py:844] [4/1313] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.253000 612 torch/_dynamo/convert_frame.py:844] [4/1313]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.253000 612 torch/_dynamo/convert_frame.py:844] [4/1313]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.253000 612 torch/_dynamo/convert_frame.py:844] [4/1313] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.253000 612 torch/_dynamo/convert_frame.py:844] [4/1313] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.260000 612 torch/_dynamo/convert_frame.py:844] [4/1314] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.260000 612 torch/_dynamo/convert_frame.py:844] [4/1314]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.260000 612 torch/_dynamo/convert_frame.py:844] [4/1314]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.260000 612 torch/_dynamo/convert_frame.py:844] [4/1314] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.260000 612 torch/_dynamo/convert_frame.py:844] [4/1314] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.262000 612 torch/_dynamo/convert_frame.py:844] [4/1315] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.262000 612 torch/_dynamo/convert_frame.py:844] [4/1315]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.262000 612 torch/_dynamo/convert_frame.py:844] [4/1315]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.262000 612 torch/_dynamo/convert_frame.py:844] [4/1315] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.262000 612 torch/_dynamo/convert_frame.py:844] [4/1315] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.269000 612 torch/_dynamo/convert_frame.py:844] [4/1316] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.269000 612 torch/_dynamo/convert_frame.py:844] [4/1316]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.269000 612 torch/_dynamo/convert_frame.py:844] [4/1316]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.269000 612 torch/_dynamo/convert_frame.py:844] [4/1316] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.269000 612 torch/_dynamo/convert_frame.py:844] [4/1316] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.271000 612 torch/_dynamo/convert_frame.py:844] [4/1317] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.271000 612 torch/_dynamo/convert_frame.py:844] [4/1317]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.271000 612 torch/_dynamo/convert_frame.py:844] [4/1317]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.271000 612 torch/_dynamo/convert_frame.py:844] [4/1317] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.271000 612 torch/_dynamo/convert_frame.py:844] [4/1317] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.278000 612 torch/_dynamo/convert_frame.py:844] [4/1318] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.278000 612 torch/_dynamo/convert_frame.py:844] [4/1318]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.278000 612 torch/_dynamo/convert_frame.py:844] [4/1318]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.278000 612 torch/_dynamo/convert_frame.py:844] [4/1318] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.278000 612 torch/_dynamo/convert_frame.py:844] [4/1318] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.281000 612 torch/_dynamo/convert_frame.py:844] [4/1319] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.281000 612 torch/_dynamo/convert_frame.py:844] [4/1319]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.281000 612 torch/_dynamo/convert_frame.py:844] [4/1319]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.281000 612 torch/_dynamo/convert_frame.py:844] [4/1319] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.281000 612 torch/_dynamo/convert_frame.py:844] [4/1319] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.288000 612 torch/_dynamo/convert_frame.py:844] [4/1320] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.288000 612 torch/_dynamo/convert_frame.py:844] [4/1320]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.288000 612 torch/_dynamo/convert_frame.py:844] [4/1320]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.288000 612 torch/_dynamo/convert_frame.py:844] [4/1320] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.288000 612 torch/_dynamo/convert_frame.py:844] [4/1320] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.297000 612 torch/_dynamo/convert_frame.py:844] [4/1321] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.297000 612 torch/_dynamo/convert_frame.py:844] [4/1321]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.297000 612 torch/_dynamo/convert_frame.py:844] [4/1321]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.297000 612 torch/_dynamo/convert_frame.py:844] [4/1321] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.297000 612 torch/_dynamo/convert_frame.py:844] [4/1321] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.301000 612 torch/_dynamo/convert_frame.py:844] [4/1322] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.301000 612 torch/_dynamo/convert_frame.py:844] [4/1322]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.301000 612 torch/_dynamo/convert_frame.py:844] [4/1322]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.301000 612 torch/_dynamo/convert_frame.py:844] [4/1322] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.301000 612 torch/_dynamo/convert_frame.py:844] [4/1322] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.309000 612 torch/_dynamo/convert_frame.py:844] [4/1323] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.309000 612 torch/_dynamo/convert_frame.py:844] [4/1323]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.309000 612 torch/_dynamo/convert_frame.py:844] [4/1323]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.309000 612 torch/_dynamo/convert_frame.py:844] [4/1323] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.309000 612 torch/_dynamo/convert_frame.py:844] [4/1323] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.318000 612 torch/_dynamo/convert_frame.py:844] [4/1324] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.318000 612 torch/_dynamo/convert_frame.py:844] [4/1324]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.318000 612 torch/_dynamo/convert_frame.py:844] [4/1324]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.318000 612 torch/_dynamo/convert_frame.py:844] [4/1324] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.318000 612 torch/_dynamo/convert_frame.py:844] [4/1324] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.325000 612 torch/_dynamo/convert_frame.py:844] [4/1325] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.325000 612 torch/_dynamo/convert_frame.py:844] [4/1325]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.325000 612 torch/_dynamo/convert_frame.py:844] [4/1325]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.325000 612 torch/_dynamo/convert_frame.py:844] [4/1325] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.325000 612 torch/_dynamo/convert_frame.py:844] [4/1325] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.330000 612 torch/_dynamo/convert_frame.py:844] [4/1326] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.330000 612 torch/_dynamo/convert_frame.py:844] [4/1326]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.330000 612 torch/_dynamo/convert_frame.py:844] [4/1326]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.330000 612 torch/_dynamo/convert_frame.py:844] [4/1326] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.330000 612 torch/_dynamo/convert_frame.py:844] [4/1326] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.336000 612 torch/_dynamo/convert_frame.py:844] [4/1327] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.336000 612 torch/_dynamo/convert_frame.py:844] [4/1327]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.336000 612 torch/_dynamo/convert_frame.py:844] [4/1327]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.336000 612 torch/_dynamo/convert_frame.py:844] [4/1327] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.336000 612 torch/_dynamo/convert_frame.py:844] [4/1327] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.340000 612 torch/_dynamo/convert_frame.py:844] [4/1328] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.340000 612 torch/_dynamo/convert_frame.py:844] [4/1328]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.340000 612 torch/_dynamo/convert_frame.py:844] [4/1328]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.340000 612 torch/_dynamo/convert_frame.py:844] [4/1328] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.340000 612 torch/_dynamo/convert_frame.py:844] [4/1328] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.344000 612 torch/_dynamo/convert_frame.py:844] [4/1329] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.344000 612 torch/_dynamo/convert_frame.py:844] [4/1329]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.344000 612 torch/_dynamo/convert_frame.py:844] [4/1329]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.344000 612 torch/_dynamo/convert_frame.py:844] [4/1329] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.344000 612 torch/_dynamo/convert_frame.py:844] [4/1329] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.347000 612 torch/_dynamo/convert_frame.py:844] [4/1330] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.347000 612 torch/_dynamo/convert_frame.py:844] [4/1330]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.347000 612 torch/_dynamo/convert_frame.py:844] [4/1330]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.347000 612 torch/_dynamo/convert_frame.py:844] [4/1330] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.347000 612 torch/_dynamo/convert_frame.py:844] [4/1330] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.350000 612 torch/_dynamo/convert_frame.py:844] [4/1331] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.350000 612 torch/_dynamo/convert_frame.py:844] [4/1331]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.350000 612 torch/_dynamo/convert_frame.py:844] [4/1331]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.350000 612 torch/_dynamo/convert_frame.py:844] [4/1331] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.350000 612 torch/_dynamo/convert_frame.py:844] [4/1331] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.354000 612 torch/_dynamo/convert_frame.py:844] [4/1332] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.354000 612 torch/_dynamo/convert_frame.py:844] [4/1332]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.354000 612 torch/_dynamo/convert_frame.py:844] [4/1332]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.354000 612 torch/_dynamo/convert_frame.py:844] [4/1332] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.354000 612 torch/_dynamo/convert_frame.py:844] [4/1332] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.359000 612 torch/_dynamo/convert_frame.py:844] [4/1333] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.359000 612 torch/_dynamo/convert_frame.py:844] [4/1333]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.359000 612 torch/_dynamo/convert_frame.py:844] [4/1333]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.359000 612 torch/_dynamo/convert_frame.py:844] [4/1333] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.359000 612 torch/_dynamo/convert_frame.py:844] [4/1333] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.366000 612 torch/_dynamo/convert_frame.py:844] [4/1334] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.366000 612 torch/_dynamo/convert_frame.py:844] [4/1334]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.366000 612 torch/_dynamo/convert_frame.py:844] [4/1334]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.366000 612 torch/_dynamo/convert_frame.py:844] [4/1334] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.366000 612 torch/_dynamo/convert_frame.py:844] [4/1334] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.371000 612 torch/_dynamo/convert_frame.py:844] [4/1335] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.371000 612 torch/_dynamo/convert_frame.py:844] [4/1335]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.371000 612 torch/_dynamo/convert_frame.py:844] [4/1335]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.371000 612 torch/_dynamo/convert_frame.py:844] [4/1335] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.371000 612 torch/_dynamo/convert_frame.py:844] [4/1335] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.374000 612 torch/_dynamo/convert_frame.py:844] [4/1336] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.374000 612 torch/_dynamo/convert_frame.py:844] [4/1336]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.374000 612 torch/_dynamo/convert_frame.py:844] [4/1336]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.374000 612 torch/_dynamo/convert_frame.py:844] [4/1336] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.374000 612 torch/_dynamo/convert_frame.py:844] [4/1336] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.378000 612 torch/_dynamo/convert_frame.py:844] [4/1337] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.378000 612 torch/_dynamo/convert_frame.py:844] [4/1337]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.378000 612 torch/_dynamo/convert_frame.py:844] [4/1337]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.378000 612 torch/_dynamo/convert_frame.py:844] [4/1337] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.378000 612 torch/_dynamo/convert_frame.py:844] [4/1337] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.385000 612 torch/_dynamo/convert_frame.py:844] [4/1338] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.385000 612 torch/_dynamo/convert_frame.py:844] [4/1338]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.385000 612 torch/_dynamo/convert_frame.py:844] [4/1338]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.385000 612 torch/_dynamo/convert_frame.py:844] [4/1338] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.385000 612 torch/_dynamo/convert_frame.py:844] [4/1338] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.387000 612 torch/_dynamo/convert_frame.py:844] [4/1339] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.387000 612 torch/_dynamo/convert_frame.py:844] [4/1339]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.387000 612 torch/_dynamo/convert_frame.py:844] [4/1339]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.387000 612 torch/_dynamo/convert_frame.py:844] [4/1339] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.387000 612 torch/_dynamo/convert_frame.py:844] [4/1339] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.395000 612 torch/_dynamo/convert_frame.py:844] [4/1340] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.395000 612 torch/_dynamo/convert_frame.py:844] [4/1340]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.395000 612 torch/_dynamo/convert_frame.py:844] [4/1340]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.395000 612 torch/_dynamo/convert_frame.py:844] [4/1340] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.395000 612 torch/_dynamo/convert_frame.py:844] [4/1340] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.402000 612 torch/_dynamo/convert_frame.py:844] [4/1341] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.402000 612 torch/_dynamo/convert_frame.py:844] [4/1341]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.402000 612 torch/_dynamo/convert_frame.py:844] [4/1341]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.402000 612 torch/_dynamo/convert_frame.py:844] [4/1341] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.402000 612 torch/_dynamo/convert_frame.py:844] [4/1341] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.406000 612 torch/_dynamo/convert_frame.py:844] [4/1342] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.406000 612 torch/_dynamo/convert_frame.py:844] [4/1342]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.406000 612 torch/_dynamo/convert_frame.py:844] [4/1342]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.406000 612 torch/_dynamo/convert_frame.py:844] [4/1342] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.406000 612 torch/_dynamo/convert_frame.py:844] [4/1342] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.411000 612 torch/_dynamo/convert_frame.py:844] [4/1343] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.411000 612 torch/_dynamo/convert_frame.py:844] [4/1343]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.411000 612 torch/_dynamo/convert_frame.py:844] [4/1343]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.411000 612 torch/_dynamo/convert_frame.py:844] [4/1343] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.411000 612 torch/_dynamo/convert_frame.py:844] [4/1343] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.414000 612 torch/_dynamo/convert_frame.py:844] [4/1344] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.414000 612 torch/_dynamo/convert_frame.py:844] [4/1344]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.414000 612 torch/_dynamo/convert_frame.py:844] [4/1344]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.414000 612 torch/_dynamo/convert_frame.py:844] [4/1344] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.414000 612 torch/_dynamo/convert_frame.py:844] [4/1344] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.421000 612 torch/_dynamo/convert_frame.py:844] [4/1345] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.421000 612 torch/_dynamo/convert_frame.py:844] [4/1345]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.421000 612 torch/_dynamo/convert_frame.py:844] [4/1345]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.421000 612 torch/_dynamo/convert_frame.py:844] [4/1345] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.421000 612 torch/_dynamo/convert_frame.py:844] [4/1345] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.428000 612 torch/_dynamo/convert_frame.py:844] [4/1346] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.428000 612 torch/_dynamo/convert_frame.py:844] [4/1346]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.428000 612 torch/_dynamo/convert_frame.py:844] [4/1346]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.428000 612 torch/_dynamo/convert_frame.py:844] [4/1346] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.428000 612 torch/_dynamo/convert_frame.py:844] [4/1346] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.436000 612 torch/_dynamo/convert_frame.py:844] [4/1347] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.436000 612 torch/_dynamo/convert_frame.py:844] [4/1347]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.436000 612 torch/_dynamo/convert_frame.py:844] [4/1347]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.436000 612 torch/_dynamo/convert_frame.py:844] [4/1347] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.436000 612 torch/_dynamo/convert_frame.py:844] [4/1347] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.442000 612 torch/_dynamo/convert_frame.py:844] [4/1348] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.442000 612 torch/_dynamo/convert_frame.py:844] [4/1348]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.442000 612 torch/_dynamo/convert_frame.py:844] [4/1348]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.442000 612 torch/_dynamo/convert_frame.py:844] [4/1348] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.442000 612 torch/_dynamo/convert_frame.py:844] [4/1348] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.447000 612 torch/_dynamo/convert_frame.py:844] [4/1349] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.447000 612 torch/_dynamo/convert_frame.py:844] [4/1349]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.447000 612 torch/_dynamo/convert_frame.py:844] [4/1349]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.447000 612 torch/_dynamo/convert_frame.py:844] [4/1349] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.447000 612 torch/_dynamo/convert_frame.py:844] [4/1349] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.452000 612 torch/_dynamo/convert_frame.py:844] [4/1350] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.452000 612 torch/_dynamo/convert_frame.py:844] [4/1350]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.452000 612 torch/_dynamo/convert_frame.py:844] [4/1350]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.452000 612 torch/_dynamo/convert_frame.py:844] [4/1350] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.452000 612 torch/_dynamo/convert_frame.py:844] [4/1350] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.459000 612 torch/_dynamo/convert_frame.py:844] [4/1351] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.459000 612 torch/_dynamo/convert_frame.py:844] [4/1351]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.459000 612 torch/_dynamo/convert_frame.py:844] [4/1351]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.459000 612 torch/_dynamo/convert_frame.py:844] [4/1351] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.459000 612 torch/_dynamo/convert_frame.py:844] [4/1351] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.464000 612 torch/_dynamo/convert_frame.py:844] [4/1352] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.464000 612 torch/_dynamo/convert_frame.py:844] [4/1352]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.464000 612 torch/_dynamo/convert_frame.py:844] [4/1352]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.464000 612 torch/_dynamo/convert_frame.py:844] [4/1352] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.464000 612 torch/_dynamo/convert_frame.py:844] [4/1352] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.472000 612 torch/_dynamo/convert_frame.py:844] [4/1353] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.472000 612 torch/_dynamo/convert_frame.py:844] [4/1353]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.472000 612 torch/_dynamo/convert_frame.py:844] [4/1353]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.472000 612 torch/_dynamo/convert_frame.py:844] [4/1353] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.472000 612 torch/_dynamo/convert_frame.py:844] [4/1353] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.479000 612 torch/_dynamo/convert_frame.py:844] [4/1354] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.479000 612 torch/_dynamo/convert_frame.py:844] [4/1354]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.479000 612 torch/_dynamo/convert_frame.py:844] [4/1354]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.479000 612 torch/_dynamo/convert_frame.py:844] [4/1354] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.479000 612 torch/_dynamo/convert_frame.py:844] [4/1354] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.482000 612 torch/_dynamo/convert_frame.py:844] [4/1355] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.482000 612 torch/_dynamo/convert_frame.py:844] [4/1355]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.482000 612 torch/_dynamo/convert_frame.py:844] [4/1355]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.482000 612 torch/_dynamo/convert_frame.py:844] [4/1355] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.482000 612 torch/_dynamo/convert_frame.py:844] [4/1355] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.491000 612 torch/_dynamo/convert_frame.py:844] [4/1356] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.491000 612 torch/_dynamo/convert_frame.py:844] [4/1356]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.491000 612 torch/_dynamo/convert_frame.py:844] [4/1356]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.491000 612 torch/_dynamo/convert_frame.py:844] [4/1356] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.491000 612 torch/_dynamo/convert_frame.py:844] [4/1356] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.495000 612 torch/_dynamo/convert_frame.py:844] [4/1357] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.495000 612 torch/_dynamo/convert_frame.py:844] [4/1357]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.495000 612 torch/_dynamo/convert_frame.py:844] [4/1357]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.495000 612 torch/_dynamo/convert_frame.py:844] [4/1357] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.495000 612 torch/_dynamo/convert_frame.py:844] [4/1357] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.503000 612 torch/_dynamo/convert_frame.py:844] [4/1358] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.503000 612 torch/_dynamo/convert_frame.py:844] [4/1358]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.503000 612 torch/_dynamo/convert_frame.py:844] [4/1358]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.503000 612 torch/_dynamo/convert_frame.py:844] [4/1358] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.503000 612 torch/_dynamo/convert_frame.py:844] [4/1358] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.510000 612 torch/_dynamo/convert_frame.py:844] [4/1359] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.510000 612 torch/_dynamo/convert_frame.py:844] [4/1359]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.510000 612 torch/_dynamo/convert_frame.py:844] [4/1359]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.510000 612 torch/_dynamo/convert_frame.py:844] [4/1359] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.510000 612 torch/_dynamo/convert_frame.py:844] [4/1359] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.515000 612 torch/_dynamo/convert_frame.py:844] [4/1360] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.515000 612 torch/_dynamo/convert_frame.py:844] [4/1360]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.515000 612 torch/_dynamo/convert_frame.py:844] [4/1360]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.515000 612 torch/_dynamo/convert_frame.py:844] [4/1360] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.515000 612 torch/_dynamo/convert_frame.py:844] [4/1360] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.521000 612 torch/_dynamo/convert_frame.py:844] [4/1361] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.521000 612 torch/_dynamo/convert_frame.py:844] [4/1361]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.521000 612 torch/_dynamo/convert_frame.py:844] [4/1361]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.521000 612 torch/_dynamo/convert_frame.py:844] [4/1361] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.521000 612 torch/_dynamo/convert_frame.py:844] [4/1361] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.528000 612 torch/_dynamo/convert_frame.py:844] [4/1362] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.528000 612 torch/_dynamo/convert_frame.py:844] [4/1362]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.528000 612 torch/_dynamo/convert_frame.py:844] [4/1362]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.528000 612 torch/_dynamo/convert_frame.py:844] [4/1362] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.528000 612 torch/_dynamo/convert_frame.py:844] [4/1362] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.534000 612 torch/_dynamo/convert_frame.py:844] [4/1363] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.534000 612 torch/_dynamo/convert_frame.py:844] [4/1363]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.534000 612 torch/_dynamo/convert_frame.py:844] [4/1363]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.534000 612 torch/_dynamo/convert_frame.py:844] [4/1363] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.534000 612 torch/_dynamo/convert_frame.py:844] [4/1363] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.542000 612 torch/_dynamo/convert_frame.py:844] [4/1364] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.542000 612 torch/_dynamo/convert_frame.py:844] [4/1364]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.542000 612 torch/_dynamo/convert_frame.py:844] [4/1364]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.542000 612 torch/_dynamo/convert_frame.py:844] [4/1364] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.542000 612 torch/_dynamo/convert_frame.py:844] [4/1364] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.549000 612 torch/_dynamo/convert_frame.py:844] [4/1365] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.549000 612 torch/_dynamo/convert_frame.py:844] [4/1365]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.549000 612 torch/_dynamo/convert_frame.py:844] [4/1365]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.549000 612 torch/_dynamo/convert_frame.py:844] [4/1365] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.549000 612 torch/_dynamo/convert_frame.py:844] [4/1365] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.555000 612 torch/_dynamo/convert_frame.py:844] [4/1366] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.555000 612 torch/_dynamo/convert_frame.py:844] [4/1366]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.555000 612 torch/_dynamo/convert_frame.py:844] [4/1366]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.555000 612 torch/_dynamo/convert_frame.py:844] [4/1366] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.555000 612 torch/_dynamo/convert_frame.py:844] [4/1366] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.563000 612 torch/_dynamo/convert_frame.py:844] [4/1367] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.563000 612 torch/_dynamo/convert_frame.py:844] [4/1367]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.563000 612 torch/_dynamo/convert_frame.py:844] [4/1367]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.563000 612 torch/_dynamo/convert_frame.py:844] [4/1367] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.563000 612 torch/_dynamo/convert_frame.py:844] [4/1367] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.569000 612 torch/_dynamo/convert_frame.py:844] [4/1368] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.569000 612 torch/_dynamo/convert_frame.py:844] [4/1368]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.569000 612 torch/_dynamo/convert_frame.py:844] [4/1368]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.569000 612 torch/_dynamo/convert_frame.py:844] [4/1368] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.569000 612 torch/_dynamo/convert_frame.py:844] [4/1368] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.578000 612 torch/_dynamo/convert_frame.py:844] [4/1369] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.578000 612 torch/_dynamo/convert_frame.py:844] [4/1369]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.578000 612 torch/_dynamo/convert_frame.py:844] [4/1369]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.578000 612 torch/_dynamo/convert_frame.py:844] [4/1369] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.578000 612 torch/_dynamo/convert_frame.py:844] [4/1369] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.590000 612 torch/_dynamo/convert_frame.py:844] [4/1370] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.590000 612 torch/_dynamo/convert_frame.py:844] [4/1370]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.590000 612 torch/_dynamo/convert_frame.py:844] [4/1370]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.590000 612 torch/_dynamo/convert_frame.py:844] [4/1370] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.590000 612 torch/_dynamo/convert_frame.py:844] [4/1370] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.595000 612 torch/_dynamo/convert_frame.py:844] [4/1371] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.595000 612 torch/_dynamo/convert_frame.py:844] [4/1371]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.595000 612 torch/_dynamo/convert_frame.py:844] [4/1371]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.595000 612 torch/_dynamo/convert_frame.py:844] [4/1371] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.595000 612 torch/_dynamo/convert_frame.py:844] [4/1371] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.603000 612 torch/_dynamo/convert_frame.py:844] [4/1372] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.603000 612 torch/_dynamo/convert_frame.py:844] [4/1372]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.603000 612 torch/_dynamo/convert_frame.py:844] [4/1372]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.603000 612 torch/_dynamo/convert_frame.py:844] [4/1372] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.603000 612 torch/_dynamo/convert_frame.py:844] [4/1372] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.612000 612 torch/_dynamo/convert_frame.py:844] [4/1373] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.612000 612 torch/_dynamo/convert_frame.py:844] [4/1373]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.612000 612 torch/_dynamo/convert_frame.py:844] [4/1373]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.612000 612 torch/_dynamo/convert_frame.py:844] [4/1373] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.612000 612 torch/_dynamo/convert_frame.py:844] [4/1373] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.624000 612 torch/_dynamo/convert_frame.py:844] [4/1374] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.624000 612 torch/_dynamo/convert_frame.py:844] [4/1374]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.624000 612 torch/_dynamo/convert_frame.py:844] [4/1374]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.624000 612 torch/_dynamo/convert_frame.py:844] [4/1374] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.624000 612 torch/_dynamo/convert_frame.py:844] [4/1374] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.633000 612 torch/_dynamo/convert_frame.py:844] [4/1375] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.633000 612 torch/_dynamo/convert_frame.py:844] [4/1375]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.633000 612 torch/_dynamo/convert_frame.py:844] [4/1375]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.633000 612 torch/_dynamo/convert_frame.py:844] [4/1375] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.633000 612 torch/_dynamo/convert_frame.py:844] [4/1375] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.641000 612 torch/_dynamo/convert_frame.py:844] [4/1376] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.641000 612 torch/_dynamo/convert_frame.py:844] [4/1376]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.641000 612 torch/_dynamo/convert_frame.py:844] [4/1376]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.641000 612 torch/_dynamo/convert_frame.py:844] [4/1376] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.641000 612 torch/_dynamo/convert_frame.py:844] [4/1376] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.648000 612 torch/_dynamo/convert_frame.py:844] [4/1377] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.648000 612 torch/_dynamo/convert_frame.py:844] [4/1377]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.648000 612 torch/_dynamo/convert_frame.py:844] [4/1377]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.648000 612 torch/_dynamo/convert_frame.py:844] [4/1377] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.648000 612 torch/_dynamo/convert_frame.py:844] [4/1377] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.658000 612 torch/_dynamo/convert_frame.py:844] [4/1378] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.658000 612 torch/_dynamo/convert_frame.py:844] [4/1378]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.658000 612 torch/_dynamo/convert_frame.py:844] [4/1378]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.658000 612 torch/_dynamo/convert_frame.py:844] [4/1378] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.658000 612 torch/_dynamo/convert_frame.py:844] [4/1378] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.668000 612 torch/_dynamo/convert_frame.py:844] [4/1379] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.668000 612 torch/_dynamo/convert_frame.py:844] [4/1379]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.668000 612 torch/_dynamo/convert_frame.py:844] [4/1379]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.668000 612 torch/_dynamo/convert_frame.py:844] [4/1379] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.668000 612 torch/_dynamo/convert_frame.py:844] [4/1379] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.679000 612 torch/_dynamo/convert_frame.py:844] [4/1380] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.679000 612 torch/_dynamo/convert_frame.py:844] [4/1380]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.679000 612 torch/_dynamo/convert_frame.py:844] [4/1380]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.679000 612 torch/_dynamo/convert_frame.py:844] [4/1380] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.679000 612 torch/_dynamo/convert_frame.py:844] [4/1380] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.689000 612 torch/_dynamo/convert_frame.py:844] [4/1381] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.689000 612 torch/_dynamo/convert_frame.py:844] [4/1381]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.689000 612 torch/_dynamo/convert_frame.py:844] [4/1381]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.689000 612 torch/_dynamo/convert_frame.py:844] [4/1381] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.689000 612 torch/_dynamo/convert_frame.py:844] [4/1381] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.695000 612 torch/_dynamo/convert_frame.py:844] [4/1382] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.695000 612 torch/_dynamo/convert_frame.py:844] [4/1382]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.695000 612 torch/_dynamo/convert_frame.py:844] [4/1382]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.695000 612 torch/_dynamo/convert_frame.py:844] [4/1382] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.695000 612 torch/_dynamo/convert_frame.py:844] [4/1382] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.702000 612 torch/_dynamo/convert_frame.py:844] [4/1383] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.702000 612 torch/_dynamo/convert_frame.py:844] [4/1383]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.702000 612 torch/_dynamo/convert_frame.py:844] [4/1383]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.702000 612 torch/_dynamo/convert_frame.py:844] [4/1383] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.702000 612 torch/_dynamo/convert_frame.py:844] [4/1383] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.708000 612 torch/_dynamo/convert_frame.py:844] [4/1384] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.708000 612 torch/_dynamo/convert_frame.py:844] [4/1384]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.708000 612 torch/_dynamo/convert_frame.py:844] [4/1384]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.708000 612 torch/_dynamo/convert_frame.py:844] [4/1384] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.708000 612 torch/_dynamo/convert_frame.py:844] [4/1384] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.713000 612 torch/_dynamo/convert_frame.py:844] [4/1385] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.713000 612 torch/_dynamo/convert_frame.py:844] [4/1385]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.713000 612 torch/_dynamo/convert_frame.py:844] [4/1385]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.713000 612 torch/_dynamo/convert_frame.py:844] [4/1385] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.713000 612 torch/_dynamo/convert_frame.py:844] [4/1385] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.718000 612 torch/_dynamo/convert_frame.py:844] [4/1386] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.718000 612 torch/_dynamo/convert_frame.py:844] [4/1386]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.718000 612 torch/_dynamo/convert_frame.py:844] [4/1386]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.718000 612 torch/_dynamo/convert_frame.py:844] [4/1386] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.718000 612 torch/_dynamo/convert_frame.py:844] [4/1386] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.724000 612 torch/_dynamo/convert_frame.py:844] [4/1387] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.724000 612 torch/_dynamo/convert_frame.py:844] [4/1387]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.724000 612 torch/_dynamo/convert_frame.py:844] [4/1387]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.724000 612 torch/_dynamo/convert_frame.py:844] [4/1387] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.724000 612 torch/_dynamo/convert_frame.py:844] [4/1387] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.731000 612 torch/_dynamo/convert_frame.py:844] [4/1388] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.731000 612 torch/_dynamo/convert_frame.py:844] [4/1388]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.731000 612 torch/_dynamo/convert_frame.py:844] [4/1388]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.731000 612 torch/_dynamo/convert_frame.py:844] [4/1388] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.731000 612 torch/_dynamo/convert_frame.py:844] [4/1388] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.737000 612 torch/_dynamo/convert_frame.py:844] [4/1389] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.737000 612 torch/_dynamo/convert_frame.py:844] [4/1389]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.737000 612 torch/_dynamo/convert_frame.py:844] [4/1389]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.737000 612 torch/_dynamo/convert_frame.py:844] [4/1389] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.737000 612 torch/_dynamo/convert_frame.py:844] [4/1389] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.742000 612 torch/_dynamo/convert_frame.py:844] [4/1390] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.742000 612 torch/_dynamo/convert_frame.py:844] [4/1390]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.742000 612 torch/_dynamo/convert_frame.py:844] [4/1390]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.742000 612 torch/_dynamo/convert_frame.py:844] [4/1390] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.742000 612 torch/_dynamo/convert_frame.py:844] [4/1390] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.746000 612 torch/_dynamo/convert_frame.py:844] [4/1391] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.746000 612 torch/_dynamo/convert_frame.py:844] [4/1391]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.746000 612 torch/_dynamo/convert_frame.py:844] [4/1391]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.746000 612 torch/_dynamo/convert_frame.py:844] [4/1391] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.746000 612 torch/_dynamo/convert_frame.py:844] [4/1391] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.751000 612 torch/_dynamo/convert_frame.py:844] [4/1392] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.751000 612 torch/_dynamo/convert_frame.py:844] [4/1392]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.751000 612 torch/_dynamo/convert_frame.py:844] [4/1392]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.751000 612 torch/_dynamo/convert_frame.py:844] [4/1392] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.751000 612 torch/_dynamo/convert_frame.py:844] [4/1392] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.757000 612 torch/_dynamo/convert_frame.py:844] [4/1393] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.757000 612 torch/_dynamo/convert_frame.py:844] [4/1393]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.757000 612 torch/_dynamo/convert_frame.py:844] [4/1393]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.757000 612 torch/_dynamo/convert_frame.py:844] [4/1393] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.757000 612 torch/_dynamo/convert_frame.py:844] [4/1393] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.763000 612 torch/_dynamo/convert_frame.py:844] [4/1394] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.763000 612 torch/_dynamo/convert_frame.py:844] [4/1394]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.763000 612 torch/_dynamo/convert_frame.py:844] [4/1394]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.763000 612 torch/_dynamo/convert_frame.py:844] [4/1394] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.763000 612 torch/_dynamo/convert_frame.py:844] [4/1394] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.769000 612 torch/_dynamo/convert_frame.py:844] [4/1395] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.769000 612 torch/_dynamo/convert_frame.py:844] [4/1395]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.769000 612 torch/_dynamo/convert_frame.py:844] [4/1395]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.769000 612 torch/_dynamo/convert_frame.py:844] [4/1395] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.769000 612 torch/_dynamo/convert_frame.py:844] [4/1395] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.774000 612 torch/_dynamo/convert_frame.py:844] [4/1396] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.774000 612 torch/_dynamo/convert_frame.py:844] [4/1396]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.774000 612 torch/_dynamo/convert_frame.py:844] [4/1396]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.774000 612 torch/_dynamo/convert_frame.py:844] [4/1396] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.774000 612 torch/_dynamo/convert_frame.py:844] [4/1396] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.780000 612 torch/_dynamo/convert_frame.py:844] [4/1397] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.780000 612 torch/_dynamo/convert_frame.py:844] [4/1397]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.780000 612 torch/_dynamo/convert_frame.py:844] [4/1397]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.780000 612 torch/_dynamo/convert_frame.py:844] [4/1397] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.780000 612 torch/_dynamo/convert_frame.py:844] [4/1397] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.785000 612 torch/_dynamo/convert_frame.py:844] [4/1398] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.785000 612 torch/_dynamo/convert_frame.py:844] [4/1398]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.785000 612 torch/_dynamo/convert_frame.py:844] [4/1398]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.785000 612 torch/_dynamo/convert_frame.py:844] [4/1398] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.785000 612 torch/_dynamo/convert_frame.py:844] [4/1398] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.790000 612 torch/_dynamo/convert_frame.py:844] [4/1399] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.790000 612 torch/_dynamo/convert_frame.py:844] [4/1399]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.790000 612 torch/_dynamo/convert_frame.py:844] [4/1399]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.790000 612 torch/_dynamo/convert_frame.py:844] [4/1399] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.790000 612 torch/_dynamo/convert_frame.py:844] [4/1399] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.793000 612 torch/_dynamo/convert_frame.py:844] [4/1400] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.793000 612 torch/_dynamo/convert_frame.py:844] [4/1400]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.793000 612 torch/_dynamo/convert_frame.py:844] [4/1400]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.793000 612 torch/_dynamo/convert_frame.py:844] [4/1400] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.793000 612 torch/_dynamo/convert_frame.py:844] [4/1400] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.796000 612 torch/_dynamo/convert_frame.py:844] [4/1401] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.796000 612 torch/_dynamo/convert_frame.py:844] [4/1401]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.796000 612 torch/_dynamo/convert_frame.py:844] [4/1401]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.796000 612 torch/_dynamo/convert_frame.py:844] [4/1401] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.796000 612 torch/_dynamo/convert_frame.py:844] [4/1401] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.799000 612 torch/_dynamo/convert_frame.py:844] [4/1402] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.799000 612 torch/_dynamo/convert_frame.py:844] [4/1402]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.799000 612 torch/_dynamo/convert_frame.py:844] [4/1402]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.799000 612 torch/_dynamo/convert_frame.py:844] [4/1402] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.799000 612 torch/_dynamo/convert_frame.py:844] [4/1402] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.802000 612 torch/_dynamo/convert_frame.py:844] [4/1403] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.802000 612 torch/_dynamo/convert_frame.py:844] [4/1403]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.802000 612 torch/_dynamo/convert_frame.py:844] [4/1403]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.802000 612 torch/_dynamo/convert_frame.py:844] [4/1403] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.802000 612 torch/_dynamo/convert_frame.py:844] [4/1403] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.805000 612 torch/_dynamo/convert_frame.py:844] [4/1404] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.805000 612 torch/_dynamo/convert_frame.py:844] [4/1404]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.805000 612 torch/_dynamo/convert_frame.py:844] [4/1404]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.805000 612 torch/_dynamo/convert_frame.py:844] [4/1404] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.805000 612 torch/_dynamo/convert_frame.py:844] [4/1404] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.809000 612 torch/_dynamo/convert_frame.py:844] [4/1405] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.809000 612 torch/_dynamo/convert_frame.py:844] [4/1405]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.809000 612 torch/_dynamo/convert_frame.py:844] [4/1405]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.809000 612 torch/_dynamo/convert_frame.py:844] [4/1405] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.809000 612 torch/_dynamo/convert_frame.py:844] [4/1405] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.812000 612 torch/_dynamo/convert_frame.py:844] [4/1406] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.812000 612 torch/_dynamo/convert_frame.py:844] [4/1406]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.812000 612 torch/_dynamo/convert_frame.py:844] [4/1406]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.812000 612 torch/_dynamo/convert_frame.py:844] [4/1406] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.812000 612 torch/_dynamo/convert_frame.py:844] [4/1406] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.814000 612 torch/_dynamo/convert_frame.py:844] [4/1407] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.814000 612 torch/_dynamo/convert_frame.py:844] [4/1407]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.814000 612 torch/_dynamo/convert_frame.py:844] [4/1407]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.814000 612 torch/_dynamo/convert_frame.py:844] [4/1407] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.814000 612 torch/_dynamo/convert_frame.py:844] [4/1407] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.818000 612 torch/_dynamo/convert_frame.py:844] [4/1408] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.818000 612 torch/_dynamo/convert_frame.py:844] [4/1408]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.818000 612 torch/_dynamo/convert_frame.py:844] [4/1408]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.818000 612 torch/_dynamo/convert_frame.py:844] [4/1408] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.818000 612 torch/_dynamo/convert_frame.py:844] [4/1408] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.821000 612 torch/_dynamo/convert_frame.py:844] [4/1409] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.821000 612 torch/_dynamo/convert_frame.py:844] [4/1409]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.821000 612 torch/_dynamo/convert_frame.py:844] [4/1409]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.821000 612 torch/_dynamo/convert_frame.py:844] [4/1409] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.821000 612 torch/_dynamo/convert_frame.py:844] [4/1409] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.823000 612 torch/_dynamo/convert_frame.py:844] [4/1410] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.823000 612 torch/_dynamo/convert_frame.py:844] [4/1410]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.823000 612 torch/_dynamo/convert_frame.py:844] [4/1410]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.823000 612 torch/_dynamo/convert_frame.py:844] [4/1410] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.823000 612 torch/_dynamo/convert_frame.py:844] [4/1410] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.827000 612 torch/_dynamo/convert_frame.py:844] [4/1411] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.827000 612 torch/_dynamo/convert_frame.py:844] [4/1411]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.827000 612 torch/_dynamo/convert_frame.py:844] [4/1411]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.827000 612 torch/_dynamo/convert_frame.py:844] [4/1411] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.827000 612 torch/_dynamo/convert_frame.py:844] [4/1411] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.829000 612 torch/_dynamo/convert_frame.py:844] [4/1412] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.829000 612 torch/_dynamo/convert_frame.py:844] [4/1412]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.829000 612 torch/_dynamo/convert_frame.py:844] [4/1412]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.829000 612 torch/_dynamo/convert_frame.py:844] [4/1412] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.829000 612 torch/_dynamo/convert_frame.py:844] [4/1412] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.832000 612 torch/_dynamo/convert_frame.py:844] [4/1413] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.832000 612 torch/_dynamo/convert_frame.py:844] [4/1413]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.832000 612 torch/_dynamo/convert_frame.py:844] [4/1413]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.832000 612 torch/_dynamo/convert_frame.py:844] [4/1413] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.832000 612 torch/_dynamo/convert_frame.py:844] [4/1413] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.834000 612 torch/_dynamo/convert_frame.py:844] [4/1414] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.834000 612 torch/_dynamo/convert_frame.py:844] [4/1414]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.834000 612 torch/_dynamo/convert_frame.py:844] [4/1414]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.834000 612 torch/_dynamo/convert_frame.py:844] [4/1414] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.834000 612 torch/_dynamo/convert_frame.py:844] [4/1414] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.838000 612 torch/_dynamo/convert_frame.py:844] [4/1415] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.838000 612 torch/_dynamo/convert_frame.py:844] [4/1415]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.838000 612 torch/_dynamo/convert_frame.py:844] [4/1415]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.838000 612 torch/_dynamo/convert_frame.py:844] [4/1415] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.838000 612 torch/_dynamo/convert_frame.py:844] [4/1415] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.841000 612 torch/_dynamo/convert_frame.py:844] [4/1416] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.841000 612 torch/_dynamo/convert_frame.py:844] [4/1416]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.841000 612 torch/_dynamo/convert_frame.py:844] [4/1416]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.841000 612 torch/_dynamo/convert_frame.py:844] [4/1416] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.841000 612 torch/_dynamo/convert_frame.py:844] [4/1416] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.844000 612 torch/_dynamo/convert_frame.py:844] [4/1417] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.844000 612 torch/_dynamo/convert_frame.py:844] [4/1417]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.844000 612 torch/_dynamo/convert_frame.py:844] [4/1417]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.844000 612 torch/_dynamo/convert_frame.py:844] [4/1417] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.844000 612 torch/_dynamo/convert_frame.py:844] [4/1417] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.846000 612 torch/_dynamo/convert_frame.py:844] [4/1418] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.846000 612 torch/_dynamo/convert_frame.py:844] [4/1418]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.846000 612 torch/_dynamo/convert_frame.py:844] [4/1418]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.846000 612 torch/_dynamo/convert_frame.py:844] [4/1418] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.846000 612 torch/_dynamo/convert_frame.py:844] [4/1418] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.849000 612 torch/_dynamo/convert_frame.py:844] [4/1419] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.849000 612 torch/_dynamo/convert_frame.py:844] [4/1419]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.849000 612 torch/_dynamo/convert_frame.py:844] [4/1419]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.849000 612 torch/_dynamo/convert_frame.py:844] [4/1419] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.849000 612 torch/_dynamo/convert_frame.py:844] [4/1419] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.852000 612 torch/_dynamo/convert_frame.py:844] [4/1420] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.852000 612 torch/_dynamo/convert_frame.py:844] [4/1420]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.852000 612 torch/_dynamo/convert_frame.py:844] [4/1420]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.852000 612 torch/_dynamo/convert_frame.py:844] [4/1420] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.852000 612 torch/_dynamo/convert_frame.py:844] [4/1420] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.855000 612 torch/_dynamo/convert_frame.py:844] [4/1421] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.855000 612 torch/_dynamo/convert_frame.py:844] [4/1421]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.855000 612 torch/_dynamo/convert_frame.py:844] [4/1421]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.855000 612 torch/_dynamo/convert_frame.py:844] [4/1421] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.855000 612 torch/_dynamo/convert_frame.py:844] [4/1421] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.857000 612 torch/_dynamo/convert_frame.py:844] [4/1422] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.857000 612 torch/_dynamo/convert_frame.py:844] [4/1422]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.857000 612 torch/_dynamo/convert_frame.py:844] [4/1422]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.857000 612 torch/_dynamo/convert_frame.py:844] [4/1422] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.857000 612 torch/_dynamo/convert_frame.py:844] [4/1422] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.860000 612 torch/_dynamo/convert_frame.py:844] [4/1423] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.860000 612 torch/_dynamo/convert_frame.py:844] [4/1423]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.860000 612 torch/_dynamo/convert_frame.py:844] [4/1423]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.860000 612 torch/_dynamo/convert_frame.py:844] [4/1423] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.860000 612 torch/_dynamo/convert_frame.py:844] [4/1423] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.863000 612 torch/_dynamo/convert_frame.py:844] [4/1424] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.863000 612 torch/_dynamo/convert_frame.py:844] [4/1424]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.863000 612 torch/_dynamo/convert_frame.py:844] [4/1424]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.863000 612 torch/_dynamo/convert_frame.py:844] [4/1424] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.863000 612 torch/_dynamo/convert_frame.py:844] [4/1424] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.866000 612 torch/_dynamo/convert_frame.py:844] [4/1425] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.866000 612 torch/_dynamo/convert_frame.py:844] [4/1425]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.866000 612 torch/_dynamo/convert_frame.py:844] [4/1425]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.866000 612 torch/_dynamo/convert_frame.py:844] [4/1425] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.866000 612 torch/_dynamo/convert_frame.py:844] [4/1425] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.869000 612 torch/_dynamo/convert_frame.py:844] [4/1426] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.869000 612 torch/_dynamo/convert_frame.py:844] [4/1426]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.869000 612 torch/_dynamo/convert_frame.py:844] [4/1426]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.869000 612 torch/_dynamo/convert_frame.py:844] [4/1426] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.869000 612 torch/_dynamo/convert_frame.py:844] [4/1426] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.871000 612 torch/_dynamo/convert_frame.py:844] [4/1427] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.871000 612 torch/_dynamo/convert_frame.py:844] [4/1427]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.871000 612 torch/_dynamo/convert_frame.py:844] [4/1427]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.871000 612 torch/_dynamo/convert_frame.py:844] [4/1427] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.871000 612 torch/_dynamo/convert_frame.py:844] [4/1427] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.874000 612 torch/_dynamo/convert_frame.py:844] [4/1428] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.874000 612 torch/_dynamo/convert_frame.py:844] [4/1428]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.874000 612 torch/_dynamo/convert_frame.py:844] [4/1428]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.874000 612 torch/_dynamo/convert_frame.py:844] [4/1428] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.874000 612 torch/_dynamo/convert_frame.py:844] [4/1428] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.878000 612 torch/_dynamo/convert_frame.py:844] [4/1429] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.878000 612 torch/_dynamo/convert_frame.py:844] [4/1429]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.878000 612 torch/_dynamo/convert_frame.py:844] [4/1429]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.878000 612 torch/_dynamo/convert_frame.py:844] [4/1429] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.878000 612 torch/_dynamo/convert_frame.py:844] [4/1429] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.881000 612 torch/_dynamo/convert_frame.py:844] [4/1430] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.881000 612 torch/_dynamo/convert_frame.py:844] [4/1430]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.881000 612 torch/_dynamo/convert_frame.py:844] [4/1430]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.881000 612 torch/_dynamo/convert_frame.py:844] [4/1430] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.881000 612 torch/_dynamo/convert_frame.py:844] [4/1430] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.885000 612 torch/_dynamo/convert_frame.py:844] [4/1431] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.885000 612 torch/_dynamo/convert_frame.py:844] [4/1431]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.885000 612 torch/_dynamo/convert_frame.py:844] [4/1431]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.885000 612 torch/_dynamo/convert_frame.py:844] [4/1431] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.885000 612 torch/_dynamo/convert_frame.py:844] [4/1431] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.888000 612 torch/_dynamo/convert_frame.py:844] [4/1432] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.888000 612 torch/_dynamo/convert_frame.py:844] [4/1432]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.888000 612 torch/_dynamo/convert_frame.py:844] [4/1432]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.888000 612 torch/_dynamo/convert_frame.py:844] [4/1432] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.888000 612 torch/_dynamo/convert_frame.py:844] [4/1432] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.891000 612 torch/_dynamo/convert_frame.py:844] [4/1433] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.891000 612 torch/_dynamo/convert_frame.py:844] [4/1433]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.891000 612 torch/_dynamo/convert_frame.py:844] [4/1433]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.891000 612 torch/_dynamo/convert_frame.py:844] [4/1433] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.891000 612 torch/_dynamo/convert_frame.py:844] [4/1433] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.894000 612 torch/_dynamo/convert_frame.py:844] [4/1434] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.894000 612 torch/_dynamo/convert_frame.py:844] [4/1434]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.894000 612 torch/_dynamo/convert_frame.py:844] [4/1434]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.894000 612 torch/_dynamo/convert_frame.py:844] [4/1434] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.894000 612 torch/_dynamo/convert_frame.py:844] [4/1434] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.898000 612 torch/_dynamo/convert_frame.py:844] [4/1435] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.898000 612 torch/_dynamo/convert_frame.py:844] [4/1435]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.898000 612 torch/_dynamo/convert_frame.py:844] [4/1435]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.898000 612 torch/_dynamo/convert_frame.py:844] [4/1435] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.898000 612 torch/_dynamo/convert_frame.py:844] [4/1435] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.901000 612 torch/_dynamo/convert_frame.py:844] [4/1436] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.901000 612 torch/_dynamo/convert_frame.py:844] [4/1436]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.901000 612 torch/_dynamo/convert_frame.py:844] [4/1436]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.901000 612 torch/_dynamo/convert_frame.py:844] [4/1436] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.901000 612 torch/_dynamo/convert_frame.py:844] [4/1436] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.903000 612 torch/_dynamo/convert_frame.py:844] [4/1437] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.903000 612 torch/_dynamo/convert_frame.py:844] [4/1437]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.903000 612 torch/_dynamo/convert_frame.py:844] [4/1437]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.903000 612 torch/_dynamo/convert_frame.py:844] [4/1437] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.903000 612 torch/_dynamo/convert_frame.py:844] [4/1437] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.907000 612 torch/_dynamo/convert_frame.py:844] [4/1438] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.907000 612 torch/_dynamo/convert_frame.py:844] [4/1438]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.907000 612 torch/_dynamo/convert_frame.py:844] [4/1438]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.907000 612 torch/_dynamo/convert_frame.py:844] [4/1438] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.907000 612 torch/_dynamo/convert_frame.py:844] [4/1438] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.910000 612 torch/_dynamo/convert_frame.py:844] [4/1439] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.910000 612 torch/_dynamo/convert_frame.py:844] [4/1439]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.910000 612 torch/_dynamo/convert_frame.py:844] [4/1439]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.910000 612 torch/_dynamo/convert_frame.py:844] [4/1439] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.910000 612 torch/_dynamo/convert_frame.py:844] [4/1439] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.913000 612 torch/_dynamo/convert_frame.py:844] [4/1440] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.913000 612 torch/_dynamo/convert_frame.py:844] [4/1440]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.913000 612 torch/_dynamo/convert_frame.py:844] [4/1440]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.913000 612 torch/_dynamo/convert_frame.py:844] [4/1440] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.913000 612 torch/_dynamo/convert_frame.py:844] [4/1440] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.916000 612 torch/_dynamo/convert_frame.py:844] [4/1441] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.916000 612 torch/_dynamo/convert_frame.py:844] [4/1441]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.916000 612 torch/_dynamo/convert_frame.py:844] [4/1441]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.916000 612 torch/_dynamo/convert_frame.py:844] [4/1441] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.916000 612 torch/_dynamo/convert_frame.py:844] [4/1441] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.919000 612 torch/_dynamo/convert_frame.py:844] [4/1442] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.919000 612 torch/_dynamo/convert_frame.py:844] [4/1442]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.919000 612 torch/_dynamo/convert_frame.py:844] [4/1442]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.919000 612 torch/_dynamo/convert_frame.py:844] [4/1442] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.919000 612 torch/_dynamo/convert_frame.py:844] [4/1442] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.921000 612 torch/_dynamo/convert_frame.py:844] [4/1443] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.921000 612 torch/_dynamo/convert_frame.py:844] [4/1443]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.921000 612 torch/_dynamo/convert_frame.py:844] [4/1443]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.921000 612 torch/_dynamo/convert_frame.py:844] [4/1443] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.921000 612 torch/_dynamo/convert_frame.py:844] [4/1443] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.924000 612 torch/_dynamo/convert_frame.py:844] [4/1444] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.924000 612 torch/_dynamo/convert_frame.py:844] [4/1444]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.924000 612 torch/_dynamo/convert_frame.py:844] [4/1444]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.924000 612 torch/_dynamo/convert_frame.py:844] [4/1444] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.924000 612 torch/_dynamo/convert_frame.py:844] [4/1444] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.927000 612 torch/_dynamo/convert_frame.py:844] [4/1445] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.927000 612 torch/_dynamo/convert_frame.py:844] [4/1445]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.927000 612 torch/_dynamo/convert_frame.py:844] [4/1445]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.927000 612 torch/_dynamo/convert_frame.py:844] [4/1445] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.927000 612 torch/_dynamo/convert_frame.py:844] [4/1445] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.930000 612 torch/_dynamo/convert_frame.py:844] [4/1446] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.930000 612 torch/_dynamo/convert_frame.py:844] [4/1446]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.930000 612 torch/_dynamo/convert_frame.py:844] [4/1446]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.930000 612 torch/_dynamo/convert_frame.py:844] [4/1446] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.930000 612 torch/_dynamo/convert_frame.py:844] [4/1446] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.933000 612 torch/_dynamo/convert_frame.py:844] [4/1447] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.933000 612 torch/_dynamo/convert_frame.py:844] [4/1447]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.933000 612 torch/_dynamo/convert_frame.py:844] [4/1447]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.933000 612 torch/_dynamo/convert_frame.py:844] [4/1447] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.933000 612 torch/_dynamo/convert_frame.py:844] [4/1447] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.935000 612 torch/_dynamo/convert_frame.py:844] [4/1448] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.935000 612 torch/_dynamo/convert_frame.py:844] [4/1448]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.935000 612 torch/_dynamo/convert_frame.py:844] [4/1448]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.935000 612 torch/_dynamo/convert_frame.py:844] [4/1448] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.935000 612 torch/_dynamo/convert_frame.py:844] [4/1448] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.939000 612 torch/_dynamo/convert_frame.py:844] [4/1449] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.939000 612 torch/_dynamo/convert_frame.py:844] [4/1449]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.939000 612 torch/_dynamo/convert_frame.py:844] [4/1449]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.939000 612 torch/_dynamo/convert_frame.py:844] [4/1449] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.939000 612 torch/_dynamo/convert_frame.py:844] [4/1449] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.942000 612 torch/_dynamo/convert_frame.py:844] [4/1450] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.942000 612 torch/_dynamo/convert_frame.py:844] [4/1450]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.942000 612 torch/_dynamo/convert_frame.py:844] [4/1450]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.942000 612 torch/_dynamo/convert_frame.py:844] [4/1450] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.942000 612 torch/_dynamo/convert_frame.py:844] [4/1450] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.944000 612 torch/_dynamo/convert_frame.py:844] [4/1451] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.944000 612 torch/_dynamo/convert_frame.py:844] [4/1451]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.944000 612 torch/_dynamo/convert_frame.py:844] [4/1451]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.944000 612 torch/_dynamo/convert_frame.py:844] [4/1451] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.944000 612 torch/_dynamo/convert_frame.py:844] [4/1451] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.947000 612 torch/_dynamo/convert_frame.py:844] [4/1452] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.947000 612 torch/_dynamo/convert_frame.py:844] [4/1452]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.947000 612 torch/_dynamo/convert_frame.py:844] [4/1452]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.947000 612 torch/_dynamo/convert_frame.py:844] [4/1452] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.947000 612 torch/_dynamo/convert_frame.py:844] [4/1452] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.950000 612 torch/_dynamo/convert_frame.py:844] [4/1453] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.950000 612 torch/_dynamo/convert_frame.py:844] [4/1453]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.950000 612 torch/_dynamo/convert_frame.py:844] [4/1453]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.950000 612 torch/_dynamo/convert_frame.py:844] [4/1453] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.950000 612 torch/_dynamo/convert_frame.py:844] [4/1453] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.953000 612 torch/_dynamo/convert_frame.py:844] [4/1454] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.953000 612 torch/_dynamo/convert_frame.py:844] [4/1454]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.953000 612 torch/_dynamo/convert_frame.py:844] [4/1454]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.953000 612 torch/_dynamo/convert_frame.py:844] [4/1454] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.953000 612 torch/_dynamo/convert_frame.py:844] [4/1454] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.956000 612 torch/_dynamo/convert_frame.py:844] [4/1455] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.956000 612 torch/_dynamo/convert_frame.py:844] [4/1455]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.956000 612 torch/_dynamo/convert_frame.py:844] [4/1455]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.956000 612 torch/_dynamo/convert_frame.py:844] [4/1455] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.956000 612 torch/_dynamo/convert_frame.py:844] [4/1455] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.959000 612 torch/_dynamo/convert_frame.py:844] [4/1456] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.959000 612 torch/_dynamo/convert_frame.py:844] [4/1456]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.959000 612 torch/_dynamo/convert_frame.py:844] [4/1456]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.959000 612 torch/_dynamo/convert_frame.py:844] [4/1456] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.959000 612 torch/_dynamo/convert_frame.py:844] [4/1456] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.962000 612 torch/_dynamo/convert_frame.py:844] [4/1457] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.962000 612 torch/_dynamo/convert_frame.py:844] [4/1457]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.962000 612 torch/_dynamo/convert_frame.py:844] [4/1457]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.962000 612 torch/_dynamo/convert_frame.py:844] [4/1457] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.962000 612 torch/_dynamo/convert_frame.py:844] [4/1457] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.965000 612 torch/_dynamo/convert_frame.py:844] [4/1458] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.965000 612 torch/_dynamo/convert_frame.py:844] [4/1458]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.965000 612 torch/_dynamo/convert_frame.py:844] [4/1458]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.965000 612 torch/_dynamo/convert_frame.py:844] [4/1458] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.965000 612 torch/_dynamo/convert_frame.py:844] [4/1458] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.968000 612 torch/_dynamo/convert_frame.py:844] [4/1459] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.968000 612 torch/_dynamo/convert_frame.py:844] [4/1459]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.968000 612 torch/_dynamo/convert_frame.py:844] [4/1459]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.968000 612 torch/_dynamo/convert_frame.py:844] [4/1459] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.968000 612 torch/_dynamo/convert_frame.py:844] [4/1459] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.971000 612 torch/_dynamo/convert_frame.py:844] [4/1460] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.971000 612 torch/_dynamo/convert_frame.py:844] [4/1460]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.971000 612 torch/_dynamo/convert_frame.py:844] [4/1460]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.971000 612 torch/_dynamo/convert_frame.py:844] [4/1460] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.971000 612 torch/_dynamo/convert_frame.py:844] [4/1460] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.974000 612 torch/_dynamo/convert_frame.py:844] [4/1461] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.974000 612 torch/_dynamo/convert_frame.py:844] [4/1461]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.974000 612 torch/_dynamo/convert_frame.py:844] [4/1461]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.974000 612 torch/_dynamo/convert_frame.py:844] [4/1461] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.974000 612 torch/_dynamo/convert_frame.py:844] [4/1461] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.976000 612 torch/_dynamo/convert_frame.py:844] [4/1462] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.976000 612 torch/_dynamo/convert_frame.py:844] [4/1462]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.976000 612 torch/_dynamo/convert_frame.py:844] [4/1462]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.976000 612 torch/_dynamo/convert_frame.py:844] [4/1462] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.976000 612 torch/_dynamo/convert_frame.py:844] [4/1462] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.980000 612 torch/_dynamo/convert_frame.py:844] [4/1463] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.980000 612 torch/_dynamo/convert_frame.py:844] [4/1463]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.980000 612 torch/_dynamo/convert_frame.py:844] [4/1463]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.980000 612 torch/_dynamo/convert_frame.py:844] [4/1463] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.980000 612 torch/_dynamo/convert_frame.py:844] [4/1463] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.983000 612 torch/_dynamo/convert_frame.py:844] [4/1464] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.983000 612 torch/_dynamo/convert_frame.py:844] [4/1464]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.983000 612 torch/_dynamo/convert_frame.py:844] [4/1464]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.983000 612 torch/_dynamo/convert_frame.py:844] [4/1464] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.983000 612 torch/_dynamo/convert_frame.py:844] [4/1464] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.985000 612 torch/_dynamo/convert_frame.py:844] [4/1465] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.985000 612 torch/_dynamo/convert_frame.py:844] [4/1465]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.985000 612 torch/_dynamo/convert_frame.py:844] [4/1465]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.985000 612 torch/_dynamo/convert_frame.py:844] [4/1465] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.985000 612 torch/_dynamo/convert_frame.py:844] [4/1465] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.990000 612 torch/_dynamo/convert_frame.py:844] [4/1466] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.990000 612 torch/_dynamo/convert_frame.py:844] [4/1466]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.990000 612 torch/_dynamo/convert_frame.py:844] [4/1466]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.990000 612 torch/_dynamo/convert_frame.py:844] [4/1466] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.990000 612 torch/_dynamo/convert_frame.py:844] [4/1466] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.993000 612 torch/_dynamo/convert_frame.py:844] [4/1467] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.993000 612 torch/_dynamo/convert_frame.py:844] [4/1467]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.993000 612 torch/_dynamo/convert_frame.py:844] [4/1467]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.993000 612 torch/_dynamo/convert_frame.py:844] [4/1467] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.993000 612 torch/_dynamo/convert_frame.py:844] [4/1467] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:13.996000 612 torch/_dynamo/convert_frame.py:844] [4/1468] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:13.996000 612 torch/_dynamo/convert_frame.py:844] [4/1468]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:13.996000 612 torch/_dynamo/convert_frame.py:844] [4/1468]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:13.996000 612 torch/_dynamo/convert_frame.py:844] [4/1468] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:13.996000 612 torch/_dynamo/convert_frame.py:844] [4/1468] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.000000 612 torch/_dynamo/convert_frame.py:844] [4/1469] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.000000 612 torch/_dynamo/convert_frame.py:844] [4/1469]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.000000 612 torch/_dynamo/convert_frame.py:844] [4/1469]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.000000 612 torch/_dynamo/convert_frame.py:844] [4/1469] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.000000 612 torch/_dynamo/convert_frame.py:844] [4/1469] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.003000 612 torch/_dynamo/convert_frame.py:844] [4/1470] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.003000 612 torch/_dynamo/convert_frame.py:844] [4/1470]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.003000 612 torch/_dynamo/convert_frame.py:844] [4/1470]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.003000 612 torch/_dynamo/convert_frame.py:844] [4/1470] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.003000 612 torch/_dynamo/convert_frame.py:844] [4/1470] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.006000 612 torch/_dynamo/convert_frame.py:844] [4/1471] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.006000 612 torch/_dynamo/convert_frame.py:844] [4/1471]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.006000 612 torch/_dynamo/convert_frame.py:844] [4/1471]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.006000 612 torch/_dynamo/convert_frame.py:844] [4/1471] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.006000 612 torch/_dynamo/convert_frame.py:844] [4/1471] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.009000 612 torch/_dynamo/convert_frame.py:844] [4/1472] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.009000 612 torch/_dynamo/convert_frame.py:844] [4/1472]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.009000 612 torch/_dynamo/convert_frame.py:844] [4/1472]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.009000 612 torch/_dynamo/convert_frame.py:844] [4/1472] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.009000 612 torch/_dynamo/convert_frame.py:844] [4/1472] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.012000 612 torch/_dynamo/convert_frame.py:844] [4/1473] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.012000 612 torch/_dynamo/convert_frame.py:844] [4/1473]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.012000 612 torch/_dynamo/convert_frame.py:844] [4/1473]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.012000 612 torch/_dynamo/convert_frame.py:844] [4/1473] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.012000 612 torch/_dynamo/convert_frame.py:844] [4/1473] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.014000 612 torch/_dynamo/convert_frame.py:844] [4/1474] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.014000 612 torch/_dynamo/convert_frame.py:844] [4/1474]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.014000 612 torch/_dynamo/convert_frame.py:844] [4/1474]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.014000 612 torch/_dynamo/convert_frame.py:844] [4/1474] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.014000 612 torch/_dynamo/convert_frame.py:844] [4/1474] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.017000 612 torch/_dynamo/convert_frame.py:844] [4/1475] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.017000 612 torch/_dynamo/convert_frame.py:844] [4/1475]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.017000 612 torch/_dynamo/convert_frame.py:844] [4/1475]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.017000 612 torch/_dynamo/convert_frame.py:844] [4/1475] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.017000 612 torch/_dynamo/convert_frame.py:844] [4/1475] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.021000 612 torch/_dynamo/convert_frame.py:844] [4/1476] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.021000 612 torch/_dynamo/convert_frame.py:844] [4/1476]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.021000 612 torch/_dynamo/convert_frame.py:844] [4/1476]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.021000 612 torch/_dynamo/convert_frame.py:844] [4/1476] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.021000 612 torch/_dynamo/convert_frame.py:844] [4/1476] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.023000 612 torch/_dynamo/convert_frame.py:844] [4/1477] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.023000 612 torch/_dynamo/convert_frame.py:844] [4/1477]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.023000 612 torch/_dynamo/convert_frame.py:844] [4/1477]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.023000 612 torch/_dynamo/convert_frame.py:844] [4/1477] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.023000 612 torch/_dynamo/convert_frame.py:844] [4/1477] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.027000 612 torch/_dynamo/convert_frame.py:844] [4/1478] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.027000 612 torch/_dynamo/convert_frame.py:844] [4/1478]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.027000 612 torch/_dynamo/convert_frame.py:844] [4/1478]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.027000 612 torch/_dynamo/convert_frame.py:844] [4/1478] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.027000 612 torch/_dynamo/convert_frame.py:844] [4/1478] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.030000 612 torch/_dynamo/convert_frame.py:844] [4/1479] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.030000 612 torch/_dynamo/convert_frame.py:844] [4/1479]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.030000 612 torch/_dynamo/convert_frame.py:844] [4/1479]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.030000 612 torch/_dynamo/convert_frame.py:844] [4/1479] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.030000 612 torch/_dynamo/convert_frame.py:844] [4/1479] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.033000 612 torch/_dynamo/convert_frame.py:844] [4/1480] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.033000 612 torch/_dynamo/convert_frame.py:844] [4/1480]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.033000 612 torch/_dynamo/convert_frame.py:844] [4/1480]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.033000 612 torch/_dynamo/convert_frame.py:844] [4/1480] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.033000 612 torch/_dynamo/convert_frame.py:844] [4/1480] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.035000 612 torch/_dynamo/convert_frame.py:844] [4/1481] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.035000 612 torch/_dynamo/convert_frame.py:844] [4/1481]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.035000 612 torch/_dynamo/convert_frame.py:844] [4/1481]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.035000 612 torch/_dynamo/convert_frame.py:844] [4/1481] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.035000 612 torch/_dynamo/convert_frame.py:844] [4/1481] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.038000 612 torch/_dynamo/convert_frame.py:844] [4/1482] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.038000 612 torch/_dynamo/convert_frame.py:844] [4/1482]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.038000 612 torch/_dynamo/convert_frame.py:844] [4/1482]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.038000 612 torch/_dynamo/convert_frame.py:844] [4/1482] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.038000 612 torch/_dynamo/convert_frame.py:844] [4/1482] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.041000 612 torch/_dynamo/convert_frame.py:844] [4/1483] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.041000 612 torch/_dynamo/convert_frame.py:844] [4/1483]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.041000 612 torch/_dynamo/convert_frame.py:844] [4/1483]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.041000 612 torch/_dynamo/convert_frame.py:844] [4/1483] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.041000 612 torch/_dynamo/convert_frame.py:844] [4/1483] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.044000 612 torch/_dynamo/convert_frame.py:844] [4/1484] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.044000 612 torch/_dynamo/convert_frame.py:844] [4/1484]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.044000 612 torch/_dynamo/convert_frame.py:844] [4/1484]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.044000 612 torch/_dynamo/convert_frame.py:844] [4/1484] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.044000 612 torch/_dynamo/convert_frame.py:844] [4/1484] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.047000 612 torch/_dynamo/convert_frame.py:844] [4/1485] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.047000 612 torch/_dynamo/convert_frame.py:844] [4/1485]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.047000 612 torch/_dynamo/convert_frame.py:844] [4/1485]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.047000 612 torch/_dynamo/convert_frame.py:844] [4/1485] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.047000 612 torch/_dynamo/convert_frame.py:844] [4/1485] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.050000 612 torch/_dynamo/convert_frame.py:844] [4/1486] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.050000 612 torch/_dynamo/convert_frame.py:844] [4/1486]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.050000 612 torch/_dynamo/convert_frame.py:844] [4/1486]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.050000 612 torch/_dynamo/convert_frame.py:844] [4/1486] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.050000 612 torch/_dynamo/convert_frame.py:844] [4/1486] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.053000 612 torch/_dynamo/convert_frame.py:844] [4/1487] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.053000 612 torch/_dynamo/convert_frame.py:844] [4/1487]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.053000 612 torch/_dynamo/convert_frame.py:844] [4/1487]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.053000 612 torch/_dynamo/convert_frame.py:844] [4/1487] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.053000 612 torch/_dynamo/convert_frame.py:844] [4/1487] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.055000 612 torch/_dynamo/convert_frame.py:844] [4/1488] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.055000 612 torch/_dynamo/convert_frame.py:844] [4/1488]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.055000 612 torch/_dynamo/convert_frame.py:844] [4/1488]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.055000 612 torch/_dynamo/convert_frame.py:844] [4/1488] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.055000 612 torch/_dynamo/convert_frame.py:844] [4/1488] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.058000 612 torch/_dynamo/convert_frame.py:844] [4/1489] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.058000 612 torch/_dynamo/convert_frame.py:844] [4/1489]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.058000 612 torch/_dynamo/convert_frame.py:844] [4/1489]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.058000 612 torch/_dynamo/convert_frame.py:844] [4/1489] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.058000 612 torch/_dynamo/convert_frame.py:844] [4/1489] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.061000 612 torch/_dynamo/convert_frame.py:844] [4/1490] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.061000 612 torch/_dynamo/convert_frame.py:844] [4/1490]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.061000 612 torch/_dynamo/convert_frame.py:844] [4/1490]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.061000 612 torch/_dynamo/convert_frame.py:844] [4/1490] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.061000 612 torch/_dynamo/convert_frame.py:844] [4/1490] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.064000 612 torch/_dynamo/convert_frame.py:844] [4/1491] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.064000 612 torch/_dynamo/convert_frame.py:844] [4/1491]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.064000 612 torch/_dynamo/convert_frame.py:844] [4/1491]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.064000 612 torch/_dynamo/convert_frame.py:844] [4/1491] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.064000 612 torch/_dynamo/convert_frame.py:844] [4/1491] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.066000 612 torch/_dynamo/convert_frame.py:844] [4/1492] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.066000 612 torch/_dynamo/convert_frame.py:844] [4/1492]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.066000 612 torch/_dynamo/convert_frame.py:844] [4/1492]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.066000 612 torch/_dynamo/convert_frame.py:844] [4/1492] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.066000 612 torch/_dynamo/convert_frame.py:844] [4/1492] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.069000 612 torch/_dynamo/convert_frame.py:844] [4/1493] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.069000 612 torch/_dynamo/convert_frame.py:844] [4/1493]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.069000 612 torch/_dynamo/convert_frame.py:844] [4/1493]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.069000 612 torch/_dynamo/convert_frame.py:844] [4/1493] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.069000 612 torch/_dynamo/convert_frame.py:844] [4/1493] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.072000 612 torch/_dynamo/convert_frame.py:844] [4/1494] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.072000 612 torch/_dynamo/convert_frame.py:844] [4/1494]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.072000 612 torch/_dynamo/convert_frame.py:844] [4/1494]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.072000 612 torch/_dynamo/convert_frame.py:844] [4/1494] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.072000 612 torch/_dynamo/convert_frame.py:844] [4/1494] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.075000 612 torch/_dynamo/convert_frame.py:844] [4/1495] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.075000 612 torch/_dynamo/convert_frame.py:844] [4/1495]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.075000 612 torch/_dynamo/convert_frame.py:844] [4/1495]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.075000 612 torch/_dynamo/convert_frame.py:844] [4/1495] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.075000 612 torch/_dynamo/convert_frame.py:844] [4/1495] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.078000 612 torch/_dynamo/convert_frame.py:844] [4/1496] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.078000 612 torch/_dynamo/convert_frame.py:844] [4/1496]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.078000 612 torch/_dynamo/convert_frame.py:844] [4/1496]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.078000 612 torch/_dynamo/convert_frame.py:844] [4/1496] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.078000 612 torch/_dynamo/convert_frame.py:844] [4/1496] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.081000 612 torch/_dynamo/convert_frame.py:844] [4/1497] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.081000 612 torch/_dynamo/convert_frame.py:844] [4/1497]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.081000 612 torch/_dynamo/convert_frame.py:844] [4/1497]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.081000 612 torch/_dynamo/convert_frame.py:844] [4/1497] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.081000 612 torch/_dynamo/convert_frame.py:844] [4/1497] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.083000 612 torch/_dynamo/convert_frame.py:844] [4/1498] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.083000 612 torch/_dynamo/convert_frame.py:844] [4/1498]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.083000 612 torch/_dynamo/convert_frame.py:844] [4/1498]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.083000 612 torch/_dynamo/convert_frame.py:844] [4/1498] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.083000 612 torch/_dynamo/convert_frame.py:844] [4/1498] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.086000 612 torch/_dynamo/convert_frame.py:844] [4/1499] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.086000 612 torch/_dynamo/convert_frame.py:844] [4/1499]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.086000 612 torch/_dynamo/convert_frame.py:844] [4/1499]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.086000 612 torch/_dynamo/convert_frame.py:844] [4/1499] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.086000 612 torch/_dynamo/convert_frame.py:844] [4/1499] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.089000 612 torch/_dynamo/convert_frame.py:844] [4/1500] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.089000 612 torch/_dynamo/convert_frame.py:844] [4/1500]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.089000 612 torch/_dynamo/convert_frame.py:844] [4/1500]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.089000 612 torch/_dynamo/convert_frame.py:844] [4/1500] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.089000 612 torch/_dynamo/convert_frame.py:844] [4/1500] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.091000 612 torch/_dynamo/convert_frame.py:844] [4/1501] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.091000 612 torch/_dynamo/convert_frame.py:844] [4/1501]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.091000 612 torch/_dynamo/convert_frame.py:844] [4/1501]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.091000 612 torch/_dynamo/convert_frame.py:844] [4/1501] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.091000 612 torch/_dynamo/convert_frame.py:844] [4/1501] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.093000 612 torch/_dynamo/convert_frame.py:844] [4/1502] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.093000 612 torch/_dynamo/convert_frame.py:844] [4/1502]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.093000 612 torch/_dynamo/convert_frame.py:844] [4/1502]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.093000 612 torch/_dynamo/convert_frame.py:844] [4/1502] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.093000 612 torch/_dynamo/convert_frame.py:844] [4/1502] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.096000 612 torch/_dynamo/convert_frame.py:844] [4/1503] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.096000 612 torch/_dynamo/convert_frame.py:844] [4/1503]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.096000 612 torch/_dynamo/convert_frame.py:844] [4/1503]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.096000 612 torch/_dynamo/convert_frame.py:844] [4/1503] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.096000 612 torch/_dynamo/convert_frame.py:844] [4/1503] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.099000 612 torch/_dynamo/convert_frame.py:844] [4/1504] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.099000 612 torch/_dynamo/convert_frame.py:844] [4/1504]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.099000 612 torch/_dynamo/convert_frame.py:844] [4/1504]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.099000 612 torch/_dynamo/convert_frame.py:844] [4/1504] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.099000 612 torch/_dynamo/convert_frame.py:844] [4/1504] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.105000 612 torch/_dynamo/convert_frame.py:844] [4/1505] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.105000 612 torch/_dynamo/convert_frame.py:844] [4/1505]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.105000 612 torch/_dynamo/convert_frame.py:844] [4/1505]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.105000 612 torch/_dynamo/convert_frame.py:844] [4/1505] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.105000 612 torch/_dynamo/convert_frame.py:844] [4/1505] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.108000 612 torch/_dynamo/convert_frame.py:844] [4/1506] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.108000 612 torch/_dynamo/convert_frame.py:844] [4/1506]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.108000 612 torch/_dynamo/convert_frame.py:844] [4/1506]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.108000 612 torch/_dynamo/convert_frame.py:844] [4/1506] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.108000 612 torch/_dynamo/convert_frame.py:844] [4/1506] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.112000 612 torch/_dynamo/convert_frame.py:844] [4/1507] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.112000 612 torch/_dynamo/convert_frame.py:844] [4/1507]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.112000 612 torch/_dynamo/convert_frame.py:844] [4/1507]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.112000 612 torch/_dynamo/convert_frame.py:844] [4/1507] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.112000 612 torch/_dynamo/convert_frame.py:844] [4/1507] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.116000 612 torch/_dynamo/convert_frame.py:844] [4/1508] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.116000 612 torch/_dynamo/convert_frame.py:844] [4/1508]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.116000 612 torch/_dynamo/convert_frame.py:844] [4/1508]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.116000 612 torch/_dynamo/convert_frame.py:844] [4/1508] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.116000 612 torch/_dynamo/convert_frame.py:844] [4/1508] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.122000 612 torch/_dynamo/convert_frame.py:844] [4/1509] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.122000 612 torch/_dynamo/convert_frame.py:844] [4/1509]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.122000 612 torch/_dynamo/convert_frame.py:844] [4/1509]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.122000 612 torch/_dynamo/convert_frame.py:844] [4/1509] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.122000 612 torch/_dynamo/convert_frame.py:844] [4/1509] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.127000 612 torch/_dynamo/convert_frame.py:844] [4/1510] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.127000 612 torch/_dynamo/convert_frame.py:844] [4/1510]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.127000 612 torch/_dynamo/convert_frame.py:844] [4/1510]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.127000 612 torch/_dynamo/convert_frame.py:844] [4/1510] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.127000 612 torch/_dynamo/convert_frame.py:844] [4/1510] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.130000 612 torch/_dynamo/convert_frame.py:844] [4/1511] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.130000 612 torch/_dynamo/convert_frame.py:844] [4/1511]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.130000 612 torch/_dynamo/convert_frame.py:844] [4/1511]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.130000 612 torch/_dynamo/convert_frame.py:844] [4/1511] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.130000 612 torch/_dynamo/convert_frame.py:844] [4/1511] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.136000 612 torch/_dynamo/convert_frame.py:844] [4/1512] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.136000 612 torch/_dynamo/convert_frame.py:844] [4/1512]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.136000 612 torch/_dynamo/convert_frame.py:844] [4/1512]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.136000 612 torch/_dynamo/convert_frame.py:844] [4/1512] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.136000 612 torch/_dynamo/convert_frame.py:844] [4/1512] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.143000 612 torch/_dynamo/convert_frame.py:844] [4/1513] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.143000 612 torch/_dynamo/convert_frame.py:844] [4/1513]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.143000 612 torch/_dynamo/convert_frame.py:844] [4/1513]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.143000 612 torch/_dynamo/convert_frame.py:844] [4/1513] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.143000 612 torch/_dynamo/convert_frame.py:844] [4/1513] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.148000 612 torch/_dynamo/convert_frame.py:844] [4/1514] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.148000 612 torch/_dynamo/convert_frame.py:844] [4/1514]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.148000 612 torch/_dynamo/convert_frame.py:844] [4/1514]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.148000 612 torch/_dynamo/convert_frame.py:844] [4/1514] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.148000 612 torch/_dynamo/convert_frame.py:844] [4/1514] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.152000 612 torch/_dynamo/convert_frame.py:844] [4/1515] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.152000 612 torch/_dynamo/convert_frame.py:844] [4/1515]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.152000 612 torch/_dynamo/convert_frame.py:844] [4/1515]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.152000 612 torch/_dynamo/convert_frame.py:844] [4/1515] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.152000 612 torch/_dynamo/convert_frame.py:844] [4/1515] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.157000 612 torch/_dynamo/convert_frame.py:844] [4/1516] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.157000 612 torch/_dynamo/convert_frame.py:844] [4/1516]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.157000 612 torch/_dynamo/convert_frame.py:844] [4/1516]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.157000 612 torch/_dynamo/convert_frame.py:844] [4/1516] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.157000 612 torch/_dynamo/convert_frame.py:844] [4/1516] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.163000 612 torch/_dynamo/convert_frame.py:844] [4/1517] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.163000 612 torch/_dynamo/convert_frame.py:844] [4/1517]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.163000 612 torch/_dynamo/convert_frame.py:844] [4/1517]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.163000 612 torch/_dynamo/convert_frame.py:844] [4/1517] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.163000 612 torch/_dynamo/convert_frame.py:844] [4/1517] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.166000 612 torch/_dynamo/convert_frame.py:844] [4/1518] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.166000 612 torch/_dynamo/convert_frame.py:844] [4/1518]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.166000 612 torch/_dynamo/convert_frame.py:844] [4/1518]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.166000 612 torch/_dynamo/convert_frame.py:844] [4/1518] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.166000 612 torch/_dynamo/convert_frame.py:844] [4/1518] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.168000 612 torch/_dynamo/convert_frame.py:844] [4/1519] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.168000 612 torch/_dynamo/convert_frame.py:844] [4/1519]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.168000 612 torch/_dynamo/convert_frame.py:844] [4/1519]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.168000 612 torch/_dynamo/convert_frame.py:844] [4/1519] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.168000 612 torch/_dynamo/convert_frame.py:844] [4/1519] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.172000 612 torch/_dynamo/convert_frame.py:844] [4/1520] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.172000 612 torch/_dynamo/convert_frame.py:844] [4/1520]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.172000 612 torch/_dynamo/convert_frame.py:844] [4/1520]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.172000 612 torch/_dynamo/convert_frame.py:844] [4/1520] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.172000 612 torch/_dynamo/convert_frame.py:844] [4/1520] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.174000 612 torch/_dynamo/convert_frame.py:844] [4/1521] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.174000 612 torch/_dynamo/convert_frame.py:844] [4/1521]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.174000 612 torch/_dynamo/convert_frame.py:844] [4/1521]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.174000 612 torch/_dynamo/convert_frame.py:844] [4/1521] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.174000 612 torch/_dynamo/convert_frame.py:844] [4/1521] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.177000 612 torch/_dynamo/convert_frame.py:844] [4/1522] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.177000 612 torch/_dynamo/convert_frame.py:844] [4/1522]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.177000 612 torch/_dynamo/convert_frame.py:844] [4/1522]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.177000 612 torch/_dynamo/convert_frame.py:844] [4/1522] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.177000 612 torch/_dynamo/convert_frame.py:844] [4/1522] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.180000 612 torch/_dynamo/convert_frame.py:844] [4/1523] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.180000 612 torch/_dynamo/convert_frame.py:844] [4/1523]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.180000 612 torch/_dynamo/convert_frame.py:844] [4/1523]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.180000 612 torch/_dynamo/convert_frame.py:844] [4/1523] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.180000 612 torch/_dynamo/convert_frame.py:844] [4/1523] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.183000 612 torch/_dynamo/convert_frame.py:844] [4/1524] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.183000 612 torch/_dynamo/convert_frame.py:844] [4/1524]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.183000 612 torch/_dynamo/convert_frame.py:844] [4/1524]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.183000 612 torch/_dynamo/convert_frame.py:844] [4/1524] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.183000 612 torch/_dynamo/convert_frame.py:844] [4/1524] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.186000 612 torch/_dynamo/convert_frame.py:844] [4/1525] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.186000 612 torch/_dynamo/convert_frame.py:844] [4/1525]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.186000 612 torch/_dynamo/convert_frame.py:844] [4/1525]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.186000 612 torch/_dynamo/convert_frame.py:844] [4/1525] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.186000 612 torch/_dynamo/convert_frame.py:844] [4/1525] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.189000 612 torch/_dynamo/convert_frame.py:844] [4/1526] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.189000 612 torch/_dynamo/convert_frame.py:844] [4/1526]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.189000 612 torch/_dynamo/convert_frame.py:844] [4/1526]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.189000 612 torch/_dynamo/convert_frame.py:844] [4/1526] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.189000 612 torch/_dynamo/convert_frame.py:844] [4/1526] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.191000 612 torch/_dynamo/convert_frame.py:844] [4/1527] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.191000 612 torch/_dynamo/convert_frame.py:844] [4/1527]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.191000 612 torch/_dynamo/convert_frame.py:844] [4/1527]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.191000 612 torch/_dynamo/convert_frame.py:844] [4/1527] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.191000 612 torch/_dynamo/convert_frame.py:844] [4/1527] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.195000 612 torch/_dynamo/convert_frame.py:844] [4/1528] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.195000 612 torch/_dynamo/convert_frame.py:844] [4/1528]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.195000 612 torch/_dynamo/convert_frame.py:844] [4/1528]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.195000 612 torch/_dynamo/convert_frame.py:844] [4/1528] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.195000 612 torch/_dynamo/convert_frame.py:844] [4/1528] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.198000 612 torch/_dynamo/convert_frame.py:844] [4/1529] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.198000 612 torch/_dynamo/convert_frame.py:844] [4/1529]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.198000 612 torch/_dynamo/convert_frame.py:844] [4/1529]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.198000 612 torch/_dynamo/convert_frame.py:844] [4/1529] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.198000 612 torch/_dynamo/convert_frame.py:844] [4/1529] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024x     32 |      5.214 |      4.187 |    1.25x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0223 05:56:14.201000 612 torch/_dynamo/convert_frame.py:844] [4/1530] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.201000 612 torch/_dynamo/convert_frame.py:844] [4/1530]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.201000 612 torch/_dynamo/convert_frame.py:844] [4/1530]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.201000 612 torch/_dynamo/convert_frame.py:844] [4/1530] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.201000 612 torch/_dynamo/convert_frame.py:844] [4/1530] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.205000 612 torch/_dynamo/convert_frame.py:844] [4/1531] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.205000 612 torch/_dynamo/convert_frame.py:844] [4/1531]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.205000 612 torch/_dynamo/convert_frame.py:844] [4/1531]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.205000 612 torch/_dynamo/convert_frame.py:844] [4/1531] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.205000 612 torch/_dynamo/convert_frame.py:844] [4/1531] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.208000 612 torch/_dynamo/convert_frame.py:844] [4/1532] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.208000 612 torch/_dynamo/convert_frame.py:844] [4/1532]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.208000 612 torch/_dynamo/convert_frame.py:844] [4/1532]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.208000 612 torch/_dynamo/convert_frame.py:844] [4/1532] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.208000 612 torch/_dynamo/convert_frame.py:844] [4/1532] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.212000 612 torch/_dynamo/convert_frame.py:844] [4/1533] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.212000 612 torch/_dynamo/convert_frame.py:844] [4/1533]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.212000 612 torch/_dynamo/convert_frame.py:844] [4/1533]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.212000 612 torch/_dynamo/convert_frame.py:844] [4/1533] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.212000 612 torch/_dynamo/convert_frame.py:844] [4/1533] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.217000 612 torch/_dynamo/convert_frame.py:844] [4/1534] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.217000 612 torch/_dynamo/convert_frame.py:844] [4/1534]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.217000 612 torch/_dynamo/convert_frame.py:844] [4/1534]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.217000 612 torch/_dynamo/convert_frame.py:844] [4/1534] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.217000 612 torch/_dynamo/convert_frame.py:844] [4/1534] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.221000 612 torch/_dynamo/convert_frame.py:844] [4/1535] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.221000 612 torch/_dynamo/convert_frame.py:844] [4/1535]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.221000 612 torch/_dynamo/convert_frame.py:844] [4/1535]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.221000 612 torch/_dynamo/convert_frame.py:844] [4/1535] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.221000 612 torch/_dynamo/convert_frame.py:844] [4/1535] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.228000 612 torch/_dynamo/convert_frame.py:844] [4/1536] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.228000 612 torch/_dynamo/convert_frame.py:844] [4/1536]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.228000 612 torch/_dynamo/convert_frame.py:844] [4/1536]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.228000 612 torch/_dynamo/convert_frame.py:844] [4/1536] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.228000 612 torch/_dynamo/convert_frame.py:844] [4/1536] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.231000 612 torch/_dynamo/convert_frame.py:844] [4/1537] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.231000 612 torch/_dynamo/convert_frame.py:844] [4/1537]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.231000 612 torch/_dynamo/convert_frame.py:844] [4/1537]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.231000 612 torch/_dynamo/convert_frame.py:844] [4/1537] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.231000 612 torch/_dynamo/convert_frame.py:844] [4/1537] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.234000 612 torch/_dynamo/convert_frame.py:844] [4/1538] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.234000 612 torch/_dynamo/convert_frame.py:844] [4/1538]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.234000 612 torch/_dynamo/convert_frame.py:844] [4/1538]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.234000 612 torch/_dynamo/convert_frame.py:844] [4/1538] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.234000 612 torch/_dynamo/convert_frame.py:844] [4/1538] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.239000 612 torch/_dynamo/convert_frame.py:844] [4/1539] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.239000 612 torch/_dynamo/convert_frame.py:844] [4/1539]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.239000 612 torch/_dynamo/convert_frame.py:844] [4/1539]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.239000 612 torch/_dynamo/convert_frame.py:844] [4/1539] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.239000 612 torch/_dynamo/convert_frame.py:844] [4/1539] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.242000 612 torch/_dynamo/convert_frame.py:844] [4/1540] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.242000 612 torch/_dynamo/convert_frame.py:844] [4/1540]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.242000 612 torch/_dynamo/convert_frame.py:844] [4/1540]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.242000 612 torch/_dynamo/convert_frame.py:844] [4/1540] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.242000 612 torch/_dynamo/convert_frame.py:844] [4/1540] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.245000 612 torch/_dynamo/convert_frame.py:844] [4/1541] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.245000 612 torch/_dynamo/convert_frame.py:844] [4/1541]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.245000 612 torch/_dynamo/convert_frame.py:844] [4/1541]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.245000 612 torch/_dynamo/convert_frame.py:844] [4/1541] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.245000 612 torch/_dynamo/convert_frame.py:844] [4/1541] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.248000 612 torch/_dynamo/convert_frame.py:844] [4/1542] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.248000 612 torch/_dynamo/convert_frame.py:844] [4/1542]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.248000 612 torch/_dynamo/convert_frame.py:844] [4/1542]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.248000 612 torch/_dynamo/convert_frame.py:844] [4/1542] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.248000 612 torch/_dynamo/convert_frame.py:844] [4/1542] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.251000 612 torch/_dynamo/convert_frame.py:844] [4/1543] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.251000 612 torch/_dynamo/convert_frame.py:844] [4/1543]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.251000 612 torch/_dynamo/convert_frame.py:844] [4/1543]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.251000 612 torch/_dynamo/convert_frame.py:844] [4/1543] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.251000 612 torch/_dynamo/convert_frame.py:844] [4/1543] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.254000 612 torch/_dynamo/convert_frame.py:844] [4/1544] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.254000 612 torch/_dynamo/convert_frame.py:844] [4/1544]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.254000 612 torch/_dynamo/convert_frame.py:844] [4/1544]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.254000 612 torch/_dynamo/convert_frame.py:844] [4/1544] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.254000 612 torch/_dynamo/convert_frame.py:844] [4/1544] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.256000 612 torch/_dynamo/convert_frame.py:844] [4/1545] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.256000 612 torch/_dynamo/convert_frame.py:844] [4/1545]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.256000 612 torch/_dynamo/convert_frame.py:844] [4/1545]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.256000 612 torch/_dynamo/convert_frame.py:844] [4/1545] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.256000 612 torch/_dynamo/convert_frame.py:844] [4/1545] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.260000 612 torch/_dynamo/convert_frame.py:844] [4/1546] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.260000 612 torch/_dynamo/convert_frame.py:844] [4/1546]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.260000 612 torch/_dynamo/convert_frame.py:844] [4/1546]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.260000 612 torch/_dynamo/convert_frame.py:844] [4/1546] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.260000 612 torch/_dynamo/convert_frame.py:844] [4/1546] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.262000 612 torch/_dynamo/convert_frame.py:844] [4/1547] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.262000 612 torch/_dynamo/convert_frame.py:844] [4/1547]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.262000 612 torch/_dynamo/convert_frame.py:844] [4/1547]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.262000 612 torch/_dynamo/convert_frame.py:844] [4/1547] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.262000 612 torch/_dynamo/convert_frame.py:844] [4/1547] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.265000 612 torch/_dynamo/convert_frame.py:844] [4/1548] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.265000 612 torch/_dynamo/convert_frame.py:844] [4/1548]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.265000 612 torch/_dynamo/convert_frame.py:844] [4/1548]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.265000 612 torch/_dynamo/convert_frame.py:844] [4/1548] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.265000 612 torch/_dynamo/convert_frame.py:844] [4/1548] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.268000 612 torch/_dynamo/convert_frame.py:844] [4/1549] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.268000 612 torch/_dynamo/convert_frame.py:844] [4/1549]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.268000 612 torch/_dynamo/convert_frame.py:844] [4/1549]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.268000 612 torch/_dynamo/convert_frame.py:844] [4/1549] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.268000 612 torch/_dynamo/convert_frame.py:844] [4/1549] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.271000 612 torch/_dynamo/convert_frame.py:844] [4/1550] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.271000 612 torch/_dynamo/convert_frame.py:844] [4/1550]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.271000 612 torch/_dynamo/convert_frame.py:844] [4/1550]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.271000 612 torch/_dynamo/convert_frame.py:844] [4/1550] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.271000 612 torch/_dynamo/convert_frame.py:844] [4/1550] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.274000 612 torch/_dynamo/convert_frame.py:844] [4/1551] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.274000 612 torch/_dynamo/convert_frame.py:844] [4/1551]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.274000 612 torch/_dynamo/convert_frame.py:844] [4/1551]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.274000 612 torch/_dynamo/convert_frame.py:844] [4/1551] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.274000 612 torch/_dynamo/convert_frame.py:844] [4/1551] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.278000 612 torch/_dynamo/convert_frame.py:844] [4/1552] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.278000 612 torch/_dynamo/convert_frame.py:844] [4/1552]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.278000 612 torch/_dynamo/convert_frame.py:844] [4/1552]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.278000 612 torch/_dynamo/convert_frame.py:844] [4/1552] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.278000 612 torch/_dynamo/convert_frame.py:844] [4/1552] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.281000 612 torch/_dynamo/convert_frame.py:844] [4/1553] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.281000 612 torch/_dynamo/convert_frame.py:844] [4/1553]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.281000 612 torch/_dynamo/convert_frame.py:844] [4/1553]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.281000 612 torch/_dynamo/convert_frame.py:844] [4/1553] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.281000 612 torch/_dynamo/convert_frame.py:844] [4/1553] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.284000 612 torch/_dynamo/convert_frame.py:844] [4/1554] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.284000 612 torch/_dynamo/convert_frame.py:844] [4/1554]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.284000 612 torch/_dynamo/convert_frame.py:844] [4/1554]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.284000 612 torch/_dynamo/convert_frame.py:844] [4/1554] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.284000 612 torch/_dynamo/convert_frame.py:844] [4/1554] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.287000 612 torch/_dynamo/convert_frame.py:844] [4/1555] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.287000 612 torch/_dynamo/convert_frame.py:844] [4/1555]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.287000 612 torch/_dynamo/convert_frame.py:844] [4/1555]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.287000 612 torch/_dynamo/convert_frame.py:844] [4/1555] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.287000 612 torch/_dynamo/convert_frame.py:844] [4/1555] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.289000 612 torch/_dynamo/convert_frame.py:844] [4/1556] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.289000 612 torch/_dynamo/convert_frame.py:844] [4/1556]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.289000 612 torch/_dynamo/convert_frame.py:844] [4/1556]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.289000 612 torch/_dynamo/convert_frame.py:844] [4/1556] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.289000 612 torch/_dynamo/convert_frame.py:844] [4/1556] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.292000 612 torch/_dynamo/convert_frame.py:844] [4/1557] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.292000 612 torch/_dynamo/convert_frame.py:844] [4/1557]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.292000 612 torch/_dynamo/convert_frame.py:844] [4/1557]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.292000 612 torch/_dynamo/convert_frame.py:844] [4/1557] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.292000 612 torch/_dynamo/convert_frame.py:844] [4/1557] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.299000 612 torch/_dynamo/convert_frame.py:844] [4/1558] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.299000 612 torch/_dynamo/convert_frame.py:844] [4/1558]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.299000 612 torch/_dynamo/convert_frame.py:844] [4/1558]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.299000 612 torch/_dynamo/convert_frame.py:844] [4/1558] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.299000 612 torch/_dynamo/convert_frame.py:844] [4/1558] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.305000 612 torch/_dynamo/convert_frame.py:844] [4/1559] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.305000 612 torch/_dynamo/convert_frame.py:844] [4/1559]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.305000 612 torch/_dynamo/convert_frame.py:844] [4/1559]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.305000 612 torch/_dynamo/convert_frame.py:844] [4/1559] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.305000 612 torch/_dynamo/convert_frame.py:844] [4/1559] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.309000 612 torch/_dynamo/convert_frame.py:844] [4/1560] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.309000 612 torch/_dynamo/convert_frame.py:844] [4/1560]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.309000 612 torch/_dynamo/convert_frame.py:844] [4/1560]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.309000 612 torch/_dynamo/convert_frame.py:844] [4/1560] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.309000 612 torch/_dynamo/convert_frame.py:844] [4/1560] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.315000 612 torch/_dynamo/convert_frame.py:844] [4/1561] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.315000 612 torch/_dynamo/convert_frame.py:844] [4/1561]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.315000 612 torch/_dynamo/convert_frame.py:844] [4/1561]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.315000 612 torch/_dynamo/convert_frame.py:844] [4/1561] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.315000 612 torch/_dynamo/convert_frame.py:844] [4/1561] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.320000 612 torch/_dynamo/convert_frame.py:844] [4/1562] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.320000 612 torch/_dynamo/convert_frame.py:844] [4/1562]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.320000 612 torch/_dynamo/convert_frame.py:844] [4/1562]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.320000 612 torch/_dynamo/convert_frame.py:844] [4/1562] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.320000 612 torch/_dynamo/convert_frame.py:844] [4/1562] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.326000 612 torch/_dynamo/convert_frame.py:844] [4/1563] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.326000 612 torch/_dynamo/convert_frame.py:844] [4/1563]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.326000 612 torch/_dynamo/convert_frame.py:844] [4/1563]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.326000 612 torch/_dynamo/convert_frame.py:844] [4/1563] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.326000 612 torch/_dynamo/convert_frame.py:844] [4/1563] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.330000 612 torch/_dynamo/convert_frame.py:844] [4/1564] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.330000 612 torch/_dynamo/convert_frame.py:844] [4/1564]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.330000 612 torch/_dynamo/convert_frame.py:844] [4/1564]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.330000 612 torch/_dynamo/convert_frame.py:844] [4/1564] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.330000 612 torch/_dynamo/convert_frame.py:844] [4/1564] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.337000 612 torch/_dynamo/convert_frame.py:844] [4/1565] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.337000 612 torch/_dynamo/convert_frame.py:844] [4/1565]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.337000 612 torch/_dynamo/convert_frame.py:844] [4/1565]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.337000 612 torch/_dynamo/convert_frame.py:844] [4/1565] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.337000 612 torch/_dynamo/convert_frame.py:844] [4/1565] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.341000 612 torch/_dynamo/convert_frame.py:844] [4/1566] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.341000 612 torch/_dynamo/convert_frame.py:844] [4/1566]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.341000 612 torch/_dynamo/convert_frame.py:844] [4/1566]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.341000 612 torch/_dynamo/convert_frame.py:844] [4/1566] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.341000 612 torch/_dynamo/convert_frame.py:844] [4/1566] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.347000 612 torch/_dynamo/convert_frame.py:844] [4/1567] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.347000 612 torch/_dynamo/convert_frame.py:844] [4/1567]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.347000 612 torch/_dynamo/convert_frame.py:844] [4/1567]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.347000 612 torch/_dynamo/convert_frame.py:844] [4/1567] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.347000 612 torch/_dynamo/convert_frame.py:844] [4/1567] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.353000 612 torch/_dynamo/convert_frame.py:844] [4/1568] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.353000 612 torch/_dynamo/convert_frame.py:844] [4/1568]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.353000 612 torch/_dynamo/convert_frame.py:844] [4/1568]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.353000 612 torch/_dynamo/convert_frame.py:844] [4/1568] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.353000 612 torch/_dynamo/convert_frame.py:844] [4/1568] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.356000 612 torch/_dynamo/convert_frame.py:844] [4/1569] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.356000 612 torch/_dynamo/convert_frame.py:844] [4/1569]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.356000 612 torch/_dynamo/convert_frame.py:844] [4/1569]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.356000 612 torch/_dynamo/convert_frame.py:844] [4/1569] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.356000 612 torch/_dynamo/convert_frame.py:844] [4/1569] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.359000 612 torch/_dynamo/convert_frame.py:844] [4/1570] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.359000 612 torch/_dynamo/convert_frame.py:844] [4/1570]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.359000 612 torch/_dynamo/convert_frame.py:844] [4/1570]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.359000 612 torch/_dynamo/convert_frame.py:844] [4/1570] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.359000 612 torch/_dynamo/convert_frame.py:844] [4/1570] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.362000 612 torch/_dynamo/convert_frame.py:844] [4/1571] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.362000 612 torch/_dynamo/convert_frame.py:844] [4/1571]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.362000 612 torch/_dynamo/convert_frame.py:844] [4/1571]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.362000 612 torch/_dynamo/convert_frame.py:844] [4/1571] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.362000 612 torch/_dynamo/convert_frame.py:844] [4/1571] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.365000 612 torch/_dynamo/convert_frame.py:844] [4/1572] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.365000 612 torch/_dynamo/convert_frame.py:844] [4/1572]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.365000 612 torch/_dynamo/convert_frame.py:844] [4/1572]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.365000 612 torch/_dynamo/convert_frame.py:844] [4/1572] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.365000 612 torch/_dynamo/convert_frame.py:844] [4/1572] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.378000 612 torch/_dynamo/convert_frame.py:844] [4/1573] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.378000 612 torch/_dynamo/convert_frame.py:844] [4/1573]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.378000 612 torch/_dynamo/convert_frame.py:844] [4/1573]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.378000 612 torch/_dynamo/convert_frame.py:844] [4/1573] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.378000 612 torch/_dynamo/convert_frame.py:844] [4/1573] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.389000 612 torch/_dynamo/convert_frame.py:844] [4/1574] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.389000 612 torch/_dynamo/convert_frame.py:844] [4/1574]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.389000 612 torch/_dynamo/convert_frame.py:844] [4/1574]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.389000 612 torch/_dynamo/convert_frame.py:844] [4/1574] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.389000 612 torch/_dynamo/convert_frame.py:844] [4/1574] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.393000 612 torch/_dynamo/convert_frame.py:844] [4/1575] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.393000 612 torch/_dynamo/convert_frame.py:844] [4/1575]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.393000 612 torch/_dynamo/convert_frame.py:844] [4/1575]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.393000 612 torch/_dynamo/convert_frame.py:844] [4/1575] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.393000 612 torch/_dynamo/convert_frame.py:844] [4/1575] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.397000 612 torch/_dynamo/convert_frame.py:844] [4/1576] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.397000 612 torch/_dynamo/convert_frame.py:844] [4/1576]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.397000 612 torch/_dynamo/convert_frame.py:844] [4/1576]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.397000 612 torch/_dynamo/convert_frame.py:844] [4/1576] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.397000 612 torch/_dynamo/convert_frame.py:844] [4/1576] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.400000 612 torch/_dynamo/convert_frame.py:844] [4/1577] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.400000 612 torch/_dynamo/convert_frame.py:844] [4/1577]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.400000 612 torch/_dynamo/convert_frame.py:844] [4/1577]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.400000 612 torch/_dynamo/convert_frame.py:844] [4/1577] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.400000 612 torch/_dynamo/convert_frame.py:844] [4/1577] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.405000 612 torch/_dynamo/convert_frame.py:844] [4/1578] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.405000 612 torch/_dynamo/convert_frame.py:844] [4/1578]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.405000 612 torch/_dynamo/convert_frame.py:844] [4/1578]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.405000 612 torch/_dynamo/convert_frame.py:844] [4/1578] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.405000 612 torch/_dynamo/convert_frame.py:844] [4/1578] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.408000 612 torch/_dynamo/convert_frame.py:844] [4/1579] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.408000 612 torch/_dynamo/convert_frame.py:844] [4/1579]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.408000 612 torch/_dynamo/convert_frame.py:844] [4/1579]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.408000 612 torch/_dynamo/convert_frame.py:844] [4/1579] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.408000 612 torch/_dynamo/convert_frame.py:844] [4/1579] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.411000 612 torch/_dynamo/convert_frame.py:844] [4/1580] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.411000 612 torch/_dynamo/convert_frame.py:844] [4/1580]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.411000 612 torch/_dynamo/convert_frame.py:844] [4/1580]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.411000 612 torch/_dynamo/convert_frame.py:844] [4/1580] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.411000 612 torch/_dynamo/convert_frame.py:844] [4/1580] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.415000 612 torch/_dynamo/convert_frame.py:844] [4/1581] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.415000 612 torch/_dynamo/convert_frame.py:844] [4/1581]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.415000 612 torch/_dynamo/convert_frame.py:844] [4/1581]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.415000 612 torch/_dynamo/convert_frame.py:844] [4/1581] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.415000 612 torch/_dynamo/convert_frame.py:844] [4/1581] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.432000 612 torch/_dynamo/convert_frame.py:844] [4/1582] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.432000 612 torch/_dynamo/convert_frame.py:844] [4/1582]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.432000 612 torch/_dynamo/convert_frame.py:844] [4/1582]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.432000 612 torch/_dynamo/convert_frame.py:844] [4/1582] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.432000 612 torch/_dynamo/convert_frame.py:844] [4/1582] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.443000 612 torch/_dynamo/convert_frame.py:844] [4/1583] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.443000 612 torch/_dynamo/convert_frame.py:844] [4/1583]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.443000 612 torch/_dynamo/convert_frame.py:844] [4/1583]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.443000 612 torch/_dynamo/convert_frame.py:844] [4/1583] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.443000 612 torch/_dynamo/convert_frame.py:844] [4/1583] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.450000 612 torch/_dynamo/convert_frame.py:844] [4/1584] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.450000 612 torch/_dynamo/convert_frame.py:844] [4/1584]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.450000 612 torch/_dynamo/convert_frame.py:844] [4/1584]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.450000 612 torch/_dynamo/convert_frame.py:844] [4/1584] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.450000 612 torch/_dynamo/convert_frame.py:844] [4/1584] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.465000 612 torch/_dynamo/convert_frame.py:844] [4/1585] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.465000 612 torch/_dynamo/convert_frame.py:844] [4/1585]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.465000 612 torch/_dynamo/convert_frame.py:844] [4/1585]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.465000 612 torch/_dynamo/convert_frame.py:844] [4/1585] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.465000 612 torch/_dynamo/convert_frame.py:844] [4/1585] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.471000 612 torch/_dynamo/convert_frame.py:844] [4/1586] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.471000 612 torch/_dynamo/convert_frame.py:844] [4/1586]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.471000 612 torch/_dynamo/convert_frame.py:844] [4/1586]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.471000 612 torch/_dynamo/convert_frame.py:844] [4/1586] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.471000 612 torch/_dynamo/convert_frame.py:844] [4/1586] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.485000 612 torch/_dynamo/convert_frame.py:844] [4/1587] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.485000 612 torch/_dynamo/convert_frame.py:844] [4/1587]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.485000 612 torch/_dynamo/convert_frame.py:844] [4/1587]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.485000 612 torch/_dynamo/convert_frame.py:844] [4/1587] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.485000 612 torch/_dynamo/convert_frame.py:844] [4/1587] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.537000 612 torch/_dynamo/convert_frame.py:844] [4/1588] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.537000 612 torch/_dynamo/convert_frame.py:844] [4/1588]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.537000 612 torch/_dynamo/convert_frame.py:844] [4/1588]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.537000 612 torch/_dynamo/convert_frame.py:844] [4/1588] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.537000 612 torch/_dynamo/convert_frame.py:844] [4/1588] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.569000 612 torch/_dynamo/convert_frame.py:844] [4/1589] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.569000 612 torch/_dynamo/convert_frame.py:844] [4/1589]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.569000 612 torch/_dynamo/convert_frame.py:844] [4/1589]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.569000 612 torch/_dynamo/convert_frame.py:844] [4/1589] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.569000 612 torch/_dynamo/convert_frame.py:844] [4/1589] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.601000 612 torch/_dynamo/convert_frame.py:844] [4/1590] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.601000 612 torch/_dynamo/convert_frame.py:844] [4/1590]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.601000 612 torch/_dynamo/convert_frame.py:844] [4/1590]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.601000 612 torch/_dynamo/convert_frame.py:844] [4/1590] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.601000 612 torch/_dynamo/convert_frame.py:844] [4/1590] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.617000 612 torch/_dynamo/convert_frame.py:844] [4/1591] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.617000 612 torch/_dynamo/convert_frame.py:844] [4/1591]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.617000 612 torch/_dynamo/convert_frame.py:844] [4/1591]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.617000 612 torch/_dynamo/convert_frame.py:844] [4/1591] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.617000 612 torch/_dynamo/convert_frame.py:844] [4/1591] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.632000 612 torch/_dynamo/convert_frame.py:844] [4/1592] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.632000 612 torch/_dynamo/convert_frame.py:844] [4/1592]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.632000 612 torch/_dynamo/convert_frame.py:844] [4/1592]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.632000 612 torch/_dynamo/convert_frame.py:844] [4/1592] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.632000 612 torch/_dynamo/convert_frame.py:844] [4/1592] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.653000 612 torch/_dynamo/convert_frame.py:844] [4/1593] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.653000 612 torch/_dynamo/convert_frame.py:844] [4/1593]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.653000 612 torch/_dynamo/convert_frame.py:844] [4/1593]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.653000 612 torch/_dynamo/convert_frame.py:844] [4/1593] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.653000 612 torch/_dynamo/convert_frame.py:844] [4/1593] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.682000 612 torch/_dynamo/convert_frame.py:844] [4/1594] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.682000 612 torch/_dynamo/convert_frame.py:844] [4/1594]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.682000 612 torch/_dynamo/convert_frame.py:844] [4/1594]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.682000 612 torch/_dynamo/convert_frame.py:844] [4/1594] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.682000 612 torch/_dynamo/convert_frame.py:844] [4/1594] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.711000 612 torch/_dynamo/convert_frame.py:844] [4/1595] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.711000 612 torch/_dynamo/convert_frame.py:844] [4/1595]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.711000 612 torch/_dynamo/convert_frame.py:844] [4/1595]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.711000 612 torch/_dynamo/convert_frame.py:844] [4/1595] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.711000 612 torch/_dynamo/convert_frame.py:844] [4/1595] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.739000 612 torch/_dynamo/convert_frame.py:844] [4/1596] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.739000 612 torch/_dynamo/convert_frame.py:844] [4/1596]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.739000 612 torch/_dynamo/convert_frame.py:844] [4/1596]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.739000 612 torch/_dynamo/convert_frame.py:844] [4/1596] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.739000 612 torch/_dynamo/convert_frame.py:844] [4/1596] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.755000 612 torch/_dynamo/convert_frame.py:844] [4/1597] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.755000 612 torch/_dynamo/convert_frame.py:844] [4/1597]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.755000 612 torch/_dynamo/convert_frame.py:844] [4/1597]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.755000 612 torch/_dynamo/convert_frame.py:844] [4/1597] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.755000 612 torch/_dynamo/convert_frame.py:844] [4/1597] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.768000 612 torch/_dynamo/convert_frame.py:844] [4/1598] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.768000 612 torch/_dynamo/convert_frame.py:844] [4/1598]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.768000 612 torch/_dynamo/convert_frame.py:844] [4/1598]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.768000 612 torch/_dynamo/convert_frame.py:844] [4/1598] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.768000 612 torch/_dynamo/convert_frame.py:844] [4/1598] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.800000 612 torch/_dynamo/convert_frame.py:844] [4/1599] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.800000 612 torch/_dynamo/convert_frame.py:844] [4/1599]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.800000 612 torch/_dynamo/convert_frame.py:844] [4/1599]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.800000 612 torch/_dynamo/convert_frame.py:844] [4/1599] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.800000 612 torch/_dynamo/convert_frame.py:844] [4/1599] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.807000 612 torch/_dynamo/convert_frame.py:844] [4/1600] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.807000 612 torch/_dynamo/convert_frame.py:844] [4/1600]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.807000 612 torch/_dynamo/convert_frame.py:844] [4/1600]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.807000 612 torch/_dynamo/convert_frame.py:844] [4/1600] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.807000 612 torch/_dynamo/convert_frame.py:844] [4/1600] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.821000 612 torch/_dynamo/convert_frame.py:844] [4/1601] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.821000 612 torch/_dynamo/convert_frame.py:844] [4/1601]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.821000 612 torch/_dynamo/convert_frame.py:844] [4/1601]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.821000 612 torch/_dynamo/convert_frame.py:844] [4/1601] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.821000 612 torch/_dynamo/convert_frame.py:844] [4/1601] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.836000 612 torch/_dynamo/convert_frame.py:844] [4/1602] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.836000 612 torch/_dynamo/convert_frame.py:844] [4/1602]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.836000 612 torch/_dynamo/convert_frame.py:844] [4/1602]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.836000 612 torch/_dynamo/convert_frame.py:844] [4/1602] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.836000 612 torch/_dynamo/convert_frame.py:844] [4/1602] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.861000 612 torch/_dynamo/convert_frame.py:844] [4/1603] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.861000 612 torch/_dynamo/convert_frame.py:844] [4/1603]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.861000 612 torch/_dynamo/convert_frame.py:844] [4/1603]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.861000 612 torch/_dynamo/convert_frame.py:844] [4/1603] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.861000 612 torch/_dynamo/convert_frame.py:844] [4/1603] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.868000 612 torch/_dynamo/convert_frame.py:844] [4/1604] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.868000 612 torch/_dynamo/convert_frame.py:844] [4/1604]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.868000 612 torch/_dynamo/convert_frame.py:844] [4/1604]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.868000 612 torch/_dynamo/convert_frame.py:844] [4/1604] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.868000 612 torch/_dynamo/convert_frame.py:844] [4/1604] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.897000 612 torch/_dynamo/convert_frame.py:844] [4/1605] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.897000 612 torch/_dynamo/convert_frame.py:844] [4/1605]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.897000 612 torch/_dynamo/convert_frame.py:844] [4/1605]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.897000 612 torch/_dynamo/convert_frame.py:844] [4/1605] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.897000 612 torch/_dynamo/convert_frame.py:844] [4/1605] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.901000 612 torch/_dynamo/convert_frame.py:844] [4/1606] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.901000 612 torch/_dynamo/convert_frame.py:844] [4/1606]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.901000 612 torch/_dynamo/convert_frame.py:844] [4/1606]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.901000 612 torch/_dynamo/convert_frame.py:844] [4/1606] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.901000 612 torch/_dynamo/convert_frame.py:844] [4/1606] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.909000 612 torch/_dynamo/convert_frame.py:844] [4/1607] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.909000 612 torch/_dynamo/convert_frame.py:844] [4/1607]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.909000 612 torch/_dynamo/convert_frame.py:844] [4/1607]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.909000 612 torch/_dynamo/convert_frame.py:844] [4/1607] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.909000 612 torch/_dynamo/convert_frame.py:844] [4/1607] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.912000 612 torch/_dynamo/convert_frame.py:844] [4/1608] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.912000 612 torch/_dynamo/convert_frame.py:844] [4/1608]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.912000 612 torch/_dynamo/convert_frame.py:844] [4/1608]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.912000 612 torch/_dynamo/convert_frame.py:844] [4/1608] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.912000 612 torch/_dynamo/convert_frame.py:844] [4/1608] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.917000 612 torch/_dynamo/convert_frame.py:844] [4/1609] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.917000 612 torch/_dynamo/convert_frame.py:844] [4/1609]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.917000 612 torch/_dynamo/convert_frame.py:844] [4/1609]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.917000 612 torch/_dynamo/convert_frame.py:844] [4/1609] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.917000 612 torch/_dynamo/convert_frame.py:844] [4/1609] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.920000 612 torch/_dynamo/convert_frame.py:844] [4/1610] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.920000 612 torch/_dynamo/convert_frame.py:844] [4/1610]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.920000 612 torch/_dynamo/convert_frame.py:844] [4/1610]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.920000 612 torch/_dynamo/convert_frame.py:844] [4/1610] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.920000 612 torch/_dynamo/convert_frame.py:844] [4/1610] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.924000 612 torch/_dynamo/convert_frame.py:844] [4/1611] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.924000 612 torch/_dynamo/convert_frame.py:844] [4/1611]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.924000 612 torch/_dynamo/convert_frame.py:844] [4/1611]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.924000 612 torch/_dynamo/convert_frame.py:844] [4/1611] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.924000 612 torch/_dynamo/convert_frame.py:844] [4/1611] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.928000 612 torch/_dynamo/convert_frame.py:844] [4/1612] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.928000 612 torch/_dynamo/convert_frame.py:844] [4/1612]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.928000 612 torch/_dynamo/convert_frame.py:844] [4/1612]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.928000 612 torch/_dynamo/convert_frame.py:844] [4/1612] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.928000 612 torch/_dynamo/convert_frame.py:844] [4/1612] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.933000 612 torch/_dynamo/convert_frame.py:844] [4/1613] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.933000 612 torch/_dynamo/convert_frame.py:844] [4/1613]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.933000 612 torch/_dynamo/convert_frame.py:844] [4/1613]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.933000 612 torch/_dynamo/convert_frame.py:844] [4/1613] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.933000 612 torch/_dynamo/convert_frame.py:844] [4/1613] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.937000 612 torch/_dynamo/convert_frame.py:844] [4/1614] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.937000 612 torch/_dynamo/convert_frame.py:844] [4/1614]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.937000 612 torch/_dynamo/convert_frame.py:844] [4/1614]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.937000 612 torch/_dynamo/convert_frame.py:844] [4/1614] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.937000 612 torch/_dynamo/convert_frame.py:844] [4/1614] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.941000 612 torch/_dynamo/convert_frame.py:844] [4/1615] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.941000 612 torch/_dynamo/convert_frame.py:844] [4/1615]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.941000 612 torch/_dynamo/convert_frame.py:844] [4/1615]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.941000 612 torch/_dynamo/convert_frame.py:844] [4/1615] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.941000 612 torch/_dynamo/convert_frame.py:844] [4/1615] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.944000 612 torch/_dynamo/convert_frame.py:844] [4/1616] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.944000 612 torch/_dynamo/convert_frame.py:844] [4/1616]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.944000 612 torch/_dynamo/convert_frame.py:844] [4/1616]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.944000 612 torch/_dynamo/convert_frame.py:844] [4/1616] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.944000 612 torch/_dynamo/convert_frame.py:844] [4/1616] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.948000 612 torch/_dynamo/convert_frame.py:844] [4/1617] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.948000 612 torch/_dynamo/convert_frame.py:844] [4/1617]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.948000 612 torch/_dynamo/convert_frame.py:844] [4/1617]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.948000 612 torch/_dynamo/convert_frame.py:844] [4/1617] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.948000 612 torch/_dynamo/convert_frame.py:844] [4/1617] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.953000 612 torch/_dynamo/convert_frame.py:844] [4/1618] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.953000 612 torch/_dynamo/convert_frame.py:844] [4/1618]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.953000 612 torch/_dynamo/convert_frame.py:844] [4/1618]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.953000 612 torch/_dynamo/convert_frame.py:844] [4/1618] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.953000 612 torch/_dynamo/convert_frame.py:844] [4/1618] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.957000 612 torch/_dynamo/convert_frame.py:844] [4/1619] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.957000 612 torch/_dynamo/convert_frame.py:844] [4/1619]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.957000 612 torch/_dynamo/convert_frame.py:844] [4/1619]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.957000 612 torch/_dynamo/convert_frame.py:844] [4/1619] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.957000 612 torch/_dynamo/convert_frame.py:844] [4/1619] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.960000 612 torch/_dynamo/convert_frame.py:844] [4/1620] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.960000 612 torch/_dynamo/convert_frame.py:844] [4/1620]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.960000 612 torch/_dynamo/convert_frame.py:844] [4/1620]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.960000 612 torch/_dynamo/convert_frame.py:844] [4/1620] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.960000 612 torch/_dynamo/convert_frame.py:844] [4/1620] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.965000 612 torch/_dynamo/convert_frame.py:844] [4/1621] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.965000 612 torch/_dynamo/convert_frame.py:844] [4/1621]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.965000 612 torch/_dynamo/convert_frame.py:844] [4/1621]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.965000 612 torch/_dynamo/convert_frame.py:844] [4/1621] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.965000 612 torch/_dynamo/convert_frame.py:844] [4/1621] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.969000 612 torch/_dynamo/convert_frame.py:844] [4/1622] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.969000 612 torch/_dynamo/convert_frame.py:844] [4/1622]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.969000 612 torch/_dynamo/convert_frame.py:844] [4/1622]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.969000 612 torch/_dynamo/convert_frame.py:844] [4/1622] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.969000 612 torch/_dynamo/convert_frame.py:844] [4/1622] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.973000 612 torch/_dynamo/convert_frame.py:844] [4/1623] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.973000 612 torch/_dynamo/convert_frame.py:844] [4/1623]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.973000 612 torch/_dynamo/convert_frame.py:844] [4/1623]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.973000 612 torch/_dynamo/convert_frame.py:844] [4/1623] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.973000 612 torch/_dynamo/convert_frame.py:844] [4/1623] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.978000 612 torch/_dynamo/convert_frame.py:844] [4/1624] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.978000 612 torch/_dynamo/convert_frame.py:844] [4/1624]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.978000 612 torch/_dynamo/convert_frame.py:844] [4/1624]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.978000 612 torch/_dynamo/convert_frame.py:844] [4/1624] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.978000 612 torch/_dynamo/convert_frame.py:844] [4/1624] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.982000 612 torch/_dynamo/convert_frame.py:844] [4/1625] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.982000 612 torch/_dynamo/convert_frame.py:844] [4/1625]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.982000 612 torch/_dynamo/convert_frame.py:844] [4/1625]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.982000 612 torch/_dynamo/convert_frame.py:844] [4/1625] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.982000 612 torch/_dynamo/convert_frame.py:844] [4/1625] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.988000 612 torch/_dynamo/convert_frame.py:844] [4/1626] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.988000 612 torch/_dynamo/convert_frame.py:844] [4/1626]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.988000 612 torch/_dynamo/convert_frame.py:844] [4/1626]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.988000 612 torch/_dynamo/convert_frame.py:844] [4/1626] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.988000 612 torch/_dynamo/convert_frame.py:844] [4/1626] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.991000 612 torch/_dynamo/convert_frame.py:844] [4/1627] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.991000 612 torch/_dynamo/convert_frame.py:844] [4/1627]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.991000 612 torch/_dynamo/convert_frame.py:844] [4/1627]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.991000 612 torch/_dynamo/convert_frame.py:844] [4/1627] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.991000 612 torch/_dynamo/convert_frame.py:844] [4/1627] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.996000 612 torch/_dynamo/convert_frame.py:844] [4/1628] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.996000 612 torch/_dynamo/convert_frame.py:844] [4/1628]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.996000 612 torch/_dynamo/convert_frame.py:844] [4/1628]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.996000 612 torch/_dynamo/convert_frame.py:844] [4/1628] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.996000 612 torch/_dynamo/convert_frame.py:844] [4/1628] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:14.999000 612 torch/_dynamo/convert_frame.py:844] [4/1629] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:14.999000 612 torch/_dynamo/convert_frame.py:844] [4/1629]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:14.999000 612 torch/_dynamo/convert_frame.py:844] [4/1629]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:14.999000 612 torch/_dynamo/convert_frame.py:844] [4/1629] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:14.999000 612 torch/_dynamo/convert_frame.py:844] [4/1629] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.006000 612 torch/_dynamo/convert_frame.py:844] [4/1630] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.006000 612 torch/_dynamo/convert_frame.py:844] [4/1630]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.006000 612 torch/_dynamo/convert_frame.py:844] [4/1630]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.006000 612 torch/_dynamo/convert_frame.py:844] [4/1630] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.006000 612 torch/_dynamo/convert_frame.py:844] [4/1630] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.013000 612 torch/_dynamo/convert_frame.py:844] [4/1631] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.013000 612 torch/_dynamo/convert_frame.py:844] [4/1631]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.013000 612 torch/_dynamo/convert_frame.py:844] [4/1631]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.013000 612 torch/_dynamo/convert_frame.py:844] [4/1631] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.013000 612 torch/_dynamo/convert_frame.py:844] [4/1631] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.015000 612 torch/_dynamo/convert_frame.py:844] [4/1632] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.015000 612 torch/_dynamo/convert_frame.py:844] [4/1632]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.015000 612 torch/_dynamo/convert_frame.py:844] [4/1632]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.015000 612 torch/_dynamo/convert_frame.py:844] [4/1632] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.015000 612 torch/_dynamo/convert_frame.py:844] [4/1632] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.024000 612 torch/_dynamo/convert_frame.py:844] [4/1633] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.024000 612 torch/_dynamo/convert_frame.py:844] [4/1633]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.024000 612 torch/_dynamo/convert_frame.py:844] [4/1633]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.024000 612 torch/_dynamo/convert_frame.py:844] [4/1633] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.024000 612 torch/_dynamo/convert_frame.py:844] [4/1633] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.028000 612 torch/_dynamo/convert_frame.py:844] [4/1634] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.028000 612 torch/_dynamo/convert_frame.py:844] [4/1634]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.028000 612 torch/_dynamo/convert_frame.py:844] [4/1634]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.028000 612 torch/_dynamo/convert_frame.py:844] [4/1634] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.028000 612 torch/_dynamo/convert_frame.py:844] [4/1634] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.036000 612 torch/_dynamo/convert_frame.py:844] [4/1635] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.036000 612 torch/_dynamo/convert_frame.py:844] [4/1635]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.036000 612 torch/_dynamo/convert_frame.py:844] [4/1635]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.036000 612 torch/_dynamo/convert_frame.py:844] [4/1635] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.036000 612 torch/_dynamo/convert_frame.py:844] [4/1635] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.041000 612 torch/_dynamo/convert_frame.py:844] [4/1636] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.041000 612 torch/_dynamo/convert_frame.py:844] [4/1636]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.041000 612 torch/_dynamo/convert_frame.py:844] [4/1636]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.041000 612 torch/_dynamo/convert_frame.py:844] [4/1636] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.041000 612 torch/_dynamo/convert_frame.py:844] [4/1636] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.049000 612 torch/_dynamo/convert_frame.py:844] [4/1637] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.049000 612 torch/_dynamo/convert_frame.py:844] [4/1637]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.049000 612 torch/_dynamo/convert_frame.py:844] [4/1637]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.049000 612 torch/_dynamo/convert_frame.py:844] [4/1637] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.049000 612 torch/_dynamo/convert_frame.py:844] [4/1637] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.053000 612 torch/_dynamo/convert_frame.py:844] [4/1638] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.053000 612 torch/_dynamo/convert_frame.py:844] [4/1638]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.053000 612 torch/_dynamo/convert_frame.py:844] [4/1638]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.053000 612 torch/_dynamo/convert_frame.py:844] [4/1638] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.053000 612 torch/_dynamo/convert_frame.py:844] [4/1638] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.056000 612 torch/_dynamo/convert_frame.py:844] [4/1639] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.056000 612 torch/_dynamo/convert_frame.py:844] [4/1639]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.056000 612 torch/_dynamo/convert_frame.py:844] [4/1639]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.056000 612 torch/_dynamo/convert_frame.py:844] [4/1639] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.056000 612 torch/_dynamo/convert_frame.py:844] [4/1639] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.059000 612 torch/_dynamo/convert_frame.py:844] [4/1640] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.059000 612 torch/_dynamo/convert_frame.py:844] [4/1640]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.059000 612 torch/_dynamo/convert_frame.py:844] [4/1640]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.059000 612 torch/_dynamo/convert_frame.py:844] [4/1640] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.059000 612 torch/_dynamo/convert_frame.py:844] [4/1640] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.062000 612 torch/_dynamo/convert_frame.py:844] [4/1641] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.062000 612 torch/_dynamo/convert_frame.py:844] [4/1641]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.062000 612 torch/_dynamo/convert_frame.py:844] [4/1641]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.062000 612 torch/_dynamo/convert_frame.py:844] [4/1641] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.062000 612 torch/_dynamo/convert_frame.py:844] [4/1641] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.064000 612 torch/_dynamo/convert_frame.py:844] [4/1642] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.064000 612 torch/_dynamo/convert_frame.py:844] [4/1642]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.064000 612 torch/_dynamo/convert_frame.py:844] [4/1642]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.064000 612 torch/_dynamo/convert_frame.py:844] [4/1642] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.064000 612 torch/_dynamo/convert_frame.py:844] [4/1642] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.067000 612 torch/_dynamo/convert_frame.py:844] [4/1643] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.067000 612 torch/_dynamo/convert_frame.py:844] [4/1643]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.067000 612 torch/_dynamo/convert_frame.py:844] [4/1643]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.067000 612 torch/_dynamo/convert_frame.py:844] [4/1643] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.067000 612 torch/_dynamo/convert_frame.py:844] [4/1643] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.075000 612 torch/_dynamo/convert_frame.py:844] [4/1644] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.075000 612 torch/_dynamo/convert_frame.py:844] [4/1644]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.075000 612 torch/_dynamo/convert_frame.py:844] [4/1644]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.075000 612 torch/_dynamo/convert_frame.py:844] [4/1644] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.075000 612 torch/_dynamo/convert_frame.py:844] [4/1644] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.079000 612 torch/_dynamo/convert_frame.py:844] [4/1645] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.079000 612 torch/_dynamo/convert_frame.py:844] [4/1645]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.079000 612 torch/_dynamo/convert_frame.py:844] [4/1645]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.079000 612 torch/_dynamo/convert_frame.py:844] [4/1645] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.079000 612 torch/_dynamo/convert_frame.py:844] [4/1645] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.083000 612 torch/_dynamo/convert_frame.py:844] [4/1646] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.083000 612 torch/_dynamo/convert_frame.py:844] [4/1646]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.083000 612 torch/_dynamo/convert_frame.py:844] [4/1646]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.083000 612 torch/_dynamo/convert_frame.py:844] [4/1646] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.083000 612 torch/_dynamo/convert_frame.py:844] [4/1646] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.085000 612 torch/_dynamo/convert_frame.py:844] [4/1647] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.085000 612 torch/_dynamo/convert_frame.py:844] [4/1647]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.085000 612 torch/_dynamo/convert_frame.py:844] [4/1647]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.085000 612 torch/_dynamo/convert_frame.py:844] [4/1647] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.085000 612 torch/_dynamo/convert_frame.py:844] [4/1647] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.088000 612 torch/_dynamo/convert_frame.py:844] [4/1648] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.088000 612 torch/_dynamo/convert_frame.py:844] [4/1648]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.088000 612 torch/_dynamo/convert_frame.py:844] [4/1648]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.088000 612 torch/_dynamo/convert_frame.py:844] [4/1648] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.088000 612 torch/_dynamo/convert_frame.py:844] [4/1648] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.090000 612 torch/_dynamo/convert_frame.py:844] [4/1649] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.090000 612 torch/_dynamo/convert_frame.py:844] [4/1649]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.090000 612 torch/_dynamo/convert_frame.py:844] [4/1649]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.090000 612 torch/_dynamo/convert_frame.py:844] [4/1649] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.090000 612 torch/_dynamo/convert_frame.py:844] [4/1649] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.092000 612 torch/_dynamo/convert_frame.py:844] [4/1650] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.092000 612 torch/_dynamo/convert_frame.py:844] [4/1650]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.092000 612 torch/_dynamo/convert_frame.py:844] [4/1650]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.092000 612 torch/_dynamo/convert_frame.py:844] [4/1650] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.092000 612 torch/_dynamo/convert_frame.py:844] [4/1650] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.095000 612 torch/_dynamo/convert_frame.py:844] [4/1651] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.095000 612 torch/_dynamo/convert_frame.py:844] [4/1651]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.095000 612 torch/_dynamo/convert_frame.py:844] [4/1651]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.095000 612 torch/_dynamo/convert_frame.py:844] [4/1651] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.095000 612 torch/_dynamo/convert_frame.py:844] [4/1651] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.097000 612 torch/_dynamo/convert_frame.py:844] [4/1652] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.097000 612 torch/_dynamo/convert_frame.py:844] [4/1652]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.097000 612 torch/_dynamo/convert_frame.py:844] [4/1652]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.097000 612 torch/_dynamo/convert_frame.py:844] [4/1652] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.097000 612 torch/_dynamo/convert_frame.py:844] [4/1652] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.101000 612 torch/_dynamo/convert_frame.py:844] [4/1653] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.101000 612 torch/_dynamo/convert_frame.py:844] [4/1653]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.101000 612 torch/_dynamo/convert_frame.py:844] [4/1653]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.101000 612 torch/_dynamo/convert_frame.py:844] [4/1653] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.101000 612 torch/_dynamo/convert_frame.py:844] [4/1653] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.104000 612 torch/_dynamo/convert_frame.py:844] [4/1654] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.104000 612 torch/_dynamo/convert_frame.py:844] [4/1654]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.104000 612 torch/_dynamo/convert_frame.py:844] [4/1654]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.104000 612 torch/_dynamo/convert_frame.py:844] [4/1654] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.104000 612 torch/_dynamo/convert_frame.py:844] [4/1654] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.106000 612 torch/_dynamo/convert_frame.py:844] [4/1655] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.106000 612 torch/_dynamo/convert_frame.py:844] [4/1655]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.106000 612 torch/_dynamo/convert_frame.py:844] [4/1655]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.106000 612 torch/_dynamo/convert_frame.py:844] [4/1655] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.106000 612 torch/_dynamo/convert_frame.py:844] [4/1655] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.109000 612 torch/_dynamo/convert_frame.py:844] [4/1656] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.109000 612 torch/_dynamo/convert_frame.py:844] [4/1656]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.109000 612 torch/_dynamo/convert_frame.py:844] [4/1656]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.109000 612 torch/_dynamo/convert_frame.py:844] [4/1656] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.109000 612 torch/_dynamo/convert_frame.py:844] [4/1656] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.112000 612 torch/_dynamo/convert_frame.py:844] [4/1657] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.112000 612 torch/_dynamo/convert_frame.py:844] [4/1657]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.112000 612 torch/_dynamo/convert_frame.py:844] [4/1657]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.112000 612 torch/_dynamo/convert_frame.py:844] [4/1657] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.112000 612 torch/_dynamo/convert_frame.py:844] [4/1657] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.115000 612 torch/_dynamo/convert_frame.py:844] [4/1658] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.115000 612 torch/_dynamo/convert_frame.py:844] [4/1658]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.115000 612 torch/_dynamo/convert_frame.py:844] [4/1658]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.115000 612 torch/_dynamo/convert_frame.py:844] [4/1658] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.115000 612 torch/_dynamo/convert_frame.py:844] [4/1658] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.117000 612 torch/_dynamo/convert_frame.py:844] [4/1659] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.117000 612 torch/_dynamo/convert_frame.py:844] [4/1659]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.117000 612 torch/_dynamo/convert_frame.py:844] [4/1659]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.117000 612 torch/_dynamo/convert_frame.py:844] [4/1659] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.117000 612 torch/_dynamo/convert_frame.py:844] [4/1659] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.120000 612 torch/_dynamo/convert_frame.py:844] [4/1660] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.120000 612 torch/_dynamo/convert_frame.py:844] [4/1660]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.120000 612 torch/_dynamo/convert_frame.py:844] [4/1660]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.120000 612 torch/_dynamo/convert_frame.py:844] [4/1660] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.120000 612 torch/_dynamo/convert_frame.py:844] [4/1660] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.122000 612 torch/_dynamo/convert_frame.py:844] [4/1661] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.122000 612 torch/_dynamo/convert_frame.py:844] [4/1661]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.122000 612 torch/_dynamo/convert_frame.py:844] [4/1661]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.122000 612 torch/_dynamo/convert_frame.py:844] [4/1661] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.122000 612 torch/_dynamo/convert_frame.py:844] [4/1661] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.125000 612 torch/_dynamo/convert_frame.py:844] [4/1662] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.125000 612 torch/_dynamo/convert_frame.py:844] [4/1662]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.125000 612 torch/_dynamo/convert_frame.py:844] [4/1662]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.125000 612 torch/_dynamo/convert_frame.py:844] [4/1662] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.125000 612 torch/_dynamo/convert_frame.py:844] [4/1662] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.128000 612 torch/_dynamo/convert_frame.py:844] [4/1663] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.128000 612 torch/_dynamo/convert_frame.py:844] [4/1663]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.128000 612 torch/_dynamo/convert_frame.py:844] [4/1663]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.128000 612 torch/_dynamo/convert_frame.py:844] [4/1663] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.128000 612 torch/_dynamo/convert_frame.py:844] [4/1663] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.132000 612 torch/_dynamo/convert_frame.py:844] [4/1664] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.132000 612 torch/_dynamo/convert_frame.py:844] [4/1664]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.132000 612 torch/_dynamo/convert_frame.py:844] [4/1664]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.132000 612 torch/_dynamo/convert_frame.py:844] [4/1664] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.132000 612 torch/_dynamo/convert_frame.py:844] [4/1664] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.135000 612 torch/_dynamo/convert_frame.py:844] [4/1665] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.135000 612 torch/_dynamo/convert_frame.py:844] [4/1665]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.135000 612 torch/_dynamo/convert_frame.py:844] [4/1665]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.135000 612 torch/_dynamo/convert_frame.py:844] [4/1665] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.135000 612 torch/_dynamo/convert_frame.py:844] [4/1665] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.138000 612 torch/_dynamo/convert_frame.py:844] [4/1666] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.138000 612 torch/_dynamo/convert_frame.py:844] [4/1666]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.138000 612 torch/_dynamo/convert_frame.py:844] [4/1666]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.138000 612 torch/_dynamo/convert_frame.py:844] [4/1666] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.138000 612 torch/_dynamo/convert_frame.py:844] [4/1666] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.140000 612 torch/_dynamo/convert_frame.py:844] [4/1667] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.140000 612 torch/_dynamo/convert_frame.py:844] [4/1667]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.140000 612 torch/_dynamo/convert_frame.py:844] [4/1667]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.140000 612 torch/_dynamo/convert_frame.py:844] [4/1667] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.140000 612 torch/_dynamo/convert_frame.py:844] [4/1667] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.143000 612 torch/_dynamo/convert_frame.py:844] [4/1668] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.143000 612 torch/_dynamo/convert_frame.py:844] [4/1668]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.143000 612 torch/_dynamo/convert_frame.py:844] [4/1668]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.143000 612 torch/_dynamo/convert_frame.py:844] [4/1668] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.143000 612 torch/_dynamo/convert_frame.py:844] [4/1668] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.147000 612 torch/_dynamo/convert_frame.py:844] [4/1669] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.147000 612 torch/_dynamo/convert_frame.py:844] [4/1669]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.147000 612 torch/_dynamo/convert_frame.py:844] [4/1669]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.147000 612 torch/_dynamo/convert_frame.py:844] [4/1669] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.147000 612 torch/_dynamo/convert_frame.py:844] [4/1669] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.149000 612 torch/_dynamo/convert_frame.py:844] [4/1670] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.149000 612 torch/_dynamo/convert_frame.py:844] [4/1670]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.149000 612 torch/_dynamo/convert_frame.py:844] [4/1670]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.149000 612 torch/_dynamo/convert_frame.py:844] [4/1670] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.149000 612 torch/_dynamo/convert_frame.py:844] [4/1670] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.152000 612 torch/_dynamo/convert_frame.py:844] [4/1671] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.152000 612 torch/_dynamo/convert_frame.py:844] [4/1671]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.152000 612 torch/_dynamo/convert_frame.py:844] [4/1671]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.152000 612 torch/_dynamo/convert_frame.py:844] [4/1671] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.152000 612 torch/_dynamo/convert_frame.py:844] [4/1671] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.157000 612 torch/_dynamo/convert_frame.py:844] [4/1672] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.157000 612 torch/_dynamo/convert_frame.py:844] [4/1672]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.157000 612 torch/_dynamo/convert_frame.py:844] [4/1672]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.157000 612 torch/_dynamo/convert_frame.py:844] [4/1672] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.157000 612 torch/_dynamo/convert_frame.py:844] [4/1672] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.160000 612 torch/_dynamo/convert_frame.py:844] [4/1673] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.160000 612 torch/_dynamo/convert_frame.py:844] [4/1673]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.160000 612 torch/_dynamo/convert_frame.py:844] [4/1673]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.160000 612 torch/_dynamo/convert_frame.py:844] [4/1673] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.160000 612 torch/_dynamo/convert_frame.py:844] [4/1673] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.162000 612 torch/_dynamo/convert_frame.py:844] [4/1674] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.162000 612 torch/_dynamo/convert_frame.py:844] [4/1674]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.162000 612 torch/_dynamo/convert_frame.py:844] [4/1674]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.162000 612 torch/_dynamo/convert_frame.py:844] [4/1674] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.162000 612 torch/_dynamo/convert_frame.py:844] [4/1674] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.165000 612 torch/_dynamo/convert_frame.py:844] [4/1675] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.165000 612 torch/_dynamo/convert_frame.py:844] [4/1675]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.165000 612 torch/_dynamo/convert_frame.py:844] [4/1675]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.165000 612 torch/_dynamo/convert_frame.py:844] [4/1675] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.165000 612 torch/_dynamo/convert_frame.py:844] [4/1675] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.168000 612 torch/_dynamo/convert_frame.py:844] [4/1676] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.168000 612 torch/_dynamo/convert_frame.py:844] [4/1676]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.168000 612 torch/_dynamo/convert_frame.py:844] [4/1676]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.168000 612 torch/_dynamo/convert_frame.py:844] [4/1676] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.168000 612 torch/_dynamo/convert_frame.py:844] [4/1676] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.170000 612 torch/_dynamo/convert_frame.py:844] [4/1677] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.170000 612 torch/_dynamo/convert_frame.py:844] [4/1677]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.170000 612 torch/_dynamo/convert_frame.py:844] [4/1677]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.170000 612 torch/_dynamo/convert_frame.py:844] [4/1677] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.170000 612 torch/_dynamo/convert_frame.py:844] [4/1677] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.174000 612 torch/_dynamo/convert_frame.py:844] [4/1678] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.174000 612 torch/_dynamo/convert_frame.py:844] [4/1678]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.174000 612 torch/_dynamo/convert_frame.py:844] [4/1678]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.174000 612 torch/_dynamo/convert_frame.py:844] [4/1678] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.174000 612 torch/_dynamo/convert_frame.py:844] [4/1678] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.176000 612 torch/_dynamo/convert_frame.py:844] [4/1679] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.176000 612 torch/_dynamo/convert_frame.py:844] [4/1679]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.176000 612 torch/_dynamo/convert_frame.py:844] [4/1679]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.176000 612 torch/_dynamo/convert_frame.py:844] [4/1679] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.176000 612 torch/_dynamo/convert_frame.py:844] [4/1679] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.180000 612 torch/_dynamo/convert_frame.py:844] [4/1680] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.180000 612 torch/_dynamo/convert_frame.py:844] [4/1680]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.180000 612 torch/_dynamo/convert_frame.py:844] [4/1680]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.180000 612 torch/_dynamo/convert_frame.py:844] [4/1680] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.180000 612 torch/_dynamo/convert_frame.py:844] [4/1680] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.188000 612 torch/_dynamo/convert_frame.py:844] [4/1681] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.188000 612 torch/_dynamo/convert_frame.py:844] [4/1681]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.188000 612 torch/_dynamo/convert_frame.py:844] [4/1681]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.188000 612 torch/_dynamo/convert_frame.py:844] [4/1681] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.188000 612 torch/_dynamo/convert_frame.py:844] [4/1681] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.194000 612 torch/_dynamo/convert_frame.py:844] [4/1682] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.194000 612 torch/_dynamo/convert_frame.py:844] [4/1682]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.194000 612 torch/_dynamo/convert_frame.py:844] [4/1682]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.194000 612 torch/_dynamo/convert_frame.py:844] [4/1682] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.194000 612 torch/_dynamo/convert_frame.py:844] [4/1682] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.197000 612 torch/_dynamo/convert_frame.py:844] [4/1683] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.197000 612 torch/_dynamo/convert_frame.py:844] [4/1683]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.197000 612 torch/_dynamo/convert_frame.py:844] [4/1683]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.197000 612 torch/_dynamo/convert_frame.py:844] [4/1683] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.197000 612 torch/_dynamo/convert_frame.py:844] [4/1683] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.200000 612 torch/_dynamo/convert_frame.py:844] [4/1684] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.200000 612 torch/_dynamo/convert_frame.py:844] [4/1684]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.200000 612 torch/_dynamo/convert_frame.py:844] [4/1684]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.200000 612 torch/_dynamo/convert_frame.py:844] [4/1684] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.200000 612 torch/_dynamo/convert_frame.py:844] [4/1684] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.205000 612 torch/_dynamo/convert_frame.py:844] [4/1685] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.205000 612 torch/_dynamo/convert_frame.py:844] [4/1685]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.205000 612 torch/_dynamo/convert_frame.py:844] [4/1685]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.205000 612 torch/_dynamo/convert_frame.py:844] [4/1685] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.205000 612 torch/_dynamo/convert_frame.py:844] [4/1685] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.210000 612 torch/_dynamo/convert_frame.py:844] [4/1686] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.210000 612 torch/_dynamo/convert_frame.py:844] [4/1686]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.210000 612 torch/_dynamo/convert_frame.py:844] [4/1686]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.210000 612 torch/_dynamo/convert_frame.py:844] [4/1686] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.210000 612 torch/_dynamo/convert_frame.py:844] [4/1686] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.213000 612 torch/_dynamo/convert_frame.py:844] [4/1687] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.213000 612 torch/_dynamo/convert_frame.py:844] [4/1687]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.213000 612 torch/_dynamo/convert_frame.py:844] [4/1687]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.213000 612 torch/_dynamo/convert_frame.py:844] [4/1687] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.213000 612 torch/_dynamo/convert_frame.py:844] [4/1687] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.216000 612 torch/_dynamo/convert_frame.py:844] [4/1688] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.216000 612 torch/_dynamo/convert_frame.py:844] [4/1688]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.216000 612 torch/_dynamo/convert_frame.py:844] [4/1688]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.216000 612 torch/_dynamo/convert_frame.py:844] [4/1688] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.216000 612 torch/_dynamo/convert_frame.py:844] [4/1688] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.220000 612 torch/_dynamo/convert_frame.py:844] [4/1689] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.220000 612 torch/_dynamo/convert_frame.py:844] [4/1689]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.220000 612 torch/_dynamo/convert_frame.py:844] [4/1689]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.220000 612 torch/_dynamo/convert_frame.py:844] [4/1689] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.220000 612 torch/_dynamo/convert_frame.py:844] [4/1689] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.223000 612 torch/_dynamo/convert_frame.py:844] [4/1690] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.223000 612 torch/_dynamo/convert_frame.py:844] [4/1690]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.223000 612 torch/_dynamo/convert_frame.py:844] [4/1690]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.223000 612 torch/_dynamo/convert_frame.py:844] [4/1690] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.223000 612 torch/_dynamo/convert_frame.py:844] [4/1690] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.227000 612 torch/_dynamo/convert_frame.py:844] [4/1691] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.227000 612 torch/_dynamo/convert_frame.py:844] [4/1691]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.227000 612 torch/_dynamo/convert_frame.py:844] [4/1691]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.227000 612 torch/_dynamo/convert_frame.py:844] [4/1691] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.227000 612 torch/_dynamo/convert_frame.py:844] [4/1691] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.229000 612 torch/_dynamo/convert_frame.py:844] [4/1692] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.229000 612 torch/_dynamo/convert_frame.py:844] [4/1692]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.229000 612 torch/_dynamo/convert_frame.py:844] [4/1692]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.229000 612 torch/_dynamo/convert_frame.py:844] [4/1692] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.229000 612 torch/_dynamo/convert_frame.py:844] [4/1692] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.232000 612 torch/_dynamo/convert_frame.py:844] [4/1693] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.232000 612 torch/_dynamo/convert_frame.py:844] [4/1693]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.232000 612 torch/_dynamo/convert_frame.py:844] [4/1693]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.232000 612 torch/_dynamo/convert_frame.py:844] [4/1693] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.232000 612 torch/_dynamo/convert_frame.py:844] [4/1693] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.236000 612 torch/_dynamo/convert_frame.py:844] [4/1694] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.236000 612 torch/_dynamo/convert_frame.py:844] [4/1694]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.236000 612 torch/_dynamo/convert_frame.py:844] [4/1694]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.236000 612 torch/_dynamo/convert_frame.py:844] [4/1694] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.236000 612 torch/_dynamo/convert_frame.py:844] [4/1694] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.240000 612 torch/_dynamo/convert_frame.py:844] [4/1695] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.240000 612 torch/_dynamo/convert_frame.py:844] [4/1695]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.240000 612 torch/_dynamo/convert_frame.py:844] [4/1695]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.240000 612 torch/_dynamo/convert_frame.py:844] [4/1695] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.240000 612 torch/_dynamo/convert_frame.py:844] [4/1695] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.243000 612 torch/_dynamo/convert_frame.py:844] [4/1696] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.243000 612 torch/_dynamo/convert_frame.py:844] [4/1696]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.243000 612 torch/_dynamo/convert_frame.py:844] [4/1696]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.243000 612 torch/_dynamo/convert_frame.py:844] [4/1696] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.243000 612 torch/_dynamo/convert_frame.py:844] [4/1696] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.246000 612 torch/_dynamo/convert_frame.py:844] [4/1697] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.246000 612 torch/_dynamo/convert_frame.py:844] [4/1697]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.246000 612 torch/_dynamo/convert_frame.py:844] [4/1697]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.246000 612 torch/_dynamo/convert_frame.py:844] [4/1697] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.246000 612 torch/_dynamo/convert_frame.py:844] [4/1697] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.249000 612 torch/_dynamo/convert_frame.py:844] [4/1698] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.249000 612 torch/_dynamo/convert_frame.py:844] [4/1698]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.249000 612 torch/_dynamo/convert_frame.py:844] [4/1698]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.249000 612 torch/_dynamo/convert_frame.py:844] [4/1698] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.249000 612 torch/_dynamo/convert_frame.py:844] [4/1698] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.252000 612 torch/_dynamo/convert_frame.py:844] [4/1699] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.252000 612 torch/_dynamo/convert_frame.py:844] [4/1699]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.252000 612 torch/_dynamo/convert_frame.py:844] [4/1699]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.252000 612 torch/_dynamo/convert_frame.py:844] [4/1699] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.252000 612 torch/_dynamo/convert_frame.py:844] [4/1699] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.255000 612 torch/_dynamo/convert_frame.py:844] [4/1700] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.255000 612 torch/_dynamo/convert_frame.py:844] [4/1700]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.255000 612 torch/_dynamo/convert_frame.py:844] [4/1700]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.255000 612 torch/_dynamo/convert_frame.py:844] [4/1700] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.255000 612 torch/_dynamo/convert_frame.py:844] [4/1700] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.260000 612 torch/_dynamo/convert_frame.py:844] [4/1701] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.260000 612 torch/_dynamo/convert_frame.py:844] [4/1701]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.260000 612 torch/_dynamo/convert_frame.py:844] [4/1701]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.260000 612 torch/_dynamo/convert_frame.py:844] [4/1701] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.260000 612 torch/_dynamo/convert_frame.py:844] [4/1701] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.263000 612 torch/_dynamo/convert_frame.py:844] [4/1702] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.263000 612 torch/_dynamo/convert_frame.py:844] [4/1702]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.263000 612 torch/_dynamo/convert_frame.py:844] [4/1702]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.263000 612 torch/_dynamo/convert_frame.py:844] [4/1702] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.263000 612 torch/_dynamo/convert_frame.py:844] [4/1702] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.266000 612 torch/_dynamo/convert_frame.py:844] [4/1703] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.266000 612 torch/_dynamo/convert_frame.py:844] [4/1703]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.266000 612 torch/_dynamo/convert_frame.py:844] [4/1703]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.266000 612 torch/_dynamo/convert_frame.py:844] [4/1703] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.266000 612 torch/_dynamo/convert_frame.py:844] [4/1703] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.270000 612 torch/_dynamo/convert_frame.py:844] [4/1704] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.270000 612 torch/_dynamo/convert_frame.py:844] [4/1704]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.270000 612 torch/_dynamo/convert_frame.py:844] [4/1704]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.270000 612 torch/_dynamo/convert_frame.py:844] [4/1704] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.270000 612 torch/_dynamo/convert_frame.py:844] [4/1704] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.273000 612 torch/_dynamo/convert_frame.py:844] [4/1705] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.273000 612 torch/_dynamo/convert_frame.py:844] [4/1705]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.273000 612 torch/_dynamo/convert_frame.py:844] [4/1705]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.273000 612 torch/_dynamo/convert_frame.py:844] [4/1705] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.273000 612 torch/_dynamo/convert_frame.py:844] [4/1705] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.277000 612 torch/_dynamo/convert_frame.py:844] [4/1706] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.277000 612 torch/_dynamo/convert_frame.py:844] [4/1706]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.277000 612 torch/_dynamo/convert_frame.py:844] [4/1706]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.277000 612 torch/_dynamo/convert_frame.py:844] [4/1706] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.277000 612 torch/_dynamo/convert_frame.py:844] [4/1706] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.281000 612 torch/_dynamo/convert_frame.py:844] [4/1707] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.281000 612 torch/_dynamo/convert_frame.py:844] [4/1707]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.281000 612 torch/_dynamo/convert_frame.py:844] [4/1707]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.281000 612 torch/_dynamo/convert_frame.py:844] [4/1707] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.281000 612 torch/_dynamo/convert_frame.py:844] [4/1707] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.285000 612 torch/_dynamo/convert_frame.py:844] [4/1708] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.285000 612 torch/_dynamo/convert_frame.py:844] [4/1708]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.285000 612 torch/_dynamo/convert_frame.py:844] [4/1708]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.285000 612 torch/_dynamo/convert_frame.py:844] [4/1708] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.285000 612 torch/_dynamo/convert_frame.py:844] [4/1708] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.289000 612 torch/_dynamo/convert_frame.py:844] [4/1709] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.289000 612 torch/_dynamo/convert_frame.py:844] [4/1709]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.289000 612 torch/_dynamo/convert_frame.py:844] [4/1709]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.289000 612 torch/_dynamo/convert_frame.py:844] [4/1709] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.289000 612 torch/_dynamo/convert_frame.py:844] [4/1709] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.291000 612 torch/_dynamo/convert_frame.py:844] [4/1710] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.291000 612 torch/_dynamo/convert_frame.py:844] [4/1710]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.291000 612 torch/_dynamo/convert_frame.py:844] [4/1710]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.291000 612 torch/_dynamo/convert_frame.py:844] [4/1710] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.291000 612 torch/_dynamo/convert_frame.py:844] [4/1710] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.296000 612 torch/_dynamo/convert_frame.py:844] [4/1711] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.296000 612 torch/_dynamo/convert_frame.py:844] [4/1711]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.296000 612 torch/_dynamo/convert_frame.py:844] [4/1711]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.296000 612 torch/_dynamo/convert_frame.py:844] [4/1711] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.296000 612 torch/_dynamo/convert_frame.py:844] [4/1711] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.299000 612 torch/_dynamo/convert_frame.py:844] [4/1712] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.299000 612 torch/_dynamo/convert_frame.py:844] [4/1712]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.299000 612 torch/_dynamo/convert_frame.py:844] [4/1712]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.299000 612 torch/_dynamo/convert_frame.py:844] [4/1712] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.299000 612 torch/_dynamo/convert_frame.py:844] [4/1712] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.301000 612 torch/_dynamo/convert_frame.py:844] [4/1713] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.301000 612 torch/_dynamo/convert_frame.py:844] [4/1713]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.301000 612 torch/_dynamo/convert_frame.py:844] [4/1713]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.301000 612 torch/_dynamo/convert_frame.py:844] [4/1713] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.301000 612 torch/_dynamo/convert_frame.py:844] [4/1713] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.305000 612 torch/_dynamo/convert_frame.py:844] [4/1714] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.305000 612 torch/_dynamo/convert_frame.py:844] [4/1714]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.305000 612 torch/_dynamo/convert_frame.py:844] [4/1714]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.305000 612 torch/_dynamo/convert_frame.py:844] [4/1714] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.305000 612 torch/_dynamo/convert_frame.py:844] [4/1714] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.308000 612 torch/_dynamo/convert_frame.py:844] [4/1715] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.308000 612 torch/_dynamo/convert_frame.py:844] [4/1715]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.308000 612 torch/_dynamo/convert_frame.py:844] [4/1715]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.308000 612 torch/_dynamo/convert_frame.py:844] [4/1715] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.308000 612 torch/_dynamo/convert_frame.py:844] [4/1715] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.311000 612 torch/_dynamo/convert_frame.py:844] [4/1716] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.311000 612 torch/_dynamo/convert_frame.py:844] [4/1716]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.311000 612 torch/_dynamo/convert_frame.py:844] [4/1716]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.311000 612 torch/_dynamo/convert_frame.py:844] [4/1716] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.311000 612 torch/_dynamo/convert_frame.py:844] [4/1716] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.315000 612 torch/_dynamo/convert_frame.py:844] [4/1717] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.315000 612 torch/_dynamo/convert_frame.py:844] [4/1717]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.315000 612 torch/_dynamo/convert_frame.py:844] [4/1717]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.315000 612 torch/_dynamo/convert_frame.py:844] [4/1717] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.315000 612 torch/_dynamo/convert_frame.py:844] [4/1717] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.319000 612 torch/_dynamo/convert_frame.py:844] [4/1718] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.319000 612 torch/_dynamo/convert_frame.py:844] [4/1718]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.319000 612 torch/_dynamo/convert_frame.py:844] [4/1718]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.319000 612 torch/_dynamo/convert_frame.py:844] [4/1718] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.319000 612 torch/_dynamo/convert_frame.py:844] [4/1718] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.321000 612 torch/_dynamo/convert_frame.py:844] [4/1719] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.321000 612 torch/_dynamo/convert_frame.py:844] [4/1719]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.321000 612 torch/_dynamo/convert_frame.py:844] [4/1719]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.321000 612 torch/_dynamo/convert_frame.py:844] [4/1719] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.321000 612 torch/_dynamo/convert_frame.py:844] [4/1719] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.324000 612 torch/_dynamo/convert_frame.py:844] [4/1720] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.324000 612 torch/_dynamo/convert_frame.py:844] [4/1720]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.324000 612 torch/_dynamo/convert_frame.py:844] [4/1720]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.324000 612 torch/_dynamo/convert_frame.py:844] [4/1720] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.324000 612 torch/_dynamo/convert_frame.py:844] [4/1720] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.328000 612 torch/_dynamo/convert_frame.py:844] [4/1721] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.328000 612 torch/_dynamo/convert_frame.py:844] [4/1721]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.328000 612 torch/_dynamo/convert_frame.py:844] [4/1721]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.328000 612 torch/_dynamo/convert_frame.py:844] [4/1721] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.328000 612 torch/_dynamo/convert_frame.py:844] [4/1721] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.331000 612 torch/_dynamo/convert_frame.py:844] [4/1722] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.331000 612 torch/_dynamo/convert_frame.py:844] [4/1722]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.331000 612 torch/_dynamo/convert_frame.py:844] [4/1722]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.331000 612 torch/_dynamo/convert_frame.py:844] [4/1722] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.331000 612 torch/_dynamo/convert_frame.py:844] [4/1722] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.335000 612 torch/_dynamo/convert_frame.py:844] [4/1723] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.335000 612 torch/_dynamo/convert_frame.py:844] [4/1723]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.335000 612 torch/_dynamo/convert_frame.py:844] [4/1723]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.335000 612 torch/_dynamo/convert_frame.py:844] [4/1723] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.335000 612 torch/_dynamo/convert_frame.py:844] [4/1723] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.338000 612 torch/_dynamo/convert_frame.py:844] [4/1724] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.338000 612 torch/_dynamo/convert_frame.py:844] [4/1724]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.338000 612 torch/_dynamo/convert_frame.py:844] [4/1724]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.338000 612 torch/_dynamo/convert_frame.py:844] [4/1724] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.338000 612 torch/_dynamo/convert_frame.py:844] [4/1724] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.341000 612 torch/_dynamo/convert_frame.py:844] [4/1725] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.341000 612 torch/_dynamo/convert_frame.py:844] [4/1725]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.341000 612 torch/_dynamo/convert_frame.py:844] [4/1725]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.341000 612 torch/_dynamo/convert_frame.py:844] [4/1725] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.341000 612 torch/_dynamo/convert_frame.py:844] [4/1725] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.345000 612 torch/_dynamo/convert_frame.py:844] [4/1726] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.345000 612 torch/_dynamo/convert_frame.py:844] [4/1726]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.345000 612 torch/_dynamo/convert_frame.py:844] [4/1726]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.345000 612 torch/_dynamo/convert_frame.py:844] [4/1726] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.345000 612 torch/_dynamo/convert_frame.py:844] [4/1726] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.349000 612 torch/_dynamo/convert_frame.py:844] [4/1727] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.349000 612 torch/_dynamo/convert_frame.py:844] [4/1727]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.349000 612 torch/_dynamo/convert_frame.py:844] [4/1727]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.349000 612 torch/_dynamo/convert_frame.py:844] [4/1727] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.349000 612 torch/_dynamo/convert_frame.py:844] [4/1727] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.353000 612 torch/_dynamo/convert_frame.py:844] [4/1728] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.353000 612 torch/_dynamo/convert_frame.py:844] [4/1728]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.353000 612 torch/_dynamo/convert_frame.py:844] [4/1728]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.353000 612 torch/_dynamo/convert_frame.py:844] [4/1728] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.353000 612 torch/_dynamo/convert_frame.py:844] [4/1728] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.357000 612 torch/_dynamo/convert_frame.py:844] [4/1729] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.357000 612 torch/_dynamo/convert_frame.py:844] [4/1729]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.357000 612 torch/_dynamo/convert_frame.py:844] [4/1729]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.357000 612 torch/_dynamo/convert_frame.py:844] [4/1729] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.357000 612 torch/_dynamo/convert_frame.py:844] [4/1729] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.361000 612 torch/_dynamo/convert_frame.py:844] [4/1730] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.361000 612 torch/_dynamo/convert_frame.py:844] [4/1730]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.361000 612 torch/_dynamo/convert_frame.py:844] [4/1730]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.361000 612 torch/_dynamo/convert_frame.py:844] [4/1730] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.361000 612 torch/_dynamo/convert_frame.py:844] [4/1730] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.364000 612 torch/_dynamo/convert_frame.py:844] [4/1731] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.364000 612 torch/_dynamo/convert_frame.py:844] [4/1731]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.364000 612 torch/_dynamo/convert_frame.py:844] [4/1731]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.364000 612 torch/_dynamo/convert_frame.py:844] [4/1731] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.364000 612 torch/_dynamo/convert_frame.py:844] [4/1731] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.368000 612 torch/_dynamo/convert_frame.py:844] [4/1732] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.368000 612 torch/_dynamo/convert_frame.py:844] [4/1732]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.368000 612 torch/_dynamo/convert_frame.py:844] [4/1732]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.368000 612 torch/_dynamo/convert_frame.py:844] [4/1732] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.368000 612 torch/_dynamo/convert_frame.py:844] [4/1732] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.371000 612 torch/_dynamo/convert_frame.py:844] [4/1733] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.371000 612 torch/_dynamo/convert_frame.py:844] [4/1733]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.371000 612 torch/_dynamo/convert_frame.py:844] [4/1733]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.371000 612 torch/_dynamo/convert_frame.py:844] [4/1733] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.371000 612 torch/_dynamo/convert_frame.py:844] [4/1733] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.374000 612 torch/_dynamo/convert_frame.py:844] [4/1734] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.374000 612 torch/_dynamo/convert_frame.py:844] [4/1734]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.374000 612 torch/_dynamo/convert_frame.py:844] [4/1734]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.374000 612 torch/_dynamo/convert_frame.py:844] [4/1734] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.374000 612 torch/_dynamo/convert_frame.py:844] [4/1734] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.377000 612 torch/_dynamo/convert_frame.py:844] [4/1735] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.377000 612 torch/_dynamo/convert_frame.py:844] [4/1735]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.377000 612 torch/_dynamo/convert_frame.py:844] [4/1735]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.377000 612 torch/_dynamo/convert_frame.py:844] [4/1735] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.377000 612 torch/_dynamo/convert_frame.py:844] [4/1735] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32x   1024 |      3.785 |      7.679 |    0.49x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.381000 612 torch/_dynamo/convert_frame.py:844] [4/1736] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.381000 612 torch/_dynamo/convert_frame.py:844] [4/1736]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.381000 612 torch/_dynamo/convert_frame.py:844] [4/1736]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.381000 612 torch/_dynamo/convert_frame.py:844] [4/1736] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.381000 612 torch/_dynamo/convert_frame.py:844] [4/1736] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.383000 612 torch/_dynamo/convert_frame.py:844] [4/1737] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.383000 612 torch/_dynamo/convert_frame.py:844] [4/1737]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.383000 612 torch/_dynamo/convert_frame.py:844] [4/1737]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.383000 612 torch/_dynamo/convert_frame.py:844] [4/1737] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.383000 612 torch/_dynamo/convert_frame.py:844] [4/1737] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.385000 612 torch/_dynamo/convert_frame.py:844] [4/1738] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.385000 612 torch/_dynamo/convert_frame.py:844] [4/1738]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.385000 612 torch/_dynamo/convert_frame.py:844] [4/1738]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.385000 612 torch/_dynamo/convert_frame.py:844] [4/1738] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.385000 612 torch/_dynamo/convert_frame.py:844] [4/1738] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.388000 612 torch/_dynamo/convert_frame.py:844] [4/1739] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.388000 612 torch/_dynamo/convert_frame.py:844] [4/1739]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.388000 612 torch/_dynamo/convert_frame.py:844] [4/1739]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.388000 612 torch/_dynamo/convert_frame.py:844] [4/1739] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.388000 612 torch/_dynamo/convert_frame.py:844] [4/1739] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.391000 612 torch/_dynamo/convert_frame.py:844] [4/1740] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.391000 612 torch/_dynamo/convert_frame.py:844] [4/1740]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.391000 612 torch/_dynamo/convert_frame.py:844] [4/1740]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.391000 612 torch/_dynamo/convert_frame.py:844] [4/1740] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.391000 612 torch/_dynamo/convert_frame.py:844] [4/1740] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.393000 612 torch/_dynamo/convert_frame.py:844] [4/1741] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.393000 612 torch/_dynamo/convert_frame.py:844] [4/1741]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.393000 612 torch/_dynamo/convert_frame.py:844] [4/1741]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.393000 612 torch/_dynamo/convert_frame.py:844] [4/1741] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.393000 612 torch/_dynamo/convert_frame.py:844] [4/1741] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.399000 612 torch/_dynamo/convert_frame.py:844] [4/1742] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.399000 612 torch/_dynamo/convert_frame.py:844] [4/1742]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.399000 612 torch/_dynamo/convert_frame.py:844] [4/1742]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.399000 612 torch/_dynamo/convert_frame.py:844] [4/1742] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.399000 612 torch/_dynamo/convert_frame.py:844] [4/1742] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.401000 612 torch/_dynamo/convert_frame.py:844] [4/1743] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.401000 612 torch/_dynamo/convert_frame.py:844] [4/1743]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.401000 612 torch/_dynamo/convert_frame.py:844] [4/1743]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.401000 612 torch/_dynamo/convert_frame.py:844] [4/1743] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.401000 612 torch/_dynamo/convert_frame.py:844] [4/1743] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.404000 612 torch/_dynamo/convert_frame.py:844] [4/1744] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.404000 612 torch/_dynamo/convert_frame.py:844] [4/1744]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.404000 612 torch/_dynamo/convert_frame.py:844] [4/1744]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.404000 612 torch/_dynamo/convert_frame.py:844] [4/1744] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.404000 612 torch/_dynamo/convert_frame.py:844] [4/1744] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.406000 612 torch/_dynamo/convert_frame.py:844] [4/1745] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.406000 612 torch/_dynamo/convert_frame.py:844] [4/1745]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.406000 612 torch/_dynamo/convert_frame.py:844] [4/1745]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.406000 612 torch/_dynamo/convert_frame.py:844] [4/1745] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.406000 612 torch/_dynamo/convert_frame.py:844] [4/1745] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.409000 612 torch/_dynamo/convert_frame.py:844] [4/1746] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.409000 612 torch/_dynamo/convert_frame.py:844] [4/1746]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.409000 612 torch/_dynamo/convert_frame.py:844] [4/1746]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.409000 612 torch/_dynamo/convert_frame.py:844] [4/1746] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.409000 612 torch/_dynamo/convert_frame.py:844] [4/1746] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.411000 612 torch/_dynamo/convert_frame.py:844] [4/1747] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.411000 612 torch/_dynamo/convert_frame.py:844] [4/1747]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.411000 612 torch/_dynamo/convert_frame.py:844] [4/1747]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.411000 612 torch/_dynamo/convert_frame.py:844] [4/1747] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.411000 612 torch/_dynamo/convert_frame.py:844] [4/1747] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.414000 612 torch/_dynamo/convert_frame.py:844] [4/1748] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.414000 612 torch/_dynamo/convert_frame.py:844] [4/1748]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.414000 612 torch/_dynamo/convert_frame.py:844] [4/1748]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.414000 612 torch/_dynamo/convert_frame.py:844] [4/1748] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.414000 612 torch/_dynamo/convert_frame.py:844] [4/1748] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.416000 612 torch/_dynamo/convert_frame.py:844] [4/1749] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.416000 612 torch/_dynamo/convert_frame.py:844] [4/1749]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.416000 612 torch/_dynamo/convert_frame.py:844] [4/1749]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.416000 612 torch/_dynamo/convert_frame.py:844] [4/1749] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.416000 612 torch/_dynamo/convert_frame.py:844] [4/1749] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.419000 612 torch/_dynamo/convert_frame.py:844] [4/1750] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.419000 612 torch/_dynamo/convert_frame.py:844] [4/1750]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.419000 612 torch/_dynamo/convert_frame.py:844] [4/1750]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.419000 612 torch/_dynamo/convert_frame.py:844] [4/1750] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.419000 612 torch/_dynamo/convert_frame.py:844] [4/1750] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.422000 612 torch/_dynamo/convert_frame.py:844] [4/1751] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.422000 612 torch/_dynamo/convert_frame.py:844] [4/1751]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.422000 612 torch/_dynamo/convert_frame.py:844] [4/1751]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.422000 612 torch/_dynamo/convert_frame.py:844] [4/1751] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.422000 612 torch/_dynamo/convert_frame.py:844] [4/1751] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.426000 612 torch/_dynamo/convert_frame.py:844] [4/1752] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.426000 612 torch/_dynamo/convert_frame.py:844] [4/1752]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.426000 612 torch/_dynamo/convert_frame.py:844] [4/1752]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.426000 612 torch/_dynamo/convert_frame.py:844] [4/1752] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.426000 612 torch/_dynamo/convert_frame.py:844] [4/1752] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.429000 612 torch/_dynamo/convert_frame.py:844] [4/1753] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.429000 612 torch/_dynamo/convert_frame.py:844] [4/1753]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.429000 612 torch/_dynamo/convert_frame.py:844] [4/1753]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.429000 612 torch/_dynamo/convert_frame.py:844] [4/1753] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.429000 612 torch/_dynamo/convert_frame.py:844] [4/1753] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.431000 612 torch/_dynamo/convert_frame.py:844] [4/1754] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.431000 612 torch/_dynamo/convert_frame.py:844] [4/1754]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.431000 612 torch/_dynamo/convert_frame.py:844] [4/1754]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.431000 612 torch/_dynamo/convert_frame.py:844] [4/1754] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.431000 612 torch/_dynamo/convert_frame.py:844] [4/1754] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.434000 612 torch/_dynamo/convert_frame.py:844] [4/1755] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.434000 612 torch/_dynamo/convert_frame.py:844] [4/1755]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.434000 612 torch/_dynamo/convert_frame.py:844] [4/1755]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.434000 612 torch/_dynamo/convert_frame.py:844] [4/1755] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.434000 612 torch/_dynamo/convert_frame.py:844] [4/1755] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.437000 612 torch/_dynamo/convert_frame.py:844] [4/1756] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.437000 612 torch/_dynamo/convert_frame.py:844] [4/1756]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.437000 612 torch/_dynamo/convert_frame.py:844] [4/1756]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.437000 612 torch/_dynamo/convert_frame.py:844] [4/1756] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.437000 612 torch/_dynamo/convert_frame.py:844] [4/1756] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.439000 612 torch/_dynamo/convert_frame.py:844] [4/1757] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.439000 612 torch/_dynamo/convert_frame.py:844] [4/1757]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.439000 612 torch/_dynamo/convert_frame.py:844] [4/1757]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.439000 612 torch/_dynamo/convert_frame.py:844] [4/1757] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.439000 612 torch/_dynamo/convert_frame.py:844] [4/1757] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.442000 612 torch/_dynamo/convert_frame.py:844] [4/1758] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.442000 612 torch/_dynamo/convert_frame.py:844] [4/1758]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.442000 612 torch/_dynamo/convert_frame.py:844] [4/1758]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.442000 612 torch/_dynamo/convert_frame.py:844] [4/1758] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.442000 612 torch/_dynamo/convert_frame.py:844] [4/1758] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.446000 612 torch/_dynamo/convert_frame.py:844] [4/1759] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.446000 612 torch/_dynamo/convert_frame.py:844] [4/1759]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.446000 612 torch/_dynamo/convert_frame.py:844] [4/1759]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.446000 612 torch/_dynamo/convert_frame.py:844] [4/1759] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.446000 612 torch/_dynamo/convert_frame.py:844] [4/1759] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.449000 612 torch/_dynamo/convert_frame.py:844] [4/1760] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.449000 612 torch/_dynamo/convert_frame.py:844] [4/1760]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.449000 612 torch/_dynamo/convert_frame.py:844] [4/1760]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.449000 612 torch/_dynamo/convert_frame.py:844] [4/1760] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.449000 612 torch/_dynamo/convert_frame.py:844] [4/1760] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.452000 612 torch/_dynamo/convert_frame.py:844] [4/1761] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.452000 612 torch/_dynamo/convert_frame.py:844] [4/1761]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.452000 612 torch/_dynamo/convert_frame.py:844] [4/1761]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.452000 612 torch/_dynamo/convert_frame.py:844] [4/1761] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.452000 612 torch/_dynamo/convert_frame.py:844] [4/1761] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.456000 612 torch/_dynamo/convert_frame.py:844] [4/1762] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.456000 612 torch/_dynamo/convert_frame.py:844] [4/1762]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.456000 612 torch/_dynamo/convert_frame.py:844] [4/1762]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.456000 612 torch/_dynamo/convert_frame.py:844] [4/1762] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.456000 612 torch/_dynamo/convert_frame.py:844] [4/1762] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.459000 612 torch/_dynamo/convert_frame.py:844] [4/1763] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.459000 612 torch/_dynamo/convert_frame.py:844] [4/1763]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.459000 612 torch/_dynamo/convert_frame.py:844] [4/1763]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.459000 612 torch/_dynamo/convert_frame.py:844] [4/1763] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.459000 612 torch/_dynamo/convert_frame.py:844] [4/1763] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.461000 612 torch/_dynamo/convert_frame.py:844] [4/1764] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.461000 612 torch/_dynamo/convert_frame.py:844] [4/1764]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.461000 612 torch/_dynamo/convert_frame.py:844] [4/1764]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.461000 612 torch/_dynamo/convert_frame.py:844] [4/1764] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.461000 612 torch/_dynamo/convert_frame.py:844] [4/1764] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.465000 612 torch/_dynamo/convert_frame.py:844] [4/1765] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.465000 612 torch/_dynamo/convert_frame.py:844] [4/1765]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.465000 612 torch/_dynamo/convert_frame.py:844] [4/1765]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.465000 612 torch/_dynamo/convert_frame.py:844] [4/1765] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.465000 612 torch/_dynamo/convert_frame.py:844] [4/1765] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.467000 612 torch/_dynamo/convert_frame.py:844] [4/1766] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.467000 612 torch/_dynamo/convert_frame.py:844] [4/1766]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.467000 612 torch/_dynamo/convert_frame.py:844] [4/1766]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.467000 612 torch/_dynamo/convert_frame.py:844] [4/1766] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.467000 612 torch/_dynamo/convert_frame.py:844] [4/1766] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.470000 612 torch/_dynamo/convert_frame.py:844] [4/1767] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.470000 612 torch/_dynamo/convert_frame.py:844] [4/1767]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.470000 612 torch/_dynamo/convert_frame.py:844] [4/1767]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.470000 612 torch/_dynamo/convert_frame.py:844] [4/1767] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.470000 612 torch/_dynamo/convert_frame.py:844] [4/1767] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.473000 612 torch/_dynamo/convert_frame.py:844] [4/1768] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.473000 612 torch/_dynamo/convert_frame.py:844] [4/1768]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.473000 612 torch/_dynamo/convert_frame.py:844] [4/1768]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.473000 612 torch/_dynamo/convert_frame.py:844] [4/1768] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.473000 612 torch/_dynamo/convert_frame.py:844] [4/1768] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.476000 612 torch/_dynamo/convert_frame.py:844] [4/1769] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.476000 612 torch/_dynamo/convert_frame.py:844] [4/1769]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.476000 612 torch/_dynamo/convert_frame.py:844] [4/1769]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.476000 612 torch/_dynamo/convert_frame.py:844] [4/1769] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.476000 612 torch/_dynamo/convert_frame.py:844] [4/1769] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.479000 612 torch/_dynamo/convert_frame.py:844] [4/1770] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.479000 612 torch/_dynamo/convert_frame.py:844] [4/1770]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.479000 612 torch/_dynamo/convert_frame.py:844] [4/1770]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.479000 612 torch/_dynamo/convert_frame.py:844] [4/1770] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.479000 612 torch/_dynamo/convert_frame.py:844] [4/1770] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.482000 612 torch/_dynamo/convert_frame.py:844] [4/1771] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.482000 612 torch/_dynamo/convert_frame.py:844] [4/1771]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.482000 612 torch/_dynamo/convert_frame.py:844] [4/1771]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.482000 612 torch/_dynamo/convert_frame.py:844] [4/1771] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.482000 612 torch/_dynamo/convert_frame.py:844] [4/1771] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.485000 612 torch/_dynamo/convert_frame.py:844] [4/1772] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.485000 612 torch/_dynamo/convert_frame.py:844] [4/1772]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.485000 612 torch/_dynamo/convert_frame.py:844] [4/1772]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.485000 612 torch/_dynamo/convert_frame.py:844] [4/1772] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.485000 612 torch/_dynamo/convert_frame.py:844] [4/1772] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.487000 612 torch/_dynamo/convert_frame.py:844] [4/1773] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.487000 612 torch/_dynamo/convert_frame.py:844] [4/1773]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.487000 612 torch/_dynamo/convert_frame.py:844] [4/1773]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.487000 612 torch/_dynamo/convert_frame.py:844] [4/1773] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.487000 612 torch/_dynamo/convert_frame.py:844] [4/1773] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.490000 612 torch/_dynamo/convert_frame.py:844] [4/1774] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.490000 612 torch/_dynamo/convert_frame.py:844] [4/1774]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.490000 612 torch/_dynamo/convert_frame.py:844] [4/1774]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.490000 612 torch/_dynamo/convert_frame.py:844] [4/1774] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.490000 612 torch/_dynamo/convert_frame.py:844] [4/1774] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.493000 612 torch/_dynamo/convert_frame.py:844] [4/1775] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.493000 612 torch/_dynamo/convert_frame.py:844] [4/1775]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.493000 612 torch/_dynamo/convert_frame.py:844] [4/1775]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.493000 612 torch/_dynamo/convert_frame.py:844] [4/1775] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.493000 612 torch/_dynamo/convert_frame.py:844] [4/1775] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.495000 612 torch/_dynamo/convert_frame.py:844] [4/1776] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.495000 612 torch/_dynamo/convert_frame.py:844] [4/1776]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.495000 612 torch/_dynamo/convert_frame.py:844] [4/1776]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.495000 612 torch/_dynamo/convert_frame.py:844] [4/1776] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.495000 612 torch/_dynamo/convert_frame.py:844] [4/1776] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.498000 612 torch/_dynamo/convert_frame.py:844] [4/1777] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.498000 612 torch/_dynamo/convert_frame.py:844] [4/1777]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.498000 612 torch/_dynamo/convert_frame.py:844] [4/1777]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.498000 612 torch/_dynamo/convert_frame.py:844] [4/1777] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.498000 612 torch/_dynamo/convert_frame.py:844] [4/1777] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.501000 612 torch/_dynamo/convert_frame.py:844] [4/1778] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.501000 612 torch/_dynamo/convert_frame.py:844] [4/1778]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.501000 612 torch/_dynamo/convert_frame.py:844] [4/1778]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.501000 612 torch/_dynamo/convert_frame.py:844] [4/1778] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.501000 612 torch/_dynamo/convert_frame.py:844] [4/1778] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.504000 612 torch/_dynamo/convert_frame.py:844] [4/1779] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.504000 612 torch/_dynamo/convert_frame.py:844] [4/1779]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.504000 612 torch/_dynamo/convert_frame.py:844] [4/1779]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.504000 612 torch/_dynamo/convert_frame.py:844] [4/1779] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.504000 612 torch/_dynamo/convert_frame.py:844] [4/1779] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.508000 612 torch/_dynamo/convert_frame.py:844] [4/1780] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.508000 612 torch/_dynamo/convert_frame.py:844] [4/1780]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.508000 612 torch/_dynamo/convert_frame.py:844] [4/1780]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.508000 612 torch/_dynamo/convert_frame.py:844] [4/1780] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.508000 612 torch/_dynamo/convert_frame.py:844] [4/1780] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.511000 612 torch/_dynamo/convert_frame.py:844] [4/1781] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.511000 612 torch/_dynamo/convert_frame.py:844] [4/1781]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.511000 612 torch/_dynamo/convert_frame.py:844] [4/1781]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.511000 612 torch/_dynamo/convert_frame.py:844] [4/1781] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.511000 612 torch/_dynamo/convert_frame.py:844] [4/1781] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.514000 612 torch/_dynamo/convert_frame.py:844] [4/1782] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.514000 612 torch/_dynamo/convert_frame.py:844] [4/1782]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.514000 612 torch/_dynamo/convert_frame.py:844] [4/1782]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.514000 612 torch/_dynamo/convert_frame.py:844] [4/1782] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.514000 612 torch/_dynamo/convert_frame.py:844] [4/1782] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.517000 612 torch/_dynamo/convert_frame.py:844] [4/1783] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.517000 612 torch/_dynamo/convert_frame.py:844] [4/1783]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.517000 612 torch/_dynamo/convert_frame.py:844] [4/1783]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.517000 612 torch/_dynamo/convert_frame.py:844] [4/1783] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.517000 612 torch/_dynamo/convert_frame.py:844] [4/1783] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.519000 612 torch/_dynamo/convert_frame.py:844] [4/1784] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.519000 612 torch/_dynamo/convert_frame.py:844] [4/1784]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.519000 612 torch/_dynamo/convert_frame.py:844] [4/1784]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.519000 612 torch/_dynamo/convert_frame.py:844] [4/1784] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.519000 612 torch/_dynamo/convert_frame.py:844] [4/1784] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.522000 612 torch/_dynamo/convert_frame.py:844] [4/1785] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.522000 612 torch/_dynamo/convert_frame.py:844] [4/1785]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.522000 612 torch/_dynamo/convert_frame.py:844] [4/1785]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.522000 612 torch/_dynamo/convert_frame.py:844] [4/1785] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.522000 612 torch/_dynamo/convert_frame.py:844] [4/1785] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.524000 612 torch/_dynamo/convert_frame.py:844] [4/1786] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.524000 612 torch/_dynamo/convert_frame.py:844] [4/1786]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.524000 612 torch/_dynamo/convert_frame.py:844] [4/1786]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.524000 612 torch/_dynamo/convert_frame.py:844] [4/1786] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.524000 612 torch/_dynamo/convert_frame.py:844] [4/1786] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.527000 612 torch/_dynamo/convert_frame.py:844] [4/1787] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.527000 612 torch/_dynamo/convert_frame.py:844] [4/1787]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.527000 612 torch/_dynamo/convert_frame.py:844] [4/1787]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.527000 612 torch/_dynamo/convert_frame.py:844] [4/1787] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.527000 612 torch/_dynamo/convert_frame.py:844] [4/1787] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.530000 612 torch/_dynamo/convert_frame.py:844] [4/1788] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.530000 612 torch/_dynamo/convert_frame.py:844] [4/1788]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.530000 612 torch/_dynamo/convert_frame.py:844] [4/1788]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.530000 612 torch/_dynamo/convert_frame.py:844] [4/1788] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.530000 612 torch/_dynamo/convert_frame.py:844] [4/1788] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.532000 612 torch/_dynamo/convert_frame.py:844] [4/1789] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.532000 612 torch/_dynamo/convert_frame.py:844] [4/1789]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.532000 612 torch/_dynamo/convert_frame.py:844] [4/1789]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.532000 612 torch/_dynamo/convert_frame.py:844] [4/1789] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.532000 612 torch/_dynamo/convert_frame.py:844] [4/1789] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.536000 612 torch/_dynamo/convert_frame.py:844] [4/1790] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.536000 612 torch/_dynamo/convert_frame.py:844] [4/1790]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.536000 612 torch/_dynamo/convert_frame.py:844] [4/1790]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.536000 612 torch/_dynamo/convert_frame.py:844] [4/1790] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.536000 612 torch/_dynamo/convert_frame.py:844] [4/1790] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.539000 612 torch/_dynamo/convert_frame.py:844] [4/1791] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.539000 612 torch/_dynamo/convert_frame.py:844] [4/1791]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.539000 612 torch/_dynamo/convert_frame.py:844] [4/1791]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.539000 612 torch/_dynamo/convert_frame.py:844] [4/1791] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.539000 612 torch/_dynamo/convert_frame.py:844] [4/1791] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.542000 612 torch/_dynamo/convert_frame.py:844] [4/1792] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.542000 612 torch/_dynamo/convert_frame.py:844] [4/1792]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.542000 612 torch/_dynamo/convert_frame.py:844] [4/1792]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.542000 612 torch/_dynamo/convert_frame.py:844] [4/1792] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.542000 612 torch/_dynamo/convert_frame.py:844] [4/1792] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.545000 612 torch/_dynamo/convert_frame.py:844] [4/1793] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.545000 612 torch/_dynamo/convert_frame.py:844] [4/1793]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.545000 612 torch/_dynamo/convert_frame.py:844] [4/1793]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.545000 612 torch/_dynamo/convert_frame.py:844] [4/1793] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.545000 612 torch/_dynamo/convert_frame.py:844] [4/1793] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.548000 612 torch/_dynamo/convert_frame.py:844] [4/1794] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.548000 612 torch/_dynamo/convert_frame.py:844] [4/1794]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.548000 612 torch/_dynamo/convert_frame.py:844] [4/1794]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.548000 612 torch/_dynamo/convert_frame.py:844] [4/1794] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.548000 612 torch/_dynamo/convert_frame.py:844] [4/1794] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.551000 612 torch/_dynamo/convert_frame.py:844] [4/1795] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.551000 612 torch/_dynamo/convert_frame.py:844] [4/1795]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.551000 612 torch/_dynamo/convert_frame.py:844] [4/1795]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.551000 612 torch/_dynamo/convert_frame.py:844] [4/1795] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.551000 612 torch/_dynamo/convert_frame.py:844] [4/1795] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.554000 612 torch/_dynamo/convert_frame.py:844] [4/1796] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.554000 612 torch/_dynamo/convert_frame.py:844] [4/1796]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.554000 612 torch/_dynamo/convert_frame.py:844] [4/1796]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.554000 612 torch/_dynamo/convert_frame.py:844] [4/1796] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.554000 612 torch/_dynamo/convert_frame.py:844] [4/1796] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.557000 612 torch/_dynamo/convert_frame.py:844] [4/1797] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.557000 612 torch/_dynamo/convert_frame.py:844] [4/1797]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.557000 612 torch/_dynamo/convert_frame.py:844] [4/1797]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.557000 612 torch/_dynamo/convert_frame.py:844] [4/1797] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.557000 612 torch/_dynamo/convert_frame.py:844] [4/1797] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.560000 612 torch/_dynamo/convert_frame.py:844] [4/1798] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.560000 612 torch/_dynamo/convert_frame.py:844] [4/1798]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.560000 612 torch/_dynamo/convert_frame.py:844] [4/1798]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.560000 612 torch/_dynamo/convert_frame.py:844] [4/1798] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.560000 612 torch/_dynamo/convert_frame.py:844] [4/1798] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.563000 612 torch/_dynamo/convert_frame.py:844] [4/1799] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.563000 612 torch/_dynamo/convert_frame.py:844] [4/1799]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.563000 612 torch/_dynamo/convert_frame.py:844] [4/1799]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.563000 612 torch/_dynamo/convert_frame.py:844] [4/1799] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.563000 612 torch/_dynamo/convert_frame.py:844] [4/1799] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.566000 612 torch/_dynamo/convert_frame.py:844] [4/1800] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.566000 612 torch/_dynamo/convert_frame.py:844] [4/1800]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.566000 612 torch/_dynamo/convert_frame.py:844] [4/1800]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.566000 612 torch/_dynamo/convert_frame.py:844] [4/1800] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.566000 612 torch/_dynamo/convert_frame.py:844] [4/1800] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.569000 612 torch/_dynamo/convert_frame.py:844] [4/1801] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.569000 612 torch/_dynamo/convert_frame.py:844] [4/1801]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.569000 612 torch/_dynamo/convert_frame.py:844] [4/1801]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.569000 612 torch/_dynamo/convert_frame.py:844] [4/1801] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.569000 612 torch/_dynamo/convert_frame.py:844] [4/1801] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.572000 612 torch/_dynamo/convert_frame.py:844] [4/1802] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.572000 612 torch/_dynamo/convert_frame.py:844] [4/1802]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.572000 612 torch/_dynamo/convert_frame.py:844] [4/1802]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.572000 612 torch/_dynamo/convert_frame.py:844] [4/1802] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.572000 612 torch/_dynamo/convert_frame.py:844] [4/1802] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.575000 612 torch/_dynamo/convert_frame.py:844] [4/1803] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.575000 612 torch/_dynamo/convert_frame.py:844] [4/1803]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.575000 612 torch/_dynamo/convert_frame.py:844] [4/1803]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.575000 612 torch/_dynamo/convert_frame.py:844] [4/1803] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.575000 612 torch/_dynamo/convert_frame.py:844] [4/1803] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.578000 612 torch/_dynamo/convert_frame.py:844] [4/1804] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.578000 612 torch/_dynamo/convert_frame.py:844] [4/1804]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.578000 612 torch/_dynamo/convert_frame.py:844] [4/1804]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.578000 612 torch/_dynamo/convert_frame.py:844] [4/1804] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.578000 612 torch/_dynamo/convert_frame.py:844] [4/1804] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.581000 612 torch/_dynamo/convert_frame.py:844] [4/1805] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.581000 612 torch/_dynamo/convert_frame.py:844] [4/1805]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.581000 612 torch/_dynamo/convert_frame.py:844] [4/1805]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.581000 612 torch/_dynamo/convert_frame.py:844] [4/1805] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.581000 612 torch/_dynamo/convert_frame.py:844] [4/1805] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.583000 612 torch/_dynamo/convert_frame.py:844] [4/1806] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.583000 612 torch/_dynamo/convert_frame.py:844] [4/1806]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.583000 612 torch/_dynamo/convert_frame.py:844] [4/1806]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.583000 612 torch/_dynamo/convert_frame.py:844] [4/1806] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.583000 612 torch/_dynamo/convert_frame.py:844] [4/1806] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.586000 612 torch/_dynamo/convert_frame.py:844] [4/1807] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.586000 612 torch/_dynamo/convert_frame.py:844] [4/1807]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.586000 612 torch/_dynamo/convert_frame.py:844] [4/1807]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.586000 612 torch/_dynamo/convert_frame.py:844] [4/1807] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.586000 612 torch/_dynamo/convert_frame.py:844] [4/1807] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.589000 612 torch/_dynamo/convert_frame.py:844] [4/1808] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.589000 612 torch/_dynamo/convert_frame.py:844] [4/1808]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.589000 612 torch/_dynamo/convert_frame.py:844] [4/1808]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.589000 612 torch/_dynamo/convert_frame.py:844] [4/1808] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.589000 612 torch/_dynamo/convert_frame.py:844] [4/1808] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.591000 612 torch/_dynamo/convert_frame.py:844] [4/1809] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.591000 612 torch/_dynamo/convert_frame.py:844] [4/1809]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.591000 612 torch/_dynamo/convert_frame.py:844] [4/1809]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.591000 612 torch/_dynamo/convert_frame.py:844] [4/1809] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.591000 612 torch/_dynamo/convert_frame.py:844] [4/1809] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.594000 612 torch/_dynamo/convert_frame.py:844] [4/1810] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.594000 612 torch/_dynamo/convert_frame.py:844] [4/1810]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.594000 612 torch/_dynamo/convert_frame.py:844] [4/1810]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.594000 612 torch/_dynamo/convert_frame.py:844] [4/1810] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.594000 612 torch/_dynamo/convert_frame.py:844] [4/1810] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.596000 612 torch/_dynamo/convert_frame.py:844] [4/1811] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.596000 612 torch/_dynamo/convert_frame.py:844] [4/1811]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.596000 612 torch/_dynamo/convert_frame.py:844] [4/1811]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.596000 612 torch/_dynamo/convert_frame.py:844] [4/1811] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.596000 612 torch/_dynamo/convert_frame.py:844] [4/1811] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.599000 612 torch/_dynamo/convert_frame.py:844] [4/1812] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.599000 612 torch/_dynamo/convert_frame.py:844] [4/1812]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.599000 612 torch/_dynamo/convert_frame.py:844] [4/1812]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.599000 612 torch/_dynamo/convert_frame.py:844] [4/1812] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.599000 612 torch/_dynamo/convert_frame.py:844] [4/1812] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.602000 612 torch/_dynamo/convert_frame.py:844] [4/1813] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.602000 612 torch/_dynamo/convert_frame.py:844] [4/1813]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.602000 612 torch/_dynamo/convert_frame.py:844] [4/1813]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.602000 612 torch/_dynamo/convert_frame.py:844] [4/1813] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.602000 612 torch/_dynamo/convert_frame.py:844] [4/1813] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.605000 612 torch/_dynamo/convert_frame.py:844] [4/1814] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.605000 612 torch/_dynamo/convert_frame.py:844] [4/1814]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.605000 612 torch/_dynamo/convert_frame.py:844] [4/1814]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.605000 612 torch/_dynamo/convert_frame.py:844] [4/1814] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.605000 612 torch/_dynamo/convert_frame.py:844] [4/1814] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.607000 612 torch/_dynamo/convert_frame.py:844] [4/1815] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.607000 612 torch/_dynamo/convert_frame.py:844] [4/1815]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.607000 612 torch/_dynamo/convert_frame.py:844] [4/1815]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.607000 612 torch/_dynamo/convert_frame.py:844] [4/1815] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.607000 612 torch/_dynamo/convert_frame.py:844] [4/1815] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.610000 612 torch/_dynamo/convert_frame.py:844] [4/1816] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.610000 612 torch/_dynamo/convert_frame.py:844] [4/1816]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.610000 612 torch/_dynamo/convert_frame.py:844] [4/1816]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.610000 612 torch/_dynamo/convert_frame.py:844] [4/1816] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.610000 612 torch/_dynamo/convert_frame.py:844] [4/1816] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.614000 612 torch/_dynamo/convert_frame.py:844] [4/1817] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.614000 612 torch/_dynamo/convert_frame.py:844] [4/1817]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.614000 612 torch/_dynamo/convert_frame.py:844] [4/1817]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.614000 612 torch/_dynamo/convert_frame.py:844] [4/1817] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.614000 612 torch/_dynamo/convert_frame.py:844] [4/1817] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.617000 612 torch/_dynamo/convert_frame.py:844] [4/1818] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.617000 612 torch/_dynamo/convert_frame.py:844] [4/1818]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.617000 612 torch/_dynamo/convert_frame.py:844] [4/1818]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.617000 612 torch/_dynamo/convert_frame.py:844] [4/1818] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.617000 612 torch/_dynamo/convert_frame.py:844] [4/1818] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.619000 612 torch/_dynamo/convert_frame.py:844] [4/1819] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.619000 612 torch/_dynamo/convert_frame.py:844] [4/1819]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.619000 612 torch/_dynamo/convert_frame.py:844] [4/1819]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.619000 612 torch/_dynamo/convert_frame.py:844] [4/1819] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.619000 612 torch/_dynamo/convert_frame.py:844] [4/1819] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.622000 612 torch/_dynamo/convert_frame.py:844] [4/1820] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.622000 612 torch/_dynamo/convert_frame.py:844] [4/1820]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.622000 612 torch/_dynamo/convert_frame.py:844] [4/1820]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.622000 612 torch/_dynamo/convert_frame.py:844] [4/1820] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.622000 612 torch/_dynamo/convert_frame.py:844] [4/1820] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.625000 612 torch/_dynamo/convert_frame.py:844] [4/1821] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.625000 612 torch/_dynamo/convert_frame.py:844] [4/1821]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.625000 612 torch/_dynamo/convert_frame.py:844] [4/1821]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.625000 612 torch/_dynamo/convert_frame.py:844] [4/1821] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.625000 612 torch/_dynamo/convert_frame.py:844] [4/1821] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.629000 612 torch/_dynamo/convert_frame.py:844] [4/1822] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.629000 612 torch/_dynamo/convert_frame.py:844] [4/1822]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.629000 612 torch/_dynamo/convert_frame.py:844] [4/1822]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.629000 612 torch/_dynamo/convert_frame.py:844] [4/1822] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.629000 612 torch/_dynamo/convert_frame.py:844] [4/1822] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.634000 612 torch/_dynamo/convert_frame.py:844] [4/1823] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.634000 612 torch/_dynamo/convert_frame.py:844] [4/1823]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.634000 612 torch/_dynamo/convert_frame.py:844] [4/1823]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.634000 612 torch/_dynamo/convert_frame.py:844] [4/1823] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.634000 612 torch/_dynamo/convert_frame.py:844] [4/1823] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.638000 612 torch/_dynamo/convert_frame.py:844] [4/1824] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.638000 612 torch/_dynamo/convert_frame.py:844] [4/1824]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.638000 612 torch/_dynamo/convert_frame.py:844] [4/1824]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.638000 612 torch/_dynamo/convert_frame.py:844] [4/1824] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.638000 612 torch/_dynamo/convert_frame.py:844] [4/1824] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.644000 612 torch/_dynamo/convert_frame.py:844] [4/1825] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.644000 612 torch/_dynamo/convert_frame.py:844] [4/1825]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.644000 612 torch/_dynamo/convert_frame.py:844] [4/1825]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.644000 612 torch/_dynamo/convert_frame.py:844] [4/1825] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.644000 612 torch/_dynamo/convert_frame.py:844] [4/1825] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.647000 612 torch/_dynamo/convert_frame.py:844] [4/1826] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.647000 612 torch/_dynamo/convert_frame.py:844] [4/1826]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.647000 612 torch/_dynamo/convert_frame.py:844] [4/1826]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.647000 612 torch/_dynamo/convert_frame.py:844] [4/1826] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.647000 612 torch/_dynamo/convert_frame.py:844] [4/1826] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.650000 612 torch/_dynamo/convert_frame.py:844] [4/1827] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.650000 612 torch/_dynamo/convert_frame.py:844] [4/1827]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.650000 612 torch/_dynamo/convert_frame.py:844] [4/1827]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.650000 612 torch/_dynamo/convert_frame.py:844] [4/1827] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.650000 612 torch/_dynamo/convert_frame.py:844] [4/1827] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.656000 612 torch/_dynamo/convert_frame.py:844] [4/1828] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.656000 612 torch/_dynamo/convert_frame.py:844] [4/1828]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.656000 612 torch/_dynamo/convert_frame.py:844] [4/1828]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.656000 612 torch/_dynamo/convert_frame.py:844] [4/1828] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.656000 612 torch/_dynamo/convert_frame.py:844] [4/1828] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.659000 612 torch/_dynamo/convert_frame.py:844] [4/1829] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.659000 612 torch/_dynamo/convert_frame.py:844] [4/1829]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.659000 612 torch/_dynamo/convert_frame.py:844] [4/1829]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.659000 612 torch/_dynamo/convert_frame.py:844] [4/1829] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.659000 612 torch/_dynamo/convert_frame.py:844] [4/1829] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.662000 612 torch/_dynamo/convert_frame.py:844] [4/1830] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.662000 612 torch/_dynamo/convert_frame.py:844] [4/1830]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.662000 612 torch/_dynamo/convert_frame.py:844] [4/1830]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.662000 612 torch/_dynamo/convert_frame.py:844] [4/1830] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.662000 612 torch/_dynamo/convert_frame.py:844] [4/1830] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.668000 612 torch/_dynamo/convert_frame.py:844] [4/1831] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.668000 612 torch/_dynamo/convert_frame.py:844] [4/1831]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.668000 612 torch/_dynamo/convert_frame.py:844] [4/1831]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.668000 612 torch/_dynamo/convert_frame.py:844] [4/1831] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.668000 612 torch/_dynamo/convert_frame.py:844] [4/1831] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.673000 612 torch/_dynamo/convert_frame.py:844] [4/1832] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.673000 612 torch/_dynamo/convert_frame.py:844] [4/1832]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.673000 612 torch/_dynamo/convert_frame.py:844] [4/1832]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.673000 612 torch/_dynamo/convert_frame.py:844] [4/1832] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.673000 612 torch/_dynamo/convert_frame.py:844] [4/1832] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.678000 612 torch/_dynamo/convert_frame.py:844] [4/1833] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.678000 612 torch/_dynamo/convert_frame.py:844] [4/1833]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.678000 612 torch/_dynamo/convert_frame.py:844] [4/1833]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.678000 612 torch/_dynamo/convert_frame.py:844] [4/1833] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.678000 612 torch/_dynamo/convert_frame.py:844] [4/1833] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.682000 612 torch/_dynamo/convert_frame.py:844] [4/1834] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.682000 612 torch/_dynamo/convert_frame.py:844] [4/1834]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.682000 612 torch/_dynamo/convert_frame.py:844] [4/1834]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.682000 612 torch/_dynamo/convert_frame.py:844] [4/1834] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.682000 612 torch/_dynamo/convert_frame.py:844] [4/1834] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.688000 612 torch/_dynamo/convert_frame.py:844] [4/1835] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.688000 612 torch/_dynamo/convert_frame.py:844] [4/1835]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.688000 612 torch/_dynamo/convert_frame.py:844] [4/1835]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.688000 612 torch/_dynamo/convert_frame.py:844] [4/1835] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.688000 612 torch/_dynamo/convert_frame.py:844] [4/1835] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.691000 612 torch/_dynamo/convert_frame.py:844] [4/1836] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.691000 612 torch/_dynamo/convert_frame.py:844] [4/1836]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.691000 612 torch/_dynamo/convert_frame.py:844] [4/1836]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.691000 612 torch/_dynamo/convert_frame.py:844] [4/1836] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.691000 612 torch/_dynamo/convert_frame.py:844] [4/1836] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.695000 612 torch/_dynamo/convert_frame.py:844] [4/1837] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.695000 612 torch/_dynamo/convert_frame.py:844] [4/1837]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.695000 612 torch/_dynamo/convert_frame.py:844] [4/1837]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.695000 612 torch/_dynamo/convert_frame.py:844] [4/1837] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.695000 612 torch/_dynamo/convert_frame.py:844] [4/1837] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.703000 612 torch/_dynamo/convert_frame.py:844] [4/1838] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.703000 612 torch/_dynamo/convert_frame.py:844] [4/1838]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.703000 612 torch/_dynamo/convert_frame.py:844] [4/1838]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.703000 612 torch/_dynamo/convert_frame.py:844] [4/1838] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.703000 612 torch/_dynamo/convert_frame.py:844] [4/1838] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.708000 612 torch/_dynamo/convert_frame.py:844] [4/1839] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.708000 612 torch/_dynamo/convert_frame.py:844] [4/1839]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.708000 612 torch/_dynamo/convert_frame.py:844] [4/1839]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.708000 612 torch/_dynamo/convert_frame.py:844] [4/1839] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.708000 612 torch/_dynamo/convert_frame.py:844] [4/1839] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.713000 612 torch/_dynamo/convert_frame.py:844] [4/1840] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.713000 612 torch/_dynamo/convert_frame.py:844] [4/1840]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.713000 612 torch/_dynamo/convert_frame.py:844] [4/1840]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.713000 612 torch/_dynamo/convert_frame.py:844] [4/1840] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.713000 612 torch/_dynamo/convert_frame.py:844] [4/1840] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.718000 612 torch/_dynamo/convert_frame.py:844] [4/1841] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.718000 612 torch/_dynamo/convert_frame.py:844] [4/1841]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.718000 612 torch/_dynamo/convert_frame.py:844] [4/1841]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.718000 612 torch/_dynamo/convert_frame.py:844] [4/1841] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.718000 612 torch/_dynamo/convert_frame.py:844] [4/1841] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.725000 612 torch/_dynamo/convert_frame.py:844] [4/1842] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.725000 612 torch/_dynamo/convert_frame.py:844] [4/1842]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.725000 612 torch/_dynamo/convert_frame.py:844] [4/1842]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.725000 612 torch/_dynamo/convert_frame.py:844] [4/1842] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.725000 612 torch/_dynamo/convert_frame.py:844] [4/1842] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.728000 612 torch/_dynamo/convert_frame.py:844] [4/1843] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.728000 612 torch/_dynamo/convert_frame.py:844] [4/1843]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.728000 612 torch/_dynamo/convert_frame.py:844] [4/1843]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.728000 612 torch/_dynamo/convert_frame.py:844] [4/1843] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.728000 612 torch/_dynamo/convert_frame.py:844] [4/1843] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.731000 612 torch/_dynamo/convert_frame.py:844] [4/1844] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.731000 612 torch/_dynamo/convert_frame.py:844] [4/1844]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.731000 612 torch/_dynamo/convert_frame.py:844] [4/1844]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.731000 612 torch/_dynamo/convert_frame.py:844] [4/1844] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.731000 612 torch/_dynamo/convert_frame.py:844] [4/1844] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.741000 612 torch/_dynamo/convert_frame.py:844] [4/1845] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.741000 612 torch/_dynamo/convert_frame.py:844] [4/1845]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.741000 612 torch/_dynamo/convert_frame.py:844] [4/1845]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.741000 612 torch/_dynamo/convert_frame.py:844] [4/1845] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.741000 612 torch/_dynamo/convert_frame.py:844] [4/1845] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.745000 612 torch/_dynamo/convert_frame.py:844] [4/1846] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.745000 612 torch/_dynamo/convert_frame.py:844] [4/1846]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.745000 612 torch/_dynamo/convert_frame.py:844] [4/1846]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.745000 612 torch/_dynamo/convert_frame.py:844] [4/1846] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.745000 612 torch/_dynamo/convert_frame.py:844] [4/1846] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.751000 612 torch/_dynamo/convert_frame.py:844] [4/1847] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.751000 612 torch/_dynamo/convert_frame.py:844] [4/1847]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.751000 612 torch/_dynamo/convert_frame.py:844] [4/1847]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.751000 612 torch/_dynamo/convert_frame.py:844] [4/1847] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.751000 612 torch/_dynamo/convert_frame.py:844] [4/1847] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.755000 612 torch/_dynamo/convert_frame.py:844] [4/1848] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.755000 612 torch/_dynamo/convert_frame.py:844] [4/1848]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.755000 612 torch/_dynamo/convert_frame.py:844] [4/1848]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.755000 612 torch/_dynamo/convert_frame.py:844] [4/1848] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.755000 612 torch/_dynamo/convert_frame.py:844] [4/1848] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.761000 612 torch/_dynamo/convert_frame.py:844] [4/1849] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.761000 612 torch/_dynamo/convert_frame.py:844] [4/1849]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.761000 612 torch/_dynamo/convert_frame.py:844] [4/1849]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.761000 612 torch/_dynamo/convert_frame.py:844] [4/1849] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.761000 612 torch/_dynamo/convert_frame.py:844] [4/1849] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.765000 612 torch/_dynamo/convert_frame.py:844] [4/1850] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.765000 612 torch/_dynamo/convert_frame.py:844] [4/1850]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.765000 612 torch/_dynamo/convert_frame.py:844] [4/1850]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.765000 612 torch/_dynamo/convert_frame.py:844] [4/1850] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.765000 612 torch/_dynamo/convert_frame.py:844] [4/1850] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.773000 612 torch/_dynamo/convert_frame.py:844] [4/1851] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.773000 612 torch/_dynamo/convert_frame.py:844] [4/1851]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.773000 612 torch/_dynamo/convert_frame.py:844] [4/1851]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.773000 612 torch/_dynamo/convert_frame.py:844] [4/1851] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.773000 612 torch/_dynamo/convert_frame.py:844] [4/1851] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.777000 612 torch/_dynamo/convert_frame.py:844] [4/1852] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.777000 612 torch/_dynamo/convert_frame.py:844] [4/1852]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.777000 612 torch/_dynamo/convert_frame.py:844] [4/1852]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.777000 612 torch/_dynamo/convert_frame.py:844] [4/1852] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.777000 612 torch/_dynamo/convert_frame.py:844] [4/1852] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.783000 612 torch/_dynamo/convert_frame.py:844] [4/1853] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.783000 612 torch/_dynamo/convert_frame.py:844] [4/1853]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.783000 612 torch/_dynamo/convert_frame.py:844] [4/1853]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.783000 612 torch/_dynamo/convert_frame.py:844] [4/1853] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.783000 612 torch/_dynamo/convert_frame.py:844] [4/1853] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.789000 612 torch/_dynamo/convert_frame.py:844] [4/1854] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.789000 612 torch/_dynamo/convert_frame.py:844] [4/1854]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.789000 612 torch/_dynamo/convert_frame.py:844] [4/1854]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.789000 612 torch/_dynamo/convert_frame.py:844] [4/1854] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.789000 612 torch/_dynamo/convert_frame.py:844] [4/1854] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.800000 612 torch/_dynamo/convert_frame.py:844] [4/1855] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.800000 612 torch/_dynamo/convert_frame.py:844] [4/1855]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.800000 612 torch/_dynamo/convert_frame.py:844] [4/1855]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.800000 612 torch/_dynamo/convert_frame.py:844] [4/1855] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.800000 612 torch/_dynamo/convert_frame.py:844] [4/1855] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.803000 612 torch/_dynamo/convert_frame.py:844] [4/1856] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.803000 612 torch/_dynamo/convert_frame.py:844] [4/1856]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.803000 612 torch/_dynamo/convert_frame.py:844] [4/1856]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.803000 612 torch/_dynamo/convert_frame.py:844] [4/1856] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.803000 612 torch/_dynamo/convert_frame.py:844] [4/1856] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.809000 612 torch/_dynamo/convert_frame.py:844] [4/1857] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.809000 612 torch/_dynamo/convert_frame.py:844] [4/1857]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.809000 612 torch/_dynamo/convert_frame.py:844] [4/1857]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.809000 612 torch/_dynamo/convert_frame.py:844] [4/1857] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.809000 612 torch/_dynamo/convert_frame.py:844] [4/1857] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.814000 612 torch/_dynamo/convert_frame.py:844] [4/1858] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.814000 612 torch/_dynamo/convert_frame.py:844] [4/1858]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.814000 612 torch/_dynamo/convert_frame.py:844] [4/1858]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.814000 612 torch/_dynamo/convert_frame.py:844] [4/1858] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.814000 612 torch/_dynamo/convert_frame.py:844] [4/1858] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.820000 612 torch/_dynamo/convert_frame.py:844] [4/1859] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.820000 612 torch/_dynamo/convert_frame.py:844] [4/1859]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.820000 612 torch/_dynamo/convert_frame.py:844] [4/1859]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.820000 612 torch/_dynamo/convert_frame.py:844] [4/1859] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.820000 612 torch/_dynamo/convert_frame.py:844] [4/1859] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.827000 612 torch/_dynamo/convert_frame.py:844] [4/1860] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.827000 612 torch/_dynamo/convert_frame.py:844] [4/1860]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.827000 612 torch/_dynamo/convert_frame.py:844] [4/1860]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.827000 612 torch/_dynamo/convert_frame.py:844] [4/1860] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.827000 612 torch/_dynamo/convert_frame.py:844] [4/1860] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.833000 612 torch/_dynamo/convert_frame.py:844] [4/1861] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.833000 612 torch/_dynamo/convert_frame.py:844] [4/1861]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.833000 612 torch/_dynamo/convert_frame.py:844] [4/1861]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.833000 612 torch/_dynamo/convert_frame.py:844] [4/1861] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.833000 612 torch/_dynamo/convert_frame.py:844] [4/1861] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.836000 612 torch/_dynamo/convert_frame.py:844] [4/1862] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.836000 612 torch/_dynamo/convert_frame.py:844] [4/1862]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.836000 612 torch/_dynamo/convert_frame.py:844] [4/1862]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.836000 612 torch/_dynamo/convert_frame.py:844] [4/1862] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.836000 612 torch/_dynamo/convert_frame.py:844] [4/1862] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.844000 612 torch/_dynamo/convert_frame.py:844] [4/1863] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.844000 612 torch/_dynamo/convert_frame.py:844] [4/1863]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.844000 612 torch/_dynamo/convert_frame.py:844] [4/1863]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.844000 612 torch/_dynamo/convert_frame.py:844] [4/1863] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.844000 612 torch/_dynamo/convert_frame.py:844] [4/1863] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.847000 612 torch/_dynamo/convert_frame.py:844] [4/1864] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.847000 612 torch/_dynamo/convert_frame.py:844] [4/1864]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.847000 612 torch/_dynamo/convert_frame.py:844] [4/1864]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.847000 612 torch/_dynamo/convert_frame.py:844] [4/1864] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.847000 612 torch/_dynamo/convert_frame.py:844] [4/1864] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.851000 612 torch/_dynamo/convert_frame.py:844] [4/1865] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.851000 612 torch/_dynamo/convert_frame.py:844] [4/1865]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.851000 612 torch/_dynamo/convert_frame.py:844] [4/1865]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.851000 612 torch/_dynamo/convert_frame.py:844] [4/1865] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.851000 612 torch/_dynamo/convert_frame.py:844] [4/1865] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.854000 612 torch/_dynamo/convert_frame.py:844] [4/1866] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.854000 612 torch/_dynamo/convert_frame.py:844] [4/1866]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.854000 612 torch/_dynamo/convert_frame.py:844] [4/1866]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.854000 612 torch/_dynamo/convert_frame.py:844] [4/1866] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.854000 612 torch/_dynamo/convert_frame.py:844] [4/1866] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.859000 612 torch/_dynamo/convert_frame.py:844] [4/1867] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.859000 612 torch/_dynamo/convert_frame.py:844] [4/1867]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.859000 612 torch/_dynamo/convert_frame.py:844] [4/1867]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.859000 612 torch/_dynamo/convert_frame.py:844] [4/1867] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.859000 612 torch/_dynamo/convert_frame.py:844] [4/1867] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.863000 612 torch/_dynamo/convert_frame.py:844] [4/1868] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.863000 612 torch/_dynamo/convert_frame.py:844] [4/1868]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.863000 612 torch/_dynamo/convert_frame.py:844] [4/1868]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.863000 612 torch/_dynamo/convert_frame.py:844] [4/1868] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.863000 612 torch/_dynamo/convert_frame.py:844] [4/1868] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.867000 612 torch/_dynamo/convert_frame.py:844] [4/1869] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.867000 612 torch/_dynamo/convert_frame.py:844] [4/1869]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.867000 612 torch/_dynamo/convert_frame.py:844] [4/1869]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.867000 612 torch/_dynamo/convert_frame.py:844] [4/1869] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.867000 612 torch/_dynamo/convert_frame.py:844] [4/1869] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.871000 612 torch/_dynamo/convert_frame.py:844] [4/1870] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.871000 612 torch/_dynamo/convert_frame.py:844] [4/1870]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.871000 612 torch/_dynamo/convert_frame.py:844] [4/1870]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.871000 612 torch/_dynamo/convert_frame.py:844] [4/1870] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.871000 612 torch/_dynamo/convert_frame.py:844] [4/1870] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.877000 612 torch/_dynamo/convert_frame.py:844] [4/1871] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.877000 612 torch/_dynamo/convert_frame.py:844] [4/1871]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.877000 612 torch/_dynamo/convert_frame.py:844] [4/1871]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.877000 612 torch/_dynamo/convert_frame.py:844] [4/1871] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.877000 612 torch/_dynamo/convert_frame.py:844] [4/1871] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.881000 612 torch/_dynamo/convert_frame.py:844] [4/1872] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.881000 612 torch/_dynamo/convert_frame.py:844] [4/1872]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.881000 612 torch/_dynamo/convert_frame.py:844] [4/1872]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.881000 612 torch/_dynamo/convert_frame.py:844] [4/1872] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.881000 612 torch/_dynamo/convert_frame.py:844] [4/1872] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.888000 612 torch/_dynamo/convert_frame.py:844] [4/1873] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.888000 612 torch/_dynamo/convert_frame.py:844] [4/1873]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.888000 612 torch/_dynamo/convert_frame.py:844] [4/1873]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.888000 612 torch/_dynamo/convert_frame.py:844] [4/1873] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.888000 612 torch/_dynamo/convert_frame.py:844] [4/1873] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.892000 612 torch/_dynamo/convert_frame.py:844] [4/1874] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.892000 612 torch/_dynamo/convert_frame.py:844] [4/1874]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.892000 612 torch/_dynamo/convert_frame.py:844] [4/1874]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.892000 612 torch/_dynamo/convert_frame.py:844] [4/1874] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.892000 612 torch/_dynamo/convert_frame.py:844] [4/1874] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.897000 612 torch/_dynamo/convert_frame.py:844] [4/1875] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.897000 612 torch/_dynamo/convert_frame.py:844] [4/1875]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.897000 612 torch/_dynamo/convert_frame.py:844] [4/1875]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.897000 612 torch/_dynamo/convert_frame.py:844] [4/1875] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.897000 612 torch/_dynamo/convert_frame.py:844] [4/1875] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.901000 612 torch/_dynamo/convert_frame.py:844] [4/1876] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.901000 612 torch/_dynamo/convert_frame.py:844] [4/1876]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.901000 612 torch/_dynamo/convert_frame.py:844] [4/1876]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.901000 612 torch/_dynamo/convert_frame.py:844] [4/1876] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.901000 612 torch/_dynamo/convert_frame.py:844] [4/1876] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.905000 612 torch/_dynamo/convert_frame.py:844] [4/1877] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.905000 612 torch/_dynamo/convert_frame.py:844] [4/1877]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.905000 612 torch/_dynamo/convert_frame.py:844] [4/1877]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.905000 612 torch/_dynamo/convert_frame.py:844] [4/1877] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.905000 612 torch/_dynamo/convert_frame.py:844] [4/1877] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.910000 612 torch/_dynamo/convert_frame.py:844] [4/1878] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.910000 612 torch/_dynamo/convert_frame.py:844] [4/1878]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.910000 612 torch/_dynamo/convert_frame.py:844] [4/1878]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.910000 612 torch/_dynamo/convert_frame.py:844] [4/1878] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.910000 612 torch/_dynamo/convert_frame.py:844] [4/1878] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.916000 612 torch/_dynamo/convert_frame.py:844] [4/1879] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.916000 612 torch/_dynamo/convert_frame.py:844] [4/1879]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.916000 612 torch/_dynamo/convert_frame.py:844] [4/1879]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.916000 612 torch/_dynamo/convert_frame.py:844] [4/1879] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.916000 612 torch/_dynamo/convert_frame.py:844] [4/1879] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.920000 612 torch/_dynamo/convert_frame.py:844] [4/1880] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.920000 612 torch/_dynamo/convert_frame.py:844] [4/1880]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.920000 612 torch/_dynamo/convert_frame.py:844] [4/1880]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.920000 612 torch/_dynamo/convert_frame.py:844] [4/1880] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.920000 612 torch/_dynamo/convert_frame.py:844] [4/1880] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.924000 612 torch/_dynamo/convert_frame.py:844] [4/1881] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.924000 612 torch/_dynamo/convert_frame.py:844] [4/1881]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.924000 612 torch/_dynamo/convert_frame.py:844] [4/1881]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.924000 612 torch/_dynamo/convert_frame.py:844] [4/1881] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.924000 612 torch/_dynamo/convert_frame.py:844] [4/1881] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.930000 612 torch/_dynamo/convert_frame.py:844] [4/1882] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.930000 612 torch/_dynamo/convert_frame.py:844] [4/1882]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.930000 612 torch/_dynamo/convert_frame.py:844] [4/1882]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.930000 612 torch/_dynamo/convert_frame.py:844] [4/1882] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.930000 612 torch/_dynamo/convert_frame.py:844] [4/1882] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.934000 612 torch/_dynamo/convert_frame.py:844] [4/1883] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.934000 612 torch/_dynamo/convert_frame.py:844] [4/1883]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.934000 612 torch/_dynamo/convert_frame.py:844] [4/1883]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.934000 612 torch/_dynamo/convert_frame.py:844] [4/1883] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.934000 612 torch/_dynamo/convert_frame.py:844] [4/1883] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.938000 612 torch/_dynamo/convert_frame.py:844] [4/1884] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.938000 612 torch/_dynamo/convert_frame.py:844] [4/1884]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.938000 612 torch/_dynamo/convert_frame.py:844] [4/1884]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.938000 612 torch/_dynamo/convert_frame.py:844] [4/1884] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.938000 612 torch/_dynamo/convert_frame.py:844] [4/1884] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.942000 612 torch/_dynamo/convert_frame.py:844] [4/1885] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.942000 612 torch/_dynamo/convert_frame.py:844] [4/1885]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.942000 612 torch/_dynamo/convert_frame.py:844] [4/1885]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.942000 612 torch/_dynamo/convert_frame.py:844] [4/1885] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.942000 612 torch/_dynamo/convert_frame.py:844] [4/1885] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.947000 612 torch/_dynamo/convert_frame.py:844] [4/1886] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.947000 612 torch/_dynamo/convert_frame.py:844] [4/1886]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.947000 612 torch/_dynamo/convert_frame.py:844] [4/1886]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.947000 612 torch/_dynamo/convert_frame.py:844] [4/1886] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.947000 612 torch/_dynamo/convert_frame.py:844] [4/1886] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.950000 612 torch/_dynamo/convert_frame.py:844] [4/1887] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.950000 612 torch/_dynamo/convert_frame.py:844] [4/1887]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.950000 612 torch/_dynamo/convert_frame.py:844] [4/1887]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.950000 612 torch/_dynamo/convert_frame.py:844] [4/1887] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.950000 612 torch/_dynamo/convert_frame.py:844] [4/1887] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.955000 612 torch/_dynamo/convert_frame.py:844] [4/1888] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.955000 612 torch/_dynamo/convert_frame.py:844] [4/1888]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.955000 612 torch/_dynamo/convert_frame.py:844] [4/1888]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.955000 612 torch/_dynamo/convert_frame.py:844] [4/1888] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.955000 612 torch/_dynamo/convert_frame.py:844] [4/1888] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.960000 612 torch/_dynamo/convert_frame.py:844] [4/1889] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.960000 612 torch/_dynamo/convert_frame.py:844] [4/1889]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.960000 612 torch/_dynamo/convert_frame.py:844] [4/1889]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.960000 612 torch/_dynamo/convert_frame.py:844] [4/1889] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.960000 612 torch/_dynamo/convert_frame.py:844] [4/1889] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.966000 612 torch/_dynamo/convert_frame.py:844] [4/1890] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.966000 612 torch/_dynamo/convert_frame.py:844] [4/1890]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.966000 612 torch/_dynamo/convert_frame.py:844] [4/1890]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.966000 612 torch/_dynamo/convert_frame.py:844] [4/1890] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.966000 612 torch/_dynamo/convert_frame.py:844] [4/1890] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.977000 612 torch/_dynamo/convert_frame.py:844] [4/1891] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.977000 612 torch/_dynamo/convert_frame.py:844] [4/1891]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.977000 612 torch/_dynamo/convert_frame.py:844] [4/1891]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.977000 612 torch/_dynamo/convert_frame.py:844] [4/1891] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.977000 612 torch/_dynamo/convert_frame.py:844] [4/1891] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.983000 612 torch/_dynamo/convert_frame.py:844] [4/1892] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.983000 612 torch/_dynamo/convert_frame.py:844] [4/1892]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.983000 612 torch/_dynamo/convert_frame.py:844] [4/1892]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.983000 612 torch/_dynamo/convert_frame.py:844] [4/1892] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.983000 612 torch/_dynamo/convert_frame.py:844] [4/1892] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:15.995000 612 torch/_dynamo/convert_frame.py:844] [4/1893] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:15.995000 612 torch/_dynamo/convert_frame.py:844] [4/1893]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:15.995000 612 torch/_dynamo/convert_frame.py:844] [4/1893]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:15.995000 612 torch/_dynamo/convert_frame.py:844] [4/1893] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:15.995000 612 torch/_dynamo/convert_frame.py:844] [4/1893] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.001000 612 torch/_dynamo/convert_frame.py:844] [4/1894] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.001000 612 torch/_dynamo/convert_frame.py:844] [4/1894]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.001000 612 torch/_dynamo/convert_frame.py:844] [4/1894]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.001000 612 torch/_dynamo/convert_frame.py:844] [4/1894] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.001000 612 torch/_dynamo/convert_frame.py:844] [4/1894] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.011000 612 torch/_dynamo/convert_frame.py:844] [4/1895] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.011000 612 torch/_dynamo/convert_frame.py:844] [4/1895]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.011000 612 torch/_dynamo/convert_frame.py:844] [4/1895]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.011000 612 torch/_dynamo/convert_frame.py:844] [4/1895] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.011000 612 torch/_dynamo/convert_frame.py:844] [4/1895] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.016000 612 torch/_dynamo/convert_frame.py:844] [4/1896] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.016000 612 torch/_dynamo/convert_frame.py:844] [4/1896]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.016000 612 torch/_dynamo/convert_frame.py:844] [4/1896]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.016000 612 torch/_dynamo/convert_frame.py:844] [4/1896] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.016000 612 torch/_dynamo/convert_frame.py:844] [4/1896] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.027000 612 torch/_dynamo/convert_frame.py:844] [4/1897] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.027000 612 torch/_dynamo/convert_frame.py:844] [4/1897]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.027000 612 torch/_dynamo/convert_frame.py:844] [4/1897]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.027000 612 torch/_dynamo/convert_frame.py:844] [4/1897] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.027000 612 torch/_dynamo/convert_frame.py:844] [4/1897] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.037000 612 torch/_dynamo/convert_frame.py:844] [4/1898] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.037000 612 torch/_dynamo/convert_frame.py:844] [4/1898]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.037000 612 torch/_dynamo/convert_frame.py:844] [4/1898]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.037000 612 torch/_dynamo/convert_frame.py:844] [4/1898] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.037000 612 torch/_dynamo/convert_frame.py:844] [4/1898] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.044000 612 torch/_dynamo/convert_frame.py:844] [4/1899] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.044000 612 torch/_dynamo/convert_frame.py:844] [4/1899]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.044000 612 torch/_dynamo/convert_frame.py:844] [4/1899]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.044000 612 torch/_dynamo/convert_frame.py:844] [4/1899] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.044000 612 torch/_dynamo/convert_frame.py:844] [4/1899] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.053000 612 torch/_dynamo/convert_frame.py:844] [4/1900] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.053000 612 torch/_dynamo/convert_frame.py:844] [4/1900]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.053000 612 torch/_dynamo/convert_frame.py:844] [4/1900]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.053000 612 torch/_dynamo/convert_frame.py:844] [4/1900] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.053000 612 torch/_dynamo/convert_frame.py:844] [4/1900] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.062000 612 torch/_dynamo/convert_frame.py:844] [4/1901] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.062000 612 torch/_dynamo/convert_frame.py:844] [4/1901]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.062000 612 torch/_dynamo/convert_frame.py:844] [4/1901]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.062000 612 torch/_dynamo/convert_frame.py:844] [4/1901] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.062000 612 torch/_dynamo/convert_frame.py:844] [4/1901] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.072000 612 torch/_dynamo/convert_frame.py:844] [4/1902] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.072000 612 torch/_dynamo/convert_frame.py:844] [4/1902]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.072000 612 torch/_dynamo/convert_frame.py:844] [4/1902]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.072000 612 torch/_dynamo/convert_frame.py:844] [4/1902] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.072000 612 torch/_dynamo/convert_frame.py:844] [4/1902] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.082000 612 torch/_dynamo/convert_frame.py:844] [4/1903] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.082000 612 torch/_dynamo/convert_frame.py:844] [4/1903]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.082000 612 torch/_dynamo/convert_frame.py:844] [4/1903]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.082000 612 torch/_dynamo/convert_frame.py:844] [4/1903] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.082000 612 torch/_dynamo/convert_frame.py:844] [4/1903] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.090000 612 torch/_dynamo/convert_frame.py:844] [4/1904] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.090000 612 torch/_dynamo/convert_frame.py:844] [4/1904]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.090000 612 torch/_dynamo/convert_frame.py:844] [4/1904]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.090000 612 torch/_dynamo/convert_frame.py:844] [4/1904] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.090000 612 torch/_dynamo/convert_frame.py:844] [4/1904] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.101000 612 torch/_dynamo/convert_frame.py:844] [4/1905] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.101000 612 torch/_dynamo/convert_frame.py:844] [4/1905]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.101000 612 torch/_dynamo/convert_frame.py:844] [4/1905]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.101000 612 torch/_dynamo/convert_frame.py:844] [4/1905] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.101000 612 torch/_dynamo/convert_frame.py:844] [4/1905] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.110000 612 torch/_dynamo/convert_frame.py:844] [4/1906] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.110000 612 torch/_dynamo/convert_frame.py:844] [4/1906]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.110000 612 torch/_dynamo/convert_frame.py:844] [4/1906]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.110000 612 torch/_dynamo/convert_frame.py:844] [4/1906] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.110000 612 torch/_dynamo/convert_frame.py:844] [4/1906] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.119000 612 torch/_dynamo/convert_frame.py:844] [4/1907] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.119000 612 torch/_dynamo/convert_frame.py:844] [4/1907]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.119000 612 torch/_dynamo/convert_frame.py:844] [4/1907]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.119000 612 torch/_dynamo/convert_frame.py:844] [4/1907] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.119000 612 torch/_dynamo/convert_frame.py:844] [4/1907] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.125000 612 torch/_dynamo/convert_frame.py:844] [4/1908] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.125000 612 torch/_dynamo/convert_frame.py:844] [4/1908]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.125000 612 torch/_dynamo/convert_frame.py:844] [4/1908]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.125000 612 torch/_dynamo/convert_frame.py:844] [4/1908] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.125000 612 torch/_dynamo/convert_frame.py:844] [4/1908] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.136000 612 torch/_dynamo/convert_frame.py:844] [4/1909] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.136000 612 torch/_dynamo/convert_frame.py:844] [4/1909]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.136000 612 torch/_dynamo/convert_frame.py:844] [4/1909]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.136000 612 torch/_dynamo/convert_frame.py:844] [4/1909] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.136000 612 torch/_dynamo/convert_frame.py:844] [4/1909] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.144000 612 torch/_dynamo/convert_frame.py:844] [4/1910] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.144000 612 torch/_dynamo/convert_frame.py:844] [4/1910]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.144000 612 torch/_dynamo/convert_frame.py:844] [4/1910]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.144000 612 torch/_dynamo/convert_frame.py:844] [4/1910] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.144000 612 torch/_dynamo/convert_frame.py:844] [4/1910] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.152000 612 torch/_dynamo/convert_frame.py:844] [4/1911] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.152000 612 torch/_dynamo/convert_frame.py:844] [4/1911]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.152000 612 torch/_dynamo/convert_frame.py:844] [4/1911]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.152000 612 torch/_dynamo/convert_frame.py:844] [4/1911] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.152000 612 torch/_dynamo/convert_frame.py:844] [4/1911] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.159000 612 torch/_dynamo/convert_frame.py:844] [4/1912] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.159000 612 torch/_dynamo/convert_frame.py:844] [4/1912]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.159000 612 torch/_dynamo/convert_frame.py:844] [4/1912]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.159000 612 torch/_dynamo/convert_frame.py:844] [4/1912] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.159000 612 torch/_dynamo/convert_frame.py:844] [4/1912] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024x   1024 |      3.122 |      4.281 |    0.73x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0223 05:56:16.169000 612 torch/_dynamo/convert_frame.py:844] [4/1913] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.169000 612 torch/_dynamo/convert_frame.py:844] [4/1913]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.169000 612 torch/_dynamo/convert_frame.py:844] [4/1913]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.169000 612 torch/_dynamo/convert_frame.py:844] [4/1913] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.169000 612 torch/_dynamo/convert_frame.py:844] [4/1913] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.178000 612 torch/_dynamo/convert_frame.py:844] [4/1914] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.178000 612 torch/_dynamo/convert_frame.py:844] [4/1914]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.178000 612 torch/_dynamo/convert_frame.py:844] [4/1914]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.178000 612 torch/_dynamo/convert_frame.py:844] [4/1914] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.178000 612 torch/_dynamo/convert_frame.py:844] [4/1914] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.186000 612 torch/_dynamo/convert_frame.py:844] [4/1915] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.186000 612 torch/_dynamo/convert_frame.py:844] [4/1915]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.186000 612 torch/_dynamo/convert_frame.py:844] [4/1915]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.186000 612 torch/_dynamo/convert_frame.py:844] [4/1915] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.186000 612 torch/_dynamo/convert_frame.py:844] [4/1915] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.196000 612 torch/_dynamo/convert_frame.py:844] [4/1916] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.196000 612 torch/_dynamo/convert_frame.py:844] [4/1916]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.196000 612 torch/_dynamo/convert_frame.py:844] [4/1916]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.196000 612 torch/_dynamo/convert_frame.py:844] [4/1916] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.196000 612 torch/_dynamo/convert_frame.py:844] [4/1916] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.205000 612 torch/_dynamo/convert_frame.py:844] [4/1917] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.205000 612 torch/_dynamo/convert_frame.py:844] [4/1917]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.205000 612 torch/_dynamo/convert_frame.py:844] [4/1917]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.205000 612 torch/_dynamo/convert_frame.py:844] [4/1917] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.205000 612 torch/_dynamo/convert_frame.py:844] [4/1917] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.211000 612 torch/_dynamo/convert_frame.py:844] [4/1918] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.211000 612 torch/_dynamo/convert_frame.py:844] [4/1918]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.211000 612 torch/_dynamo/convert_frame.py:844] [4/1918]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.211000 612 torch/_dynamo/convert_frame.py:844] [4/1918] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.211000 612 torch/_dynamo/convert_frame.py:844] [4/1918] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.218000 612 torch/_dynamo/convert_frame.py:844] [4/1919] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.218000 612 torch/_dynamo/convert_frame.py:844] [4/1919]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.218000 612 torch/_dynamo/convert_frame.py:844] [4/1919]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.218000 612 torch/_dynamo/convert_frame.py:844] [4/1919] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.218000 612 torch/_dynamo/convert_frame.py:844] [4/1919] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.230000 612 torch/_dynamo/convert_frame.py:844] [4/1920] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.230000 612 torch/_dynamo/convert_frame.py:844] [4/1920]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.230000 612 torch/_dynamo/convert_frame.py:844] [4/1920]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.230000 612 torch/_dynamo/convert_frame.py:844] [4/1920] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.230000 612 torch/_dynamo/convert_frame.py:844] [4/1920] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.237000 612 torch/_dynamo/convert_frame.py:844] [4/1921] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.237000 612 torch/_dynamo/convert_frame.py:844] [4/1921]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.237000 612 torch/_dynamo/convert_frame.py:844] [4/1921]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.237000 612 torch/_dynamo/convert_frame.py:844] [4/1921] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.237000 612 torch/_dynamo/convert_frame.py:844] [4/1921] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.245000 612 torch/_dynamo/convert_frame.py:844] [4/1922] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.245000 612 torch/_dynamo/convert_frame.py:844] [4/1922]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.245000 612 torch/_dynamo/convert_frame.py:844] [4/1922]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.245000 612 torch/_dynamo/convert_frame.py:844] [4/1922] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.245000 612 torch/_dynamo/convert_frame.py:844] [4/1922] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.251000 612 torch/_dynamo/convert_frame.py:844] [4/1923] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.251000 612 torch/_dynamo/convert_frame.py:844] [4/1923]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.251000 612 torch/_dynamo/convert_frame.py:844] [4/1923]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.251000 612 torch/_dynamo/convert_frame.py:844] [4/1923] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.251000 612 torch/_dynamo/convert_frame.py:844] [4/1923] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.261000 612 torch/_dynamo/convert_frame.py:844] [4/1924] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.261000 612 torch/_dynamo/convert_frame.py:844] [4/1924]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.261000 612 torch/_dynamo/convert_frame.py:844] [4/1924]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.261000 612 torch/_dynamo/convert_frame.py:844] [4/1924] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.261000 612 torch/_dynamo/convert_frame.py:844] [4/1924] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.271000 612 torch/_dynamo/convert_frame.py:844] [4/1925] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.271000 612 torch/_dynamo/convert_frame.py:844] [4/1925]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.271000 612 torch/_dynamo/convert_frame.py:844] [4/1925]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.271000 612 torch/_dynamo/convert_frame.py:844] [4/1925] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.271000 612 torch/_dynamo/convert_frame.py:844] [4/1925] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.282000 612 torch/_dynamo/convert_frame.py:844] [4/1926] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.282000 612 torch/_dynamo/convert_frame.py:844] [4/1926]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.282000 612 torch/_dynamo/convert_frame.py:844] [4/1926]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.282000 612 torch/_dynamo/convert_frame.py:844] [4/1926] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.282000 612 torch/_dynamo/convert_frame.py:844] [4/1926] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.289000 612 torch/_dynamo/convert_frame.py:844] [4/1927] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.289000 612 torch/_dynamo/convert_frame.py:844] [4/1927]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.289000 612 torch/_dynamo/convert_frame.py:844] [4/1927]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.289000 612 torch/_dynamo/convert_frame.py:844] [4/1927] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.289000 612 torch/_dynamo/convert_frame.py:844] [4/1927] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.299000 612 torch/_dynamo/convert_frame.py:844] [4/1928] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.299000 612 torch/_dynamo/convert_frame.py:844] [4/1928]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.299000 612 torch/_dynamo/convert_frame.py:844] [4/1928]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.299000 612 torch/_dynamo/convert_frame.py:844] [4/1928] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.299000 612 torch/_dynamo/convert_frame.py:844] [4/1928] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.309000 612 torch/_dynamo/convert_frame.py:844] [4/1929] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.309000 612 torch/_dynamo/convert_frame.py:844] [4/1929]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.309000 612 torch/_dynamo/convert_frame.py:844] [4/1929]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.309000 612 torch/_dynamo/convert_frame.py:844] [4/1929] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.309000 612 torch/_dynamo/convert_frame.py:844] [4/1929] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.316000 612 torch/_dynamo/convert_frame.py:844] [4/1930] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.316000 612 torch/_dynamo/convert_frame.py:844] [4/1930]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.316000 612 torch/_dynamo/convert_frame.py:844] [4/1930]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.316000 612 torch/_dynamo/convert_frame.py:844] [4/1930] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.316000 612 torch/_dynamo/convert_frame.py:844] [4/1930] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.333000 612 torch/_dynamo/convert_frame.py:844] [4/1931] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.333000 612 torch/_dynamo/convert_frame.py:844] [4/1931]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.333000 612 torch/_dynamo/convert_frame.py:844] [4/1931]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.333000 612 torch/_dynamo/convert_frame.py:844] [4/1931] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.333000 612 torch/_dynamo/convert_frame.py:844] [4/1931] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.340000 612 torch/_dynamo/convert_frame.py:844] [4/1932] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.340000 612 torch/_dynamo/convert_frame.py:844] [4/1932]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.340000 612 torch/_dynamo/convert_frame.py:844] [4/1932]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.340000 612 torch/_dynamo/convert_frame.py:844] [4/1932] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.340000 612 torch/_dynamo/convert_frame.py:844] [4/1932] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.347000 612 torch/_dynamo/convert_frame.py:844] [4/1933] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.347000 612 torch/_dynamo/convert_frame.py:844] [4/1933]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.347000 612 torch/_dynamo/convert_frame.py:844] [4/1933]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.347000 612 torch/_dynamo/convert_frame.py:844] [4/1933] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.347000 612 torch/_dynamo/convert_frame.py:844] [4/1933] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.356000 612 torch/_dynamo/convert_frame.py:844] [4/1934] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.356000 612 torch/_dynamo/convert_frame.py:844] [4/1934]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.356000 612 torch/_dynamo/convert_frame.py:844] [4/1934]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.356000 612 torch/_dynamo/convert_frame.py:844] [4/1934] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.356000 612 torch/_dynamo/convert_frame.py:844] [4/1934] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.362000 612 torch/_dynamo/convert_frame.py:844] [4/1935] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.362000 612 torch/_dynamo/convert_frame.py:844] [4/1935]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.362000 612 torch/_dynamo/convert_frame.py:844] [4/1935]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.362000 612 torch/_dynamo/convert_frame.py:844] [4/1935] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.362000 612 torch/_dynamo/convert_frame.py:844] [4/1935] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.367000 612 torch/_dynamo/convert_frame.py:844] [4/1936] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.367000 612 torch/_dynamo/convert_frame.py:844] [4/1936]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.367000 612 torch/_dynamo/convert_frame.py:844] [4/1936]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.367000 612 torch/_dynamo/convert_frame.py:844] [4/1936] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.367000 612 torch/_dynamo/convert_frame.py:844] [4/1936] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.377000 612 torch/_dynamo/convert_frame.py:844] [4/1937] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.377000 612 torch/_dynamo/convert_frame.py:844] [4/1937]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.377000 612 torch/_dynamo/convert_frame.py:844] [4/1937]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.377000 612 torch/_dynamo/convert_frame.py:844] [4/1937] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.377000 612 torch/_dynamo/convert_frame.py:844] [4/1937] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.387000 612 torch/_dynamo/convert_frame.py:844] [4/1938] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.387000 612 torch/_dynamo/convert_frame.py:844] [4/1938]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.387000 612 torch/_dynamo/convert_frame.py:844] [4/1938]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.387000 612 torch/_dynamo/convert_frame.py:844] [4/1938] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.387000 612 torch/_dynamo/convert_frame.py:844] [4/1938] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.398000 612 torch/_dynamo/convert_frame.py:844] [4/1939] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.398000 612 torch/_dynamo/convert_frame.py:844] [4/1939]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.398000 612 torch/_dynamo/convert_frame.py:844] [4/1939]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.398000 612 torch/_dynamo/convert_frame.py:844] [4/1939] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.398000 612 torch/_dynamo/convert_frame.py:844] [4/1939] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.404000 612 torch/_dynamo/convert_frame.py:844] [4/1940] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.404000 612 torch/_dynamo/convert_frame.py:844] [4/1940]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.404000 612 torch/_dynamo/convert_frame.py:844] [4/1940]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.404000 612 torch/_dynamo/convert_frame.py:844] [4/1940] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.404000 612 torch/_dynamo/convert_frame.py:844] [4/1940] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.412000 612 torch/_dynamo/convert_frame.py:844] [4/1941] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.412000 612 torch/_dynamo/convert_frame.py:844] [4/1941]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.412000 612 torch/_dynamo/convert_frame.py:844] [4/1941]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.412000 612 torch/_dynamo/convert_frame.py:844] [4/1941] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.412000 612 torch/_dynamo/convert_frame.py:844] [4/1941] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.420000 612 torch/_dynamo/convert_frame.py:844] [4/1942] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.420000 612 torch/_dynamo/convert_frame.py:844] [4/1942]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.420000 612 torch/_dynamo/convert_frame.py:844] [4/1942]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.420000 612 torch/_dynamo/convert_frame.py:844] [4/1942] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.420000 612 torch/_dynamo/convert_frame.py:844] [4/1942] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.426000 612 torch/_dynamo/convert_frame.py:844] [4/1943] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.426000 612 torch/_dynamo/convert_frame.py:844] [4/1943]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.426000 612 torch/_dynamo/convert_frame.py:844] [4/1943]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.426000 612 torch/_dynamo/convert_frame.py:844] [4/1943] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.426000 612 torch/_dynamo/convert_frame.py:844] [4/1943] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.432000 612 torch/_dynamo/convert_frame.py:844] [4/1944] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.432000 612 torch/_dynamo/convert_frame.py:844] [4/1944]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.432000 612 torch/_dynamo/convert_frame.py:844] [4/1944]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.432000 612 torch/_dynamo/convert_frame.py:844] [4/1944] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.432000 612 torch/_dynamo/convert_frame.py:844] [4/1944] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.439000 612 torch/_dynamo/convert_frame.py:844] [4/1945] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.439000 612 torch/_dynamo/convert_frame.py:844] [4/1945]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.439000 612 torch/_dynamo/convert_frame.py:844] [4/1945]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.439000 612 torch/_dynamo/convert_frame.py:844] [4/1945] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.439000 612 torch/_dynamo/convert_frame.py:844] [4/1945] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.446000 612 torch/_dynamo/convert_frame.py:844] [4/1946] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.446000 612 torch/_dynamo/convert_frame.py:844] [4/1946]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.446000 612 torch/_dynamo/convert_frame.py:844] [4/1946]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.446000 612 torch/_dynamo/convert_frame.py:844] [4/1946] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.446000 612 torch/_dynamo/convert_frame.py:844] [4/1946] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.452000 612 torch/_dynamo/convert_frame.py:844] [4/1947] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.452000 612 torch/_dynamo/convert_frame.py:844] [4/1947]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.452000 612 torch/_dynamo/convert_frame.py:844] [4/1947]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.452000 612 torch/_dynamo/convert_frame.py:844] [4/1947] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.452000 612 torch/_dynamo/convert_frame.py:844] [4/1947] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.458000 612 torch/_dynamo/convert_frame.py:844] [4/1948] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.458000 612 torch/_dynamo/convert_frame.py:844] [4/1948]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.458000 612 torch/_dynamo/convert_frame.py:844] [4/1948]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.458000 612 torch/_dynamo/convert_frame.py:844] [4/1948] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.458000 612 torch/_dynamo/convert_frame.py:844] [4/1948] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.464000 612 torch/_dynamo/convert_frame.py:844] [4/1949] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.464000 612 torch/_dynamo/convert_frame.py:844] [4/1949]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.464000 612 torch/_dynamo/convert_frame.py:844] [4/1949]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.464000 612 torch/_dynamo/convert_frame.py:844] [4/1949] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.464000 612 torch/_dynamo/convert_frame.py:844] [4/1949] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.471000 612 torch/_dynamo/convert_frame.py:844] [4/1950] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.471000 612 torch/_dynamo/convert_frame.py:844] [4/1950]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.471000 612 torch/_dynamo/convert_frame.py:844] [4/1950]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.471000 612 torch/_dynamo/convert_frame.py:844] [4/1950] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.471000 612 torch/_dynamo/convert_frame.py:844] [4/1950] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.476000 612 torch/_dynamo/convert_frame.py:844] [4/1951] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.476000 612 torch/_dynamo/convert_frame.py:844] [4/1951]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.476000 612 torch/_dynamo/convert_frame.py:844] [4/1951]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.476000 612 torch/_dynamo/convert_frame.py:844] [4/1951] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.476000 612 torch/_dynamo/convert_frame.py:844] [4/1951] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.484000 612 torch/_dynamo/convert_frame.py:844] [4/1952] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.484000 612 torch/_dynamo/convert_frame.py:844] [4/1952]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.484000 612 torch/_dynamo/convert_frame.py:844] [4/1952]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.484000 612 torch/_dynamo/convert_frame.py:844] [4/1952] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.484000 612 torch/_dynamo/convert_frame.py:844] [4/1952] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.497000 612 torch/_dynamo/convert_frame.py:844] [4/1953] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.497000 612 torch/_dynamo/convert_frame.py:844] [4/1953]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.497000 612 torch/_dynamo/convert_frame.py:844] [4/1953]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.497000 612 torch/_dynamo/convert_frame.py:844] [4/1953] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.497000 612 torch/_dynamo/convert_frame.py:844] [4/1953] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.503000 612 torch/_dynamo/convert_frame.py:844] [4/1954] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.503000 612 torch/_dynamo/convert_frame.py:844] [4/1954]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.503000 612 torch/_dynamo/convert_frame.py:844] [4/1954]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.503000 612 torch/_dynamo/convert_frame.py:844] [4/1954] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.503000 612 torch/_dynamo/convert_frame.py:844] [4/1954] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.509000 612 torch/_dynamo/convert_frame.py:844] [4/1955] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.509000 612 torch/_dynamo/convert_frame.py:844] [4/1955]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.509000 612 torch/_dynamo/convert_frame.py:844] [4/1955]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.509000 612 torch/_dynamo/convert_frame.py:844] [4/1955] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.509000 612 torch/_dynamo/convert_frame.py:844] [4/1955] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.515000 612 torch/_dynamo/convert_frame.py:844] [4/1956] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.515000 612 torch/_dynamo/convert_frame.py:844] [4/1956]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.515000 612 torch/_dynamo/convert_frame.py:844] [4/1956]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.515000 612 torch/_dynamo/convert_frame.py:844] [4/1956] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.515000 612 torch/_dynamo/convert_frame.py:844] [4/1956] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.520000 612 torch/_dynamo/convert_frame.py:844] [4/1957] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.520000 612 torch/_dynamo/convert_frame.py:844] [4/1957]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.520000 612 torch/_dynamo/convert_frame.py:844] [4/1957]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.520000 612 torch/_dynamo/convert_frame.py:844] [4/1957] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.520000 612 torch/_dynamo/convert_frame.py:844] [4/1957] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.526000 612 torch/_dynamo/convert_frame.py:844] [4/1958] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.526000 612 torch/_dynamo/convert_frame.py:844] [4/1958]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.526000 612 torch/_dynamo/convert_frame.py:844] [4/1958]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.526000 612 torch/_dynamo/convert_frame.py:844] [4/1958] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.526000 612 torch/_dynamo/convert_frame.py:844] [4/1958] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.532000 612 torch/_dynamo/convert_frame.py:844] [4/1959] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.532000 612 torch/_dynamo/convert_frame.py:844] [4/1959]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.532000 612 torch/_dynamo/convert_frame.py:844] [4/1959]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.532000 612 torch/_dynamo/convert_frame.py:844] [4/1959] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.532000 612 torch/_dynamo/convert_frame.py:844] [4/1959] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.538000 612 torch/_dynamo/convert_frame.py:844] [4/1960] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.538000 612 torch/_dynamo/convert_frame.py:844] [4/1960]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.538000 612 torch/_dynamo/convert_frame.py:844] [4/1960]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.538000 612 torch/_dynamo/convert_frame.py:844] [4/1960] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.538000 612 torch/_dynamo/convert_frame.py:844] [4/1960] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.544000 612 torch/_dynamo/convert_frame.py:844] [4/1961] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.544000 612 torch/_dynamo/convert_frame.py:844] [4/1961]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.544000 612 torch/_dynamo/convert_frame.py:844] [4/1961]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.544000 612 torch/_dynamo/convert_frame.py:844] [4/1961] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.544000 612 torch/_dynamo/convert_frame.py:844] [4/1961] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.553000 612 torch/_dynamo/convert_frame.py:844] [4/1962] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.553000 612 torch/_dynamo/convert_frame.py:844] [4/1962]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.553000 612 torch/_dynamo/convert_frame.py:844] [4/1962]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.553000 612 torch/_dynamo/convert_frame.py:844] [4/1962] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.553000 612 torch/_dynamo/convert_frame.py:844] [4/1962] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.559000 612 torch/_dynamo/convert_frame.py:844] [4/1963] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.559000 612 torch/_dynamo/convert_frame.py:844] [4/1963]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.559000 612 torch/_dynamo/convert_frame.py:844] [4/1963]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.559000 612 torch/_dynamo/convert_frame.py:844] [4/1963] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.559000 612 torch/_dynamo/convert_frame.py:844] [4/1963] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.567000 612 torch/_dynamo/convert_frame.py:844] [4/1964] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.567000 612 torch/_dynamo/convert_frame.py:844] [4/1964]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.567000 612 torch/_dynamo/convert_frame.py:844] [4/1964]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.567000 612 torch/_dynamo/convert_frame.py:844] [4/1964] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.567000 612 torch/_dynamo/convert_frame.py:844] [4/1964] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.573000 612 torch/_dynamo/convert_frame.py:844] [4/1965] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.573000 612 torch/_dynamo/convert_frame.py:844] [4/1965]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.573000 612 torch/_dynamo/convert_frame.py:844] [4/1965]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.573000 612 torch/_dynamo/convert_frame.py:844] [4/1965] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.573000 612 torch/_dynamo/convert_frame.py:844] [4/1965] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.580000 612 torch/_dynamo/convert_frame.py:844] [4/1966] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.580000 612 torch/_dynamo/convert_frame.py:844] [4/1966]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.580000 612 torch/_dynamo/convert_frame.py:844] [4/1966]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.580000 612 torch/_dynamo/convert_frame.py:844] [4/1966] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.580000 612 torch/_dynamo/convert_frame.py:844] [4/1966] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.588000 612 torch/_dynamo/convert_frame.py:844] [4/1967] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.588000 612 torch/_dynamo/convert_frame.py:844] [4/1967]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.588000 612 torch/_dynamo/convert_frame.py:844] [4/1967]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.588000 612 torch/_dynamo/convert_frame.py:844] [4/1967] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.588000 612 torch/_dynamo/convert_frame.py:844] [4/1967] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.598000 612 torch/_dynamo/convert_frame.py:844] [4/1968] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.598000 612 torch/_dynamo/convert_frame.py:844] [4/1968]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.598000 612 torch/_dynamo/convert_frame.py:844] [4/1968]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.598000 612 torch/_dynamo/convert_frame.py:844] [4/1968] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.598000 612 torch/_dynamo/convert_frame.py:844] [4/1968] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.606000 612 torch/_dynamo/convert_frame.py:844] [4/1969] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.606000 612 torch/_dynamo/convert_frame.py:844] [4/1969]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.606000 612 torch/_dynamo/convert_frame.py:844] [4/1969]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.606000 612 torch/_dynamo/convert_frame.py:844] [4/1969] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.606000 612 torch/_dynamo/convert_frame.py:844] [4/1969] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.615000 612 torch/_dynamo/convert_frame.py:844] [4/1970] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.615000 612 torch/_dynamo/convert_frame.py:844] [4/1970]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.615000 612 torch/_dynamo/convert_frame.py:844] [4/1970]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.615000 612 torch/_dynamo/convert_frame.py:844] [4/1970] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.615000 612 torch/_dynamo/convert_frame.py:844] [4/1970] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.622000 612 torch/_dynamo/convert_frame.py:844] [4/1971] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.622000 612 torch/_dynamo/convert_frame.py:844] [4/1971]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.622000 612 torch/_dynamo/convert_frame.py:844] [4/1971]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.622000 612 torch/_dynamo/convert_frame.py:844] [4/1971] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.622000 612 torch/_dynamo/convert_frame.py:844] [4/1971] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.631000 612 torch/_dynamo/convert_frame.py:844] [4/1972] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.631000 612 torch/_dynamo/convert_frame.py:844] [4/1972]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.631000 612 torch/_dynamo/convert_frame.py:844] [4/1972]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.631000 612 torch/_dynamo/convert_frame.py:844] [4/1972] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.631000 612 torch/_dynamo/convert_frame.py:844] [4/1972] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.638000 612 torch/_dynamo/convert_frame.py:844] [4/1973] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.638000 612 torch/_dynamo/convert_frame.py:844] [4/1973]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.638000 612 torch/_dynamo/convert_frame.py:844] [4/1973]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.638000 612 torch/_dynamo/convert_frame.py:844] [4/1973] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.638000 612 torch/_dynamo/convert_frame.py:844] [4/1973] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.648000 612 torch/_dynamo/convert_frame.py:844] [4/1974] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.648000 612 torch/_dynamo/convert_frame.py:844] [4/1974]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.648000 612 torch/_dynamo/convert_frame.py:844] [4/1974]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.648000 612 torch/_dynamo/convert_frame.py:844] [4/1974] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.648000 612 torch/_dynamo/convert_frame.py:844] [4/1974] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.656000 612 torch/_dynamo/convert_frame.py:844] [4/1975] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.656000 612 torch/_dynamo/convert_frame.py:844] [4/1975]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.656000 612 torch/_dynamo/convert_frame.py:844] [4/1975]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.656000 612 torch/_dynamo/convert_frame.py:844] [4/1975] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.656000 612 torch/_dynamo/convert_frame.py:844] [4/1975] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.664000 612 torch/_dynamo/convert_frame.py:844] [4/1976] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.664000 612 torch/_dynamo/convert_frame.py:844] [4/1976]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.664000 612 torch/_dynamo/convert_frame.py:844] [4/1976]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.664000 612 torch/_dynamo/convert_frame.py:844] [4/1976] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.664000 612 torch/_dynamo/convert_frame.py:844] [4/1976] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.670000 612 torch/_dynamo/convert_frame.py:844] [4/1977] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.670000 612 torch/_dynamo/convert_frame.py:844] [4/1977]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.670000 612 torch/_dynamo/convert_frame.py:844] [4/1977]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.670000 612 torch/_dynamo/convert_frame.py:844] [4/1977] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.670000 612 torch/_dynamo/convert_frame.py:844] [4/1977] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.677000 612 torch/_dynamo/convert_frame.py:844] [4/1978] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.677000 612 torch/_dynamo/convert_frame.py:844] [4/1978]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.677000 612 torch/_dynamo/convert_frame.py:844] [4/1978]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.677000 612 torch/_dynamo/convert_frame.py:844] [4/1978] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.677000 612 torch/_dynamo/convert_frame.py:844] [4/1978] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.683000 612 torch/_dynamo/convert_frame.py:844] [4/1979] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.683000 612 torch/_dynamo/convert_frame.py:844] [4/1979]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.683000 612 torch/_dynamo/convert_frame.py:844] [4/1979]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.683000 612 torch/_dynamo/convert_frame.py:844] [4/1979] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.683000 612 torch/_dynamo/convert_frame.py:844] [4/1979] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.689000 612 torch/_dynamo/convert_frame.py:844] [4/1980] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.689000 612 torch/_dynamo/convert_frame.py:844] [4/1980]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.689000 612 torch/_dynamo/convert_frame.py:844] [4/1980]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.689000 612 torch/_dynamo/convert_frame.py:844] [4/1980] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.689000 612 torch/_dynamo/convert_frame.py:844] [4/1980] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.696000 612 torch/_dynamo/convert_frame.py:844] [4/1981] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.696000 612 torch/_dynamo/convert_frame.py:844] [4/1981]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.696000 612 torch/_dynamo/convert_frame.py:844] [4/1981]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.696000 612 torch/_dynamo/convert_frame.py:844] [4/1981] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.696000 612 torch/_dynamo/convert_frame.py:844] [4/1981] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.702000 612 torch/_dynamo/convert_frame.py:844] [4/1982] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.702000 612 torch/_dynamo/convert_frame.py:844] [4/1982]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.702000 612 torch/_dynamo/convert_frame.py:844] [4/1982]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.702000 612 torch/_dynamo/convert_frame.py:844] [4/1982] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.702000 612 torch/_dynamo/convert_frame.py:844] [4/1982] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.708000 612 torch/_dynamo/convert_frame.py:844] [4/1983] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.708000 612 torch/_dynamo/convert_frame.py:844] [4/1983]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.708000 612 torch/_dynamo/convert_frame.py:844] [4/1983]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.708000 612 torch/_dynamo/convert_frame.py:844] [4/1983] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.708000 612 torch/_dynamo/convert_frame.py:844] [4/1983] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.714000 612 torch/_dynamo/convert_frame.py:844] [4/1984] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.714000 612 torch/_dynamo/convert_frame.py:844] [4/1984]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.714000 612 torch/_dynamo/convert_frame.py:844] [4/1984]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.714000 612 torch/_dynamo/convert_frame.py:844] [4/1984] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.714000 612 torch/_dynamo/convert_frame.py:844] [4/1984] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.720000 612 torch/_dynamo/convert_frame.py:844] [4/1985] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.720000 612 torch/_dynamo/convert_frame.py:844] [4/1985]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.720000 612 torch/_dynamo/convert_frame.py:844] [4/1985]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.720000 612 torch/_dynamo/convert_frame.py:844] [4/1985] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.720000 612 torch/_dynamo/convert_frame.py:844] [4/1985] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.726000 612 torch/_dynamo/convert_frame.py:844] [4/1986] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.726000 612 torch/_dynamo/convert_frame.py:844] [4/1986]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.726000 612 torch/_dynamo/convert_frame.py:844] [4/1986]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.726000 612 torch/_dynamo/convert_frame.py:844] [4/1986] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.726000 612 torch/_dynamo/convert_frame.py:844] [4/1986] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.733000 612 torch/_dynamo/convert_frame.py:844] [4/1987] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.733000 612 torch/_dynamo/convert_frame.py:844] [4/1987]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.733000 612 torch/_dynamo/convert_frame.py:844] [4/1987]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.733000 612 torch/_dynamo/convert_frame.py:844] [4/1987] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.733000 612 torch/_dynamo/convert_frame.py:844] [4/1987] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.740000 612 torch/_dynamo/convert_frame.py:844] [4/1988] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.740000 612 torch/_dynamo/convert_frame.py:844] [4/1988]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.740000 612 torch/_dynamo/convert_frame.py:844] [4/1988]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.740000 612 torch/_dynamo/convert_frame.py:844] [4/1988] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.740000 612 torch/_dynamo/convert_frame.py:844] [4/1988] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.747000 612 torch/_dynamo/convert_frame.py:844] [4/1989] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.747000 612 torch/_dynamo/convert_frame.py:844] [4/1989]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.747000 612 torch/_dynamo/convert_frame.py:844] [4/1989]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.747000 612 torch/_dynamo/convert_frame.py:844] [4/1989] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.747000 612 torch/_dynamo/convert_frame.py:844] [4/1989] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.757000 612 torch/_dynamo/convert_frame.py:844] [4/1990] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.757000 612 torch/_dynamo/convert_frame.py:844] [4/1990]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.757000 612 torch/_dynamo/convert_frame.py:844] [4/1990]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.757000 612 torch/_dynamo/convert_frame.py:844] [4/1990] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.757000 612 torch/_dynamo/convert_frame.py:844] [4/1990] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.763000 612 torch/_dynamo/convert_frame.py:844] [4/1991] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.763000 612 torch/_dynamo/convert_frame.py:844] [4/1991]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.763000 612 torch/_dynamo/convert_frame.py:844] [4/1991]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.763000 612 torch/_dynamo/convert_frame.py:844] [4/1991] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.763000 612 torch/_dynamo/convert_frame.py:844] [4/1991] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.771000 612 torch/_dynamo/convert_frame.py:844] [4/1992] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.771000 612 torch/_dynamo/convert_frame.py:844] [4/1992]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.771000 612 torch/_dynamo/convert_frame.py:844] [4/1992]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.771000 612 torch/_dynamo/convert_frame.py:844] [4/1992] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.771000 612 torch/_dynamo/convert_frame.py:844] [4/1992] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.779000 612 torch/_dynamo/convert_frame.py:844] [4/1993] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.779000 612 torch/_dynamo/convert_frame.py:844] [4/1993]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.779000 612 torch/_dynamo/convert_frame.py:844] [4/1993]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.779000 612 torch/_dynamo/convert_frame.py:844] [4/1993] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.779000 612 torch/_dynamo/convert_frame.py:844] [4/1993] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.787000 612 torch/_dynamo/convert_frame.py:844] [4/1994] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.787000 612 torch/_dynamo/convert_frame.py:844] [4/1994]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.787000 612 torch/_dynamo/convert_frame.py:844] [4/1994]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.787000 612 torch/_dynamo/convert_frame.py:844] [4/1994] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.787000 612 torch/_dynamo/convert_frame.py:844] [4/1994] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.793000 612 torch/_dynamo/convert_frame.py:844] [4/1995] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.793000 612 torch/_dynamo/convert_frame.py:844] [4/1995]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.793000 612 torch/_dynamo/convert_frame.py:844] [4/1995]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.793000 612 torch/_dynamo/convert_frame.py:844] [4/1995] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.793000 612 torch/_dynamo/convert_frame.py:844] [4/1995] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.799000 612 torch/_dynamo/convert_frame.py:844] [4/1996] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.799000 612 torch/_dynamo/convert_frame.py:844] [4/1996]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.799000 612 torch/_dynamo/convert_frame.py:844] [4/1996]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.799000 612 torch/_dynamo/convert_frame.py:844] [4/1996] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.799000 612 torch/_dynamo/convert_frame.py:844] [4/1996] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.807000 612 torch/_dynamo/convert_frame.py:844] [4/1997] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.807000 612 torch/_dynamo/convert_frame.py:844] [4/1997]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.807000 612 torch/_dynamo/convert_frame.py:844] [4/1997]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.807000 612 torch/_dynamo/convert_frame.py:844] [4/1997] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.807000 612 torch/_dynamo/convert_frame.py:844] [4/1997] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.813000 612 torch/_dynamo/convert_frame.py:844] [4/1998] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.813000 612 torch/_dynamo/convert_frame.py:844] [4/1998]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.813000 612 torch/_dynamo/convert_frame.py:844] [4/1998]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.813000 612 torch/_dynamo/convert_frame.py:844] [4/1998] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.813000 612 torch/_dynamo/convert_frame.py:844] [4/1998] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.824000 612 torch/_dynamo/convert_frame.py:844] [4/1999] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.824000 612 torch/_dynamo/convert_frame.py:844] [4/1999]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.824000 612 torch/_dynamo/convert_frame.py:844] [4/1999]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.824000 612 torch/_dynamo/convert_frame.py:844] [4/1999] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.824000 612 torch/_dynamo/convert_frame.py:844] [4/1999] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.832000 612 torch/_dynamo/convert_frame.py:844] [4/2000] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.832000 612 torch/_dynamo/convert_frame.py:844] [4/2000]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.832000 612 torch/_dynamo/convert_frame.py:844] [4/2000]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.832000 612 torch/_dynamo/convert_frame.py:844] [4/2000] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.832000 612 torch/_dynamo/convert_frame.py:844] [4/2000] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.843000 612 torch/_dynamo/convert_frame.py:844] [4/2001] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.843000 612 torch/_dynamo/convert_frame.py:844] [4/2001]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.843000 612 torch/_dynamo/convert_frame.py:844] [4/2001]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.843000 612 torch/_dynamo/convert_frame.py:844] [4/2001] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.843000 612 torch/_dynamo/convert_frame.py:844] [4/2001] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.851000 612 torch/_dynamo/convert_frame.py:844] [4/2002] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.851000 612 torch/_dynamo/convert_frame.py:844] [4/2002]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.851000 612 torch/_dynamo/convert_frame.py:844] [4/2002]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.851000 612 torch/_dynamo/convert_frame.py:844] [4/2002] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.851000 612 torch/_dynamo/convert_frame.py:844] [4/2002] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.867000 612 torch/_dynamo/convert_frame.py:844] [4/2003] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.867000 612 torch/_dynamo/convert_frame.py:844] [4/2003]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.867000 612 torch/_dynamo/convert_frame.py:844] [4/2003]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.867000 612 torch/_dynamo/convert_frame.py:844] [4/2003] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.867000 612 torch/_dynamo/convert_frame.py:844] [4/2003] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.874000 612 torch/_dynamo/convert_frame.py:844] [4/2004] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.874000 612 torch/_dynamo/convert_frame.py:844] [4/2004]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.874000 612 torch/_dynamo/convert_frame.py:844] [4/2004]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.874000 612 torch/_dynamo/convert_frame.py:844] [4/2004] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.874000 612 torch/_dynamo/convert_frame.py:844] [4/2004] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.881000 612 torch/_dynamo/convert_frame.py:844] [4/2005] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.881000 612 torch/_dynamo/convert_frame.py:844] [4/2005]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.881000 612 torch/_dynamo/convert_frame.py:844] [4/2005]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.881000 612 torch/_dynamo/convert_frame.py:844] [4/2005] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.881000 612 torch/_dynamo/convert_frame.py:844] [4/2005] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.894000 612 torch/_dynamo/convert_frame.py:844] [4/2006] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.894000 612 torch/_dynamo/convert_frame.py:844] [4/2006]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.894000 612 torch/_dynamo/convert_frame.py:844] [4/2006]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.894000 612 torch/_dynamo/convert_frame.py:844] [4/2006] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.894000 612 torch/_dynamo/convert_frame.py:844] [4/2006] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.903000 612 torch/_dynamo/convert_frame.py:844] [4/2007] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.903000 612 torch/_dynamo/convert_frame.py:844] [4/2007]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.903000 612 torch/_dynamo/convert_frame.py:844] [4/2007]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.903000 612 torch/_dynamo/convert_frame.py:844] [4/2007] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.903000 612 torch/_dynamo/convert_frame.py:844] [4/2007] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.911000 612 torch/_dynamo/convert_frame.py:844] [4/2008] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.911000 612 torch/_dynamo/convert_frame.py:844] [4/2008]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.911000 612 torch/_dynamo/convert_frame.py:844] [4/2008]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.911000 612 torch/_dynamo/convert_frame.py:844] [4/2008] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.911000 612 torch/_dynamo/convert_frame.py:844] [4/2008] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.922000 612 torch/_dynamo/convert_frame.py:844] [4/2009] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.922000 612 torch/_dynamo/convert_frame.py:844] [4/2009]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.922000 612 torch/_dynamo/convert_frame.py:844] [4/2009]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.922000 612 torch/_dynamo/convert_frame.py:844] [4/2009] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.922000 612 torch/_dynamo/convert_frame.py:844] [4/2009] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.930000 612 torch/_dynamo/convert_frame.py:844] [4/2010] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.930000 612 torch/_dynamo/convert_frame.py:844] [4/2010]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.930000 612 torch/_dynamo/convert_frame.py:844] [4/2010]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.930000 612 torch/_dynamo/convert_frame.py:844] [4/2010] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.930000 612 torch/_dynamo/convert_frame.py:844] [4/2010] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.938000 612 torch/_dynamo/convert_frame.py:844] [4/2011] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.938000 612 torch/_dynamo/convert_frame.py:844] [4/2011]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.938000 612 torch/_dynamo/convert_frame.py:844] [4/2011]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.938000 612 torch/_dynamo/convert_frame.py:844] [4/2011] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.938000 612 torch/_dynamo/convert_frame.py:844] [4/2011] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.944000 612 torch/_dynamo/convert_frame.py:844] [4/2012] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.944000 612 torch/_dynamo/convert_frame.py:844] [4/2012]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.944000 612 torch/_dynamo/convert_frame.py:844] [4/2012]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.944000 612 torch/_dynamo/convert_frame.py:844] [4/2012] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.944000 612 torch/_dynamo/convert_frame.py:844] [4/2012] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.950000 612 torch/_dynamo/convert_frame.py:844] [4/2013] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.950000 612 torch/_dynamo/convert_frame.py:844] [4/2013]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.950000 612 torch/_dynamo/convert_frame.py:844] [4/2013]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.950000 612 torch/_dynamo/convert_frame.py:844] [4/2013] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.950000 612 torch/_dynamo/convert_frame.py:844] [4/2013] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.957000 612 torch/_dynamo/convert_frame.py:844] [4/2014] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.957000 612 torch/_dynamo/convert_frame.py:844] [4/2014]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.957000 612 torch/_dynamo/convert_frame.py:844] [4/2014]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.957000 612 torch/_dynamo/convert_frame.py:844] [4/2014] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.957000 612 torch/_dynamo/convert_frame.py:844] [4/2014] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.963000 612 torch/_dynamo/convert_frame.py:844] [4/2015] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.963000 612 torch/_dynamo/convert_frame.py:844] [4/2015]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.963000 612 torch/_dynamo/convert_frame.py:844] [4/2015]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.963000 612 torch/_dynamo/convert_frame.py:844] [4/2015] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.963000 612 torch/_dynamo/convert_frame.py:844] [4/2015] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.971000 612 torch/_dynamo/convert_frame.py:844] [4/2016] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.971000 612 torch/_dynamo/convert_frame.py:844] [4/2016]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.971000 612 torch/_dynamo/convert_frame.py:844] [4/2016]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.971000 612 torch/_dynamo/convert_frame.py:844] [4/2016] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.971000 612 torch/_dynamo/convert_frame.py:844] [4/2016] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.976000 612 torch/_dynamo/convert_frame.py:844] [4/2017] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.976000 612 torch/_dynamo/convert_frame.py:844] [4/2017]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.976000 612 torch/_dynamo/convert_frame.py:844] [4/2017]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.976000 612 torch/_dynamo/convert_frame.py:844] [4/2017] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.976000 612 torch/_dynamo/convert_frame.py:844] [4/2017] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.982000 612 torch/_dynamo/convert_frame.py:844] [4/2018] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.982000 612 torch/_dynamo/convert_frame.py:844] [4/2018]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.982000 612 torch/_dynamo/convert_frame.py:844] [4/2018]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.982000 612 torch/_dynamo/convert_frame.py:844] [4/2018] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.982000 612 torch/_dynamo/convert_frame.py:844] [4/2018] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.988000 612 torch/_dynamo/convert_frame.py:844] [4/2019] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.988000 612 torch/_dynamo/convert_frame.py:844] [4/2019]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.988000 612 torch/_dynamo/convert_frame.py:844] [4/2019]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.988000 612 torch/_dynamo/convert_frame.py:844] [4/2019] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.988000 612 torch/_dynamo/convert_frame.py:844] [4/2019] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:16.994000 612 torch/_dynamo/convert_frame.py:844] [4/2020] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:16.994000 612 torch/_dynamo/convert_frame.py:844] [4/2020]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:16.994000 612 torch/_dynamo/convert_frame.py:844] [4/2020]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:16.994000 612 torch/_dynamo/convert_frame.py:844] [4/2020] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:16.994000 612 torch/_dynamo/convert_frame.py:844] [4/2020] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.005000 612 torch/_dynamo/convert_frame.py:844] [4/2021] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.005000 612 torch/_dynamo/convert_frame.py:844] [4/2021]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.005000 612 torch/_dynamo/convert_frame.py:844] [4/2021]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.005000 612 torch/_dynamo/convert_frame.py:844] [4/2021] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.005000 612 torch/_dynamo/convert_frame.py:844] [4/2021] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.012000 612 torch/_dynamo/convert_frame.py:844] [4/2022] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.012000 612 torch/_dynamo/convert_frame.py:844] [4/2022]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.012000 612 torch/_dynamo/convert_frame.py:844] [4/2022]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.012000 612 torch/_dynamo/convert_frame.py:844] [4/2022] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.012000 612 torch/_dynamo/convert_frame.py:844] [4/2022] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.017000 612 torch/_dynamo/convert_frame.py:844] [4/2023] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.017000 612 torch/_dynamo/convert_frame.py:844] [4/2023]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.017000 612 torch/_dynamo/convert_frame.py:844] [4/2023]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.017000 612 torch/_dynamo/convert_frame.py:844] [4/2023] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.017000 612 torch/_dynamo/convert_frame.py:844] [4/2023] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.029000 612 torch/_dynamo/convert_frame.py:844] [4/2024] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.029000 612 torch/_dynamo/convert_frame.py:844] [4/2024]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.029000 612 torch/_dynamo/convert_frame.py:844] [4/2024]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.029000 612 torch/_dynamo/convert_frame.py:844] [4/2024] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.029000 612 torch/_dynamo/convert_frame.py:844] [4/2024] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.035000 612 torch/_dynamo/convert_frame.py:844] [4/2025] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.035000 612 torch/_dynamo/convert_frame.py:844] [4/2025]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.035000 612 torch/_dynamo/convert_frame.py:844] [4/2025]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.035000 612 torch/_dynamo/convert_frame.py:844] [4/2025] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.035000 612 torch/_dynamo/convert_frame.py:844] [4/2025] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.046000 612 torch/_dynamo/convert_frame.py:844] [4/2026] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.046000 612 torch/_dynamo/convert_frame.py:844] [4/2026]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.046000 612 torch/_dynamo/convert_frame.py:844] [4/2026]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.046000 612 torch/_dynamo/convert_frame.py:844] [4/2026] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.046000 612 torch/_dynamo/convert_frame.py:844] [4/2026] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.058000 612 torch/_dynamo/convert_frame.py:844] [4/2027] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.058000 612 torch/_dynamo/convert_frame.py:844] [4/2027]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.058000 612 torch/_dynamo/convert_frame.py:844] [4/2027]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.058000 612 torch/_dynamo/convert_frame.py:844] [4/2027] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.058000 612 torch/_dynamo/convert_frame.py:844] [4/2027] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.064000 612 torch/_dynamo/convert_frame.py:844] [4/2028] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.064000 612 torch/_dynamo/convert_frame.py:844] [4/2028]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.064000 612 torch/_dynamo/convert_frame.py:844] [4/2028]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.064000 612 torch/_dynamo/convert_frame.py:844] [4/2028] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.064000 612 torch/_dynamo/convert_frame.py:844] [4/2028] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.072000 612 torch/_dynamo/convert_frame.py:844] [4/2029] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.072000 612 torch/_dynamo/convert_frame.py:844] [4/2029]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.072000 612 torch/_dynamo/convert_frame.py:844] [4/2029]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.072000 612 torch/_dynamo/convert_frame.py:844] [4/2029] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.072000 612 torch/_dynamo/convert_frame.py:844] [4/2029] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.079000 612 torch/_dynamo/convert_frame.py:844] [4/2030] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.079000 612 torch/_dynamo/convert_frame.py:844] [4/2030]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.079000 612 torch/_dynamo/convert_frame.py:844] [4/2030]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.079000 612 torch/_dynamo/convert_frame.py:844] [4/2030] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.079000 612 torch/_dynamo/convert_frame.py:844] [4/2030] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.089000 612 torch/_dynamo/convert_frame.py:844] [4/2031] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.089000 612 torch/_dynamo/convert_frame.py:844] [4/2031]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.089000 612 torch/_dynamo/convert_frame.py:844] [4/2031]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.089000 612 torch/_dynamo/convert_frame.py:844] [4/2031] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.089000 612 torch/_dynamo/convert_frame.py:844] [4/2031] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.094000 612 torch/_dynamo/convert_frame.py:844] [4/2032] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.094000 612 torch/_dynamo/convert_frame.py:844] [4/2032]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.094000 612 torch/_dynamo/convert_frame.py:844] [4/2032]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.094000 612 torch/_dynamo/convert_frame.py:844] [4/2032] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.094000 612 torch/_dynamo/convert_frame.py:844] [4/2032] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.105000 612 torch/_dynamo/convert_frame.py:844] [4/2033] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.105000 612 torch/_dynamo/convert_frame.py:844] [4/2033]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.105000 612 torch/_dynamo/convert_frame.py:844] [4/2033]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.105000 612 torch/_dynamo/convert_frame.py:844] [4/2033] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.105000 612 torch/_dynamo/convert_frame.py:844] [4/2033] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.114000 612 torch/_dynamo/convert_frame.py:844] [4/2034] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.114000 612 torch/_dynamo/convert_frame.py:844] [4/2034]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.114000 612 torch/_dynamo/convert_frame.py:844] [4/2034]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.114000 612 torch/_dynamo/convert_frame.py:844] [4/2034] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.114000 612 torch/_dynamo/convert_frame.py:844] [4/2034] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.119000 612 torch/_dynamo/convert_frame.py:844] [4/2035] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.119000 612 torch/_dynamo/convert_frame.py:844] [4/2035]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.119000 612 torch/_dynamo/convert_frame.py:844] [4/2035]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.119000 612 torch/_dynamo/convert_frame.py:844] [4/2035] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.119000 612 torch/_dynamo/convert_frame.py:844] [4/2035] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.126000 612 torch/_dynamo/convert_frame.py:844] [4/2036] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.126000 612 torch/_dynamo/convert_frame.py:844] [4/2036]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.126000 612 torch/_dynamo/convert_frame.py:844] [4/2036]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.126000 612 torch/_dynamo/convert_frame.py:844] [4/2036] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.126000 612 torch/_dynamo/convert_frame.py:844] [4/2036] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.135000 612 torch/_dynamo/convert_frame.py:844] [4/2037] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.135000 612 torch/_dynamo/convert_frame.py:844] [4/2037]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.135000 612 torch/_dynamo/convert_frame.py:844] [4/2037]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.135000 612 torch/_dynamo/convert_frame.py:844] [4/2037] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.135000 612 torch/_dynamo/convert_frame.py:844] [4/2037] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.141000 612 torch/_dynamo/convert_frame.py:844] [4/2038] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.141000 612 torch/_dynamo/convert_frame.py:844] [4/2038]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.141000 612 torch/_dynamo/convert_frame.py:844] [4/2038]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.141000 612 torch/_dynamo/convert_frame.py:844] [4/2038] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.141000 612 torch/_dynamo/convert_frame.py:844] [4/2038] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.147000 612 torch/_dynamo/convert_frame.py:844] [4/2039] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.147000 612 torch/_dynamo/convert_frame.py:844] [4/2039]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.147000 612 torch/_dynamo/convert_frame.py:844] [4/2039]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.147000 612 torch/_dynamo/convert_frame.py:844] [4/2039] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.147000 612 torch/_dynamo/convert_frame.py:844] [4/2039] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.153000 612 torch/_dynamo/convert_frame.py:844] [4/2040] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.153000 612 torch/_dynamo/convert_frame.py:844] [4/2040]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.153000 612 torch/_dynamo/convert_frame.py:844] [4/2040]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.153000 612 torch/_dynamo/convert_frame.py:844] [4/2040] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.153000 612 torch/_dynamo/convert_frame.py:844] [4/2040] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.159000 612 torch/_dynamo/convert_frame.py:844] [4/2041] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.159000 612 torch/_dynamo/convert_frame.py:844] [4/2041]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.159000 612 torch/_dynamo/convert_frame.py:844] [4/2041]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.159000 612 torch/_dynamo/convert_frame.py:844] [4/2041] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.159000 612 torch/_dynamo/convert_frame.py:844] [4/2041] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.165000 612 torch/_dynamo/convert_frame.py:844] [4/2042] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.165000 612 torch/_dynamo/convert_frame.py:844] [4/2042]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.165000 612 torch/_dynamo/convert_frame.py:844] [4/2042]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.165000 612 torch/_dynamo/convert_frame.py:844] [4/2042] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.165000 612 torch/_dynamo/convert_frame.py:844] [4/2042] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.170000 612 torch/_dynamo/convert_frame.py:844] [4/2043] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.170000 612 torch/_dynamo/convert_frame.py:844] [4/2043]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.170000 612 torch/_dynamo/convert_frame.py:844] [4/2043]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.170000 612 torch/_dynamo/convert_frame.py:844] [4/2043] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.170000 612 torch/_dynamo/convert_frame.py:844] [4/2043] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.176000 612 torch/_dynamo/convert_frame.py:844] [4/2044] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.176000 612 torch/_dynamo/convert_frame.py:844] [4/2044]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.176000 612 torch/_dynamo/convert_frame.py:844] [4/2044]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.176000 612 torch/_dynamo/convert_frame.py:844] [4/2044] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.176000 612 torch/_dynamo/convert_frame.py:844] [4/2044] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.181000 612 torch/_dynamo/convert_frame.py:844] [4/2045] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.181000 612 torch/_dynamo/convert_frame.py:844] [4/2045]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.181000 612 torch/_dynamo/convert_frame.py:844] [4/2045]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.181000 612 torch/_dynamo/convert_frame.py:844] [4/2045] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.181000 612 torch/_dynamo/convert_frame.py:844] [4/2045] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.187000 612 torch/_dynamo/convert_frame.py:844] [4/2046] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.187000 612 torch/_dynamo/convert_frame.py:844] [4/2046]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.187000 612 torch/_dynamo/convert_frame.py:844] [4/2046]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.187000 612 torch/_dynamo/convert_frame.py:844] [4/2046] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.187000 612 torch/_dynamo/convert_frame.py:844] [4/2046] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.192000 612 torch/_dynamo/convert_frame.py:844] [4/2047] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.192000 612 torch/_dynamo/convert_frame.py:844] [4/2047]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.192000 612 torch/_dynamo/convert_frame.py:844] [4/2047]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.192000 612 torch/_dynamo/convert_frame.py:844] [4/2047] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.192000 612 torch/_dynamo/convert_frame.py:844] [4/2047] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.199000 612 torch/_dynamo/convert_frame.py:844] [4/2048] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.199000 612 torch/_dynamo/convert_frame.py:844] [4/2048]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.199000 612 torch/_dynamo/convert_frame.py:844] [4/2048]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.199000 612 torch/_dynamo/convert_frame.py:844] [4/2048] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.199000 612 torch/_dynamo/convert_frame.py:844] [4/2048] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.210000 612 torch/_dynamo/convert_frame.py:844] [4/2049] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.210000 612 torch/_dynamo/convert_frame.py:844] [4/2049]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.210000 612 torch/_dynamo/convert_frame.py:844] [4/2049]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.210000 612 torch/_dynamo/convert_frame.py:844] [4/2049] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.210000 612 torch/_dynamo/convert_frame.py:844] [4/2049] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.216000 612 torch/_dynamo/convert_frame.py:844] [4/2050] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.216000 612 torch/_dynamo/convert_frame.py:844] [4/2050]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.216000 612 torch/_dynamo/convert_frame.py:844] [4/2050]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.216000 612 torch/_dynamo/convert_frame.py:844] [4/2050] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.216000 612 torch/_dynamo/convert_frame.py:844] [4/2050] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.221000 612 torch/_dynamo/convert_frame.py:844] [4/2051] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.221000 612 torch/_dynamo/convert_frame.py:844] [4/2051]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.221000 612 torch/_dynamo/convert_frame.py:844] [4/2051]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.221000 612 torch/_dynamo/convert_frame.py:844] [4/2051] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.221000 612 torch/_dynamo/convert_frame.py:844] [4/2051] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.229000 612 torch/_dynamo/convert_frame.py:844] [4/2052] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.229000 612 torch/_dynamo/convert_frame.py:844] [4/2052]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.229000 612 torch/_dynamo/convert_frame.py:844] [4/2052]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.229000 612 torch/_dynamo/convert_frame.py:844] [4/2052] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.229000 612 torch/_dynamo/convert_frame.py:844] [4/2052] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.238000 612 torch/_dynamo/convert_frame.py:844] [4/2053] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.238000 612 torch/_dynamo/convert_frame.py:844] [4/2053]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.238000 612 torch/_dynamo/convert_frame.py:844] [4/2053]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.238000 612 torch/_dynamo/convert_frame.py:844] [4/2053] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.238000 612 torch/_dynamo/convert_frame.py:844] [4/2053] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.244000 612 torch/_dynamo/convert_frame.py:844] [4/2054] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.244000 612 torch/_dynamo/convert_frame.py:844] [4/2054]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.244000 612 torch/_dynamo/convert_frame.py:844] [4/2054]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.244000 612 torch/_dynamo/convert_frame.py:844] [4/2054] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.244000 612 torch/_dynamo/convert_frame.py:844] [4/2054] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.249000 612 torch/_dynamo/convert_frame.py:844] [4/2055] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.249000 612 torch/_dynamo/convert_frame.py:844] [4/2055]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.249000 612 torch/_dynamo/convert_frame.py:844] [4/2055]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.249000 612 torch/_dynamo/convert_frame.py:844] [4/2055] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.249000 612 torch/_dynamo/convert_frame.py:844] [4/2055] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.255000 612 torch/_dynamo/convert_frame.py:844] [4/2056] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.255000 612 torch/_dynamo/convert_frame.py:844] [4/2056]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.255000 612 torch/_dynamo/convert_frame.py:844] [4/2056]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.255000 612 torch/_dynamo/convert_frame.py:844] [4/2056] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.255000 612 torch/_dynamo/convert_frame.py:844] [4/2056] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.270000 612 torch/_dynamo/convert_frame.py:844] [4/2057] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.270000 612 torch/_dynamo/convert_frame.py:844] [4/2057]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.270000 612 torch/_dynamo/convert_frame.py:844] [4/2057]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.270000 612 torch/_dynamo/convert_frame.py:844] [4/2057] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.270000 612 torch/_dynamo/convert_frame.py:844] [4/2057] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.277000 612 torch/_dynamo/convert_frame.py:844] [4/2058] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.277000 612 torch/_dynamo/convert_frame.py:844] [4/2058]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.277000 612 torch/_dynamo/convert_frame.py:844] [4/2058]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.277000 612 torch/_dynamo/convert_frame.py:844] [4/2058] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.277000 612 torch/_dynamo/convert_frame.py:844] [4/2058] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.284000 612 torch/_dynamo/convert_frame.py:844] [4/2059] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.284000 612 torch/_dynamo/convert_frame.py:844] [4/2059]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.284000 612 torch/_dynamo/convert_frame.py:844] [4/2059]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.284000 612 torch/_dynamo/convert_frame.py:844] [4/2059] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.284000 612 torch/_dynamo/convert_frame.py:844] [4/2059] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.295000 612 torch/_dynamo/convert_frame.py:844] [4/2060] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.295000 612 torch/_dynamo/convert_frame.py:844] [4/2060]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.295000 612 torch/_dynamo/convert_frame.py:844] [4/2060]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.295000 612 torch/_dynamo/convert_frame.py:844] [4/2060] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.295000 612 torch/_dynamo/convert_frame.py:844] [4/2060] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.303000 612 torch/_dynamo/convert_frame.py:844] [4/2061] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.303000 612 torch/_dynamo/convert_frame.py:844] [4/2061]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.303000 612 torch/_dynamo/convert_frame.py:844] [4/2061]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.303000 612 torch/_dynamo/convert_frame.py:844] [4/2061] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.303000 612 torch/_dynamo/convert_frame.py:844] [4/2061] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.312000 612 torch/_dynamo/convert_frame.py:844] [4/2062] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.312000 612 torch/_dynamo/convert_frame.py:844] [4/2062]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.312000 612 torch/_dynamo/convert_frame.py:844] [4/2062]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.312000 612 torch/_dynamo/convert_frame.py:844] [4/2062] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.312000 612 torch/_dynamo/convert_frame.py:844] [4/2062] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.318000 612 torch/_dynamo/convert_frame.py:844] [4/2063] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.318000 612 torch/_dynamo/convert_frame.py:844] [4/2063]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.318000 612 torch/_dynamo/convert_frame.py:844] [4/2063]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.318000 612 torch/_dynamo/convert_frame.py:844] [4/2063] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.318000 612 torch/_dynamo/convert_frame.py:844] [4/2063] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.326000 612 torch/_dynamo/convert_frame.py:844] [4/2064] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.326000 612 torch/_dynamo/convert_frame.py:844] [4/2064]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.326000 612 torch/_dynamo/convert_frame.py:844] [4/2064]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.326000 612 torch/_dynamo/convert_frame.py:844] [4/2064] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.326000 612 torch/_dynamo/convert_frame.py:844] [4/2064] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.333000 612 torch/_dynamo/convert_frame.py:844] [4/2065] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.333000 612 torch/_dynamo/convert_frame.py:844] [4/2065]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.333000 612 torch/_dynamo/convert_frame.py:844] [4/2065]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.333000 612 torch/_dynamo/convert_frame.py:844] [4/2065] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.333000 612 torch/_dynamo/convert_frame.py:844] [4/2065] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.341000 612 torch/_dynamo/convert_frame.py:844] [4/2066] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.341000 612 torch/_dynamo/convert_frame.py:844] [4/2066]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.341000 612 torch/_dynamo/convert_frame.py:844] [4/2066]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.341000 612 torch/_dynamo/convert_frame.py:844] [4/2066] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.341000 612 torch/_dynamo/convert_frame.py:844] [4/2066] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.347000 612 torch/_dynamo/convert_frame.py:844] [4/2067] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.347000 612 torch/_dynamo/convert_frame.py:844] [4/2067]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.347000 612 torch/_dynamo/convert_frame.py:844] [4/2067]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.347000 612 torch/_dynamo/convert_frame.py:844] [4/2067] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.347000 612 torch/_dynamo/convert_frame.py:844] [4/2067] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.354000 612 torch/_dynamo/convert_frame.py:844] [4/2068] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.354000 612 torch/_dynamo/convert_frame.py:844] [4/2068]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.354000 612 torch/_dynamo/convert_frame.py:844] [4/2068]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.354000 612 torch/_dynamo/convert_frame.py:844] [4/2068] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.354000 612 torch/_dynamo/convert_frame.py:844] [4/2068] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.360000 612 torch/_dynamo/convert_frame.py:844] [4/2069] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.360000 612 torch/_dynamo/convert_frame.py:844] [4/2069]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.360000 612 torch/_dynamo/convert_frame.py:844] [4/2069]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.360000 612 torch/_dynamo/convert_frame.py:844] [4/2069] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.360000 612 torch/_dynamo/convert_frame.py:844] [4/2069] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.369000 612 torch/_dynamo/convert_frame.py:844] [4/2070] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.369000 612 torch/_dynamo/convert_frame.py:844] [4/2070]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.369000 612 torch/_dynamo/convert_frame.py:844] [4/2070]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.369000 612 torch/_dynamo/convert_frame.py:844] [4/2070] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.369000 612 torch/_dynamo/convert_frame.py:844] [4/2070] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.375000 612 torch/_dynamo/convert_frame.py:844] [4/2071] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.375000 612 torch/_dynamo/convert_frame.py:844] [4/2071]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.375000 612 torch/_dynamo/convert_frame.py:844] [4/2071]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.375000 612 torch/_dynamo/convert_frame.py:844] [4/2071] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.375000 612 torch/_dynamo/convert_frame.py:844] [4/2071] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.380000 612 torch/_dynamo/convert_frame.py:844] [4/2072] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.380000 612 torch/_dynamo/convert_frame.py:844] [4/2072]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.380000 612 torch/_dynamo/convert_frame.py:844] [4/2072]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.380000 612 torch/_dynamo/convert_frame.py:844] [4/2072] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.380000 612 torch/_dynamo/convert_frame.py:844] [4/2072] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.388000 612 torch/_dynamo/convert_frame.py:844] [4/2073] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.388000 612 torch/_dynamo/convert_frame.py:844] [4/2073]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.388000 612 torch/_dynamo/convert_frame.py:844] [4/2073]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.388000 612 torch/_dynamo/convert_frame.py:844] [4/2073] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.388000 612 torch/_dynamo/convert_frame.py:844] [4/2073] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.396000 612 torch/_dynamo/convert_frame.py:844] [4/2074] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.396000 612 torch/_dynamo/convert_frame.py:844] [4/2074]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.396000 612 torch/_dynamo/convert_frame.py:844] [4/2074]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.396000 612 torch/_dynamo/convert_frame.py:844] [4/2074] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.396000 612 torch/_dynamo/convert_frame.py:844] [4/2074] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.403000 612 torch/_dynamo/convert_frame.py:844] [4/2075] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.403000 612 torch/_dynamo/convert_frame.py:844] [4/2075]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.403000 612 torch/_dynamo/convert_frame.py:844] [4/2075]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.403000 612 torch/_dynamo/convert_frame.py:844] [4/2075] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.403000 612 torch/_dynamo/convert_frame.py:844] [4/2075] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.417000 612 torch/_dynamo/convert_frame.py:844] [4/2076] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.417000 612 torch/_dynamo/convert_frame.py:844] [4/2076]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.417000 612 torch/_dynamo/convert_frame.py:844] [4/2076]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.417000 612 torch/_dynamo/convert_frame.py:844] [4/2076] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.417000 612 torch/_dynamo/convert_frame.py:844] [4/2076] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.423000 612 torch/_dynamo/convert_frame.py:844] [4/2077] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.423000 612 torch/_dynamo/convert_frame.py:844] [4/2077]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.423000 612 torch/_dynamo/convert_frame.py:844] [4/2077]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.423000 612 torch/_dynamo/convert_frame.py:844] [4/2077] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.423000 612 torch/_dynamo/convert_frame.py:844] [4/2077] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.431000 612 torch/_dynamo/convert_frame.py:844] [4/2078] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.431000 612 torch/_dynamo/convert_frame.py:844] [4/2078]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.431000 612 torch/_dynamo/convert_frame.py:844] [4/2078]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.431000 612 torch/_dynamo/convert_frame.py:844] [4/2078] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.431000 612 torch/_dynamo/convert_frame.py:844] [4/2078] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.439000 612 torch/_dynamo/convert_frame.py:844] [4/2079] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.439000 612 torch/_dynamo/convert_frame.py:844] [4/2079]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.439000 612 torch/_dynamo/convert_frame.py:844] [4/2079]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.439000 612 torch/_dynamo/convert_frame.py:844] [4/2079] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.439000 612 torch/_dynamo/convert_frame.py:844] [4/2079] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.445000 612 torch/_dynamo/convert_frame.py:844] [4/2080] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.445000 612 torch/_dynamo/convert_frame.py:844] [4/2080]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.445000 612 torch/_dynamo/convert_frame.py:844] [4/2080]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.445000 612 torch/_dynamo/convert_frame.py:844] [4/2080] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.445000 612 torch/_dynamo/convert_frame.py:844] [4/2080] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.451000 612 torch/_dynamo/convert_frame.py:844] [4/2081] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.451000 612 torch/_dynamo/convert_frame.py:844] [4/2081]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.451000 612 torch/_dynamo/convert_frame.py:844] [4/2081]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.451000 612 torch/_dynamo/convert_frame.py:844] [4/2081] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.451000 612 torch/_dynamo/convert_frame.py:844] [4/2081] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.457000 612 torch/_dynamo/convert_frame.py:844] [4/2082] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.457000 612 torch/_dynamo/convert_frame.py:844] [4/2082]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.457000 612 torch/_dynamo/convert_frame.py:844] [4/2082]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.457000 612 torch/_dynamo/convert_frame.py:844] [4/2082] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.457000 612 torch/_dynamo/convert_frame.py:844] [4/2082] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.464000 612 torch/_dynamo/convert_frame.py:844] [4/2083] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.464000 612 torch/_dynamo/convert_frame.py:844] [4/2083]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.464000 612 torch/_dynamo/convert_frame.py:844] [4/2083]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.464000 612 torch/_dynamo/convert_frame.py:844] [4/2083] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.464000 612 torch/_dynamo/convert_frame.py:844] [4/2083] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.470000 612 torch/_dynamo/convert_frame.py:844] [4/2084] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.470000 612 torch/_dynamo/convert_frame.py:844] [4/2084]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.470000 612 torch/_dynamo/convert_frame.py:844] [4/2084]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.470000 612 torch/_dynamo/convert_frame.py:844] [4/2084] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.470000 612 torch/_dynamo/convert_frame.py:844] [4/2084] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.476000 612 torch/_dynamo/convert_frame.py:844] [4/2085] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.476000 612 torch/_dynamo/convert_frame.py:844] [4/2085]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.476000 612 torch/_dynamo/convert_frame.py:844] [4/2085]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.476000 612 torch/_dynamo/convert_frame.py:844] [4/2085] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.476000 612 torch/_dynamo/convert_frame.py:844] [4/2085] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.483000 612 torch/_dynamo/convert_frame.py:844] [4/2086] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.483000 612 torch/_dynamo/convert_frame.py:844] [4/2086]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.483000 612 torch/_dynamo/convert_frame.py:844] [4/2086]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.483000 612 torch/_dynamo/convert_frame.py:844] [4/2086] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.483000 612 torch/_dynamo/convert_frame.py:844] [4/2086] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.489000 612 torch/_dynamo/convert_frame.py:844] [4/2087] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.489000 612 torch/_dynamo/convert_frame.py:844] [4/2087]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.489000 612 torch/_dynamo/convert_frame.py:844] [4/2087]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.489000 612 torch/_dynamo/convert_frame.py:844] [4/2087] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.489000 612 torch/_dynamo/convert_frame.py:844] [4/2087] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.495000 612 torch/_dynamo/convert_frame.py:844] [4/2088] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.495000 612 torch/_dynamo/convert_frame.py:844] [4/2088]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.495000 612 torch/_dynamo/convert_frame.py:844] [4/2088]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.495000 612 torch/_dynamo/convert_frame.py:844] [4/2088] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.495000 612 torch/_dynamo/convert_frame.py:844] [4/2088] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.501000 612 torch/_dynamo/convert_frame.py:844] [4/2089] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.501000 612 torch/_dynamo/convert_frame.py:844] [4/2089]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.501000 612 torch/_dynamo/convert_frame.py:844] [4/2089]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.501000 612 torch/_dynamo/convert_frame.py:844] [4/2089] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.501000 612 torch/_dynamo/convert_frame.py:844] [4/2089] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.507000 612 torch/_dynamo/convert_frame.py:844] [4/2090] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.507000 612 torch/_dynamo/convert_frame.py:844] [4/2090]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.507000 612 torch/_dynamo/convert_frame.py:844] [4/2090]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.507000 612 torch/_dynamo/convert_frame.py:844] [4/2090] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.507000 612 torch/_dynamo/convert_frame.py:844] [4/2090] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.514000 612 torch/_dynamo/convert_frame.py:844] [4/2091] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.514000 612 torch/_dynamo/convert_frame.py:844] [4/2091]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.514000 612 torch/_dynamo/convert_frame.py:844] [4/2091]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.514000 612 torch/_dynamo/convert_frame.py:844] [4/2091] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.514000 612 torch/_dynamo/convert_frame.py:844] [4/2091] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.521000 612 torch/_dynamo/convert_frame.py:844] [4/2092] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.521000 612 torch/_dynamo/convert_frame.py:844] [4/2092]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.521000 612 torch/_dynamo/convert_frame.py:844] [4/2092]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.521000 612 torch/_dynamo/convert_frame.py:844] [4/2092] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.521000 612 torch/_dynamo/convert_frame.py:844] [4/2092] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.528000 612 torch/_dynamo/convert_frame.py:844] [4/2093] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.528000 612 torch/_dynamo/convert_frame.py:844] [4/2093]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.528000 612 torch/_dynamo/convert_frame.py:844] [4/2093]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.528000 612 torch/_dynamo/convert_frame.py:844] [4/2093] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.528000 612 torch/_dynamo/convert_frame.py:844] [4/2093] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.534000 612 torch/_dynamo/convert_frame.py:844] [4/2094] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.534000 612 torch/_dynamo/convert_frame.py:844] [4/2094]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.534000 612 torch/_dynamo/convert_frame.py:844] [4/2094]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.534000 612 torch/_dynamo/convert_frame.py:844] [4/2094] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.534000 612 torch/_dynamo/convert_frame.py:844] [4/2094] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.539000 612 torch/_dynamo/convert_frame.py:844] [4/2095] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.539000 612 torch/_dynamo/convert_frame.py:844] [4/2095]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.539000 612 torch/_dynamo/convert_frame.py:844] [4/2095]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.539000 612 torch/_dynamo/convert_frame.py:844] [4/2095] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.539000 612 torch/_dynamo/convert_frame.py:844] [4/2095] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.545000 612 torch/_dynamo/convert_frame.py:844] [4/2096] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.545000 612 torch/_dynamo/convert_frame.py:844] [4/2096]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.545000 612 torch/_dynamo/convert_frame.py:844] [4/2096]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.545000 612 torch/_dynamo/convert_frame.py:844] [4/2096] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.545000 612 torch/_dynamo/convert_frame.py:844] [4/2096] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.550000 612 torch/_dynamo/convert_frame.py:844] [4/2097] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.550000 612 torch/_dynamo/convert_frame.py:844] [4/2097]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.550000 612 torch/_dynamo/convert_frame.py:844] [4/2097]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.550000 612 torch/_dynamo/convert_frame.py:844] [4/2097] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.550000 612 torch/_dynamo/convert_frame.py:844] [4/2097] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.555000 612 torch/_dynamo/convert_frame.py:844] [4/2098] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.555000 612 torch/_dynamo/convert_frame.py:844] [4/2098]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.555000 612 torch/_dynamo/convert_frame.py:844] [4/2098]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.555000 612 torch/_dynamo/convert_frame.py:844] [4/2098] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.555000 612 torch/_dynamo/convert_frame.py:844] [4/2098] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
            "W0223 05:56:17.561000 612 torch/_dynamo/convert_frame.py:844] [4/2099] torch._dynamo hit config.accumulated_cache_size_limit (256)\n",
            "W0223 05:56:17.561000 612 torch/_dynamo/convert_frame.py:844] [4/2099]    function: 'run' (/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py:605)\n",
            "W0223 05:56:17.561000 612 torch/_dynamo/convert_frame.py:844] [4/2099]    last reason: Unable to find recompilation reasons\n",
            "W0223 05:56:17.561000 612 torch/_dynamo/convert_frame.py:844] [4/2099] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
            "W0223 05:56:17.561000 612 torch/_dynamo/convert_frame.py:844] [4/2099] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096x   4096 |      7.798 |      7.342 |    1.06x\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-49366f37d0e4>:254: UserWarning: Triton kernel failed: accumulated_cache_size_limit reached. Falling back to PyTorch implementation.\n",
            "  warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "import time\n",
        "from transformers import BitsAndBytesConfig\n",
        "import warnings\n",
        "import torch._dynamo\n",
        "\n",
        "# Configure torch._dynamo to suppress errors and fall back to eager mode\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "# Utility function to check if compilation is supported\n",
        "def is_compilation_supported():\n",
        "    try:\n",
        "        @torch.compile\n",
        "        def dummy(x):\n",
        "            return x + 1\n",
        "\n",
        "        test_tensor = torch.tensor([1.0], device=\"cuda\")\n",
        "        dummy(test_tensor)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Torch compile not supported: {str(e)}. Falling back to eager mode.\")\n",
        "        return False\n",
        "\n",
        "@dataclass\n",
        "class NF4Config:\n",
        "    CLIP_MIN: int = -8\n",
        "    CLIP_MAX: int = 7\n",
        "    DTYPE_MIN: int = 0\n",
        "    DTYPE_MAX: int = 15\n",
        "\n",
        "class MemoryFormat:\n",
        "    CONTIGUOUS = \"contiguous\"\n",
        "    CHANNELS_LAST = \"channels_last\"\n",
        "\n",
        "@triton.jit\n",
        "def compute_absmax_kernel(\n",
        "    input_ptr,\n",
        "    absmax_ptr,\n",
        "    num_elements,\n",
        "    BLOCK_SIZE: tl.constexpr\n",
        "):\n",
        "    \"\"\"Compute absolute maximum values using efficient reduction.\"\"\"\n",
        "    pid = tl.program_id(0)\n",
        "    block_start = pid * BLOCK_SIZE\n",
        "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < num_elements\n",
        "\n",
        "    # Load and compute absolute values\n",
        "    x = tl.load(input_ptr + offsets, mask=mask, other=0.0)\n",
        "    x_abs = tl.abs(x)\n",
        "\n",
        "    # Perform reduction to find maximum\n",
        "    block_max = tl.max(x_abs, axis=0)\n",
        "\n",
        "    # Store result\n",
        "    tl.store(absmax_ptr + pid, block_max)\n",
        "\n",
        "@triton.jit\n",
        "def dequantize_kernel(\n",
        "    quantized_ptr,\n",
        "    absmax_ptr,\n",
        "    double_quant_scale_ptr,\n",
        "    output_ptr,\n",
        "    M, N,\n",
        "    stride_qm, stride_qn,\n",
        "    stride_om, stride_on,\n",
        "    BLOCK_M: tl.constexpr,\n",
        "    BLOCK_N: tl.constexpr,\n",
        "    MEMORY_FORMAT: tl.constexpr,\n",
        "    USE_DOUBLE_QUANT: tl.constexpr,\n",
        "):\n",
        "    \"\"\"Dequantize NF4 values with support for double quantization and different memory formats.\"\"\"\n",
        "    # Constants for NF4\n",
        "    NF4_CLIP_MIN = -8\n",
        "    NF4_CLIP_MAX = 7\n",
        "\n",
        "    # Program ID for 2D grid\n",
        "    pid_m = tl.program_id(0)\n",
        "    pid_n = tl.program_id(1)\n",
        "\n",
        "    # Calculate start indices\n",
        "    start_m = pid_m * BLOCK_M\n",
        "    start_n = pid_n * BLOCK_N\n",
        "\n",
        "    # Create ranges for the block\n",
        "    rm = start_m + tl.arange(0, BLOCK_M)\n",
        "    rn = start_n + tl.arange(0, BLOCK_N)\n",
        "\n",
        "    # Create masks for valid elements\n",
        "    mask_m = rm[:, None] < M\n",
        "    mask_n = rn[None, :] < N\n",
        "    mask = mask_m & mask_n\n",
        "\n",
        "    # Shared memory for frequently accessed scales\n",
        "    scale_cache = tl.zeros([BLOCK_M], dtype=tl.float32)\n",
        "\n",
        "    # Load quantized values based on memory format\n",
        "    if MEMORY_FORMAT == 1:  # channels_last\n",
        "        quantized = tl.load(\n",
        "            quantized_ptr + rm[:, None] * stride_qn + rn[None, :] * stride_qm,\n",
        "            mask=mask, other=0\n",
        "        )\n",
        "    else:  # contiguous\n",
        "        quantized = tl.load(\n",
        "            quantized_ptr + rm[:, None] * stride_qm + rn[None, :] * stride_qn,\n",
        "            mask=mask, other=0\n",
        "        )\n",
        "\n",
        "    # Load and cache absmax values\n",
        "    absmax = tl.load(absmax_ptr + rm, mask=rm < M, other=1.0)\n",
        "    scale_cache = absmax / NF4_CLIP_MAX\n",
        "\n",
        "    # Apply double quantization if enabled\n",
        "    if USE_DOUBLE_QUANT:\n",
        "        double_scale = tl.load(double_quant_scale_ptr + rm, mask=rm < M, other=1.0)\n",
        "        scale_cache = scale_cache * double_scale\n",
        "\n",
        "    # Dequantize\n",
        "    dequantized = (quantized - 8) * scale_cache[:, None]\n",
        "\n",
        "    # Store result\n",
        "    tl.store(\n",
        "        output_ptr + rm[:, None] * stride_om + rn[None, :] * stride_on,\n",
        "        dequantized,\n",
        "        mask=mask\n",
        "    )\n",
        "\n",
        "class BitsAndBytesNF4:\n",
        "    \"\"\"Wrapper for BitsAndBytes NF4 configuration and quantization.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        load_in_4bit: bool = True,\n",
        "        bnb_4bit_use_double_quant: bool = True,\n",
        "        bnb_4bit_quant_type: str = \"nf4\",\n",
        "        bnb_4bit_compute_dtype: torch.dtype = torch.bfloat16\n",
        "    ):\n",
        "        self.config = BitsAndBytesConfig(\n",
        "            load_in_4bit=load_in_4bit,\n",
        "            bnb_4bit_use_double_quant=bnb_4bit_use_double_quant,\n",
        "            bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "            bnb_4bit_compute_dtype=bnb_4bit_compute_dtype\n",
        "        )\n",
        "\n",
        "        # Validate configuration\n",
        "        if bnb_4bit_quant_type != \"nf4\":\n",
        "            raise ValueError(\"Only NF4 quantization is supported\")\n",
        "\n",
        "        if bnb_4bit_compute_dtype not in [torch.float16, torch.bfloat16]:\n",
        "            raise ValueError(\"Compute dtype must be float16 or bfloat16\")\n",
        "\n",
        "        self.compute_dtype = bnb_4bit_compute_dtype\n",
        "        self.use_double_quant = bnb_4bit_use_double_quant\n",
        "\n",
        "class NF4Dequantizer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        bnb_config: Optional[BitsAndBytesConfig] = None,\n",
        "        memory_format: str = MemoryFormat.CONTIGUOUS,\n",
        "        block_size: int = 1024,\n",
        "        compile_mode: str = \"reduce-overhead\"\n",
        "    ):\n",
        "        # Initialize with BitsAndBytes config if provided\n",
        "        if bnb_config is None:\n",
        "            bnb_config = BitsAndBytesNF4().config\n",
        "\n",
        "        self.use_double_quant = bnb_config.bnb_4bit_use_double_quant\n",
        "        self.compute_dtype = bnb_config.bnb_4bit_compute_dtype\n",
        "        self.memory_format = memory_format\n",
        "        self.block_size = block_size\n",
        "        self.config = NF4Config()\n",
        "\n",
        "        # Check if compilation is supported\n",
        "        self.use_compilation = is_compilation_supported()\n",
        "\n",
        "        if self.use_compilation:\n",
        "            # Compile the compute methods\n",
        "            self._compute_absmax_compiled = torch.compile(\n",
        "                self._compute_absmax_impl,\n",
        "                mode=compile_mode,\n",
        "                fullgraph=True\n",
        "            )\n",
        "            self._dequantize_compiled = torch.compile(\n",
        "                self._dequantize_impl,\n",
        "                mode=compile_mode,\n",
        "                fullgraph=True\n",
        "            )\n",
        "        else:\n",
        "            # Use non-compiled implementations\n",
        "            self._compute_absmax_compiled = self._compute_absmax_impl\n",
        "            self._dequantize_compiled = self._dequantize_impl\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _compute_absmax_impl(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Implementation of absmax computation.\"\"\"\n",
        "        try:\n",
        "            num_elements = input_tensor.numel()\n",
        "            num_blocks = (num_elements + self.block_size - 1) // self.block_size\n",
        "\n",
        "            absmax = torch.empty(num_blocks, device=input_tensor.device, dtype=self.compute_dtype)\n",
        "\n",
        "            compute_absmax_kernel[(num_blocks,)](\n",
        "                input_tensor,\n",
        "                absmax,\n",
        "                num_elements,\n",
        "                BLOCK_SIZE=self.block_size\n",
        "            )\n",
        "\n",
        "            return absmax\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
        "            return torch.max(torch.abs(input_tensor)).to(self.compute_dtype)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequantize_impl(\n",
        "        self,\n",
        "        quantized_tensor: torch.Tensor,\n",
        "        absmax_tensor: torch.Tensor,\n",
        "        double_quant_scale: Optional[torch.Tensor]\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Implementation of dequantization.\"\"\"\n",
        "        try:\n",
        "            M, N = quantized_tensor.shape\n",
        "\n",
        "            output = torch.empty(\n",
        "                (M, N),\n",
        "                device=quantized_tensor.device,\n",
        "                dtype=self.compute_dtype\n",
        "            )\n",
        "\n",
        "            BLOCK_M, BLOCK_N = 128, 128\n",
        "            grid = (triton.cdiv(M, BLOCK_M), triton.cdiv(N, BLOCK_N))\n",
        "            memory_format_int = 1 if self.memory_format == MemoryFormat.CHANNELS_LAST else 0\n",
        "\n",
        "            dequantize_kernel[grid](\n",
        "                quantized_tensor,\n",
        "                absmax_tensor,\n",
        "                double_quant_scale if double_quant_scale is not None else absmax_tensor,\n",
        "                output,\n",
        "                M, N,\n",
        "                quantized_tensor.stride(0), quantized_tensor.stride(1),\n",
        "                output.stride(0), output.stride(1),\n",
        "                BLOCK_M=BLOCK_M,\n",
        "                BLOCK_N=BLOCK_N,\n",
        "                MEMORY_FORMAT=memory_format_int,\n",
        "                USE_DOUBLE_QUANT=self.use_double_quant\n",
        "            )\n",
        "\n",
        "            return output\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Triton kernel failed: {str(e)}. Falling back to PyTorch implementation.\")\n",
        "            # PyTorch fallback implementation\n",
        "            scale = absmax_tensor[:, None] / self.config.CLIP_MAX\n",
        "            if double_quant_scale is not None and self.use_double_quant:\n",
        "                scale = scale * double_quant_scale[:, None]\n",
        "            return ((quantized_tensor - 8) * scale).to(self.compute_dtype)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def compute_absmax(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute absolute maximum values for input tensor using compiled implementation.\"\"\"\n",
        "        return self._compute_absmax_compiled(input_tensor)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def dequantize(\n",
        "        self,\n",
        "        quantized_tensor: torch.Tensor,\n",
        "        absmax_tensor: Optional[torch.Tensor] = None,\n",
        "        double_quant_scale: Optional[torch.Tensor] = None\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Dequantize NF4 tensor to fp16/bf16 using compiled implementation.\"\"\"\n",
        "        # Input validation\n",
        "        if not torch.is_tensor(quantized_tensor):\n",
        "            raise TypeError(\"quantized_tensor must be a torch.Tensor\")\n",
        "\n",
        "        if not quantized_tensor.is_cuda:\n",
        "            raise ValueError(\"quantized_tensor must be on CUDA device\")\n",
        "\n",
        "        if torch.any(quantized_tensor < self.config.DTYPE_MIN) or \\\n",
        "           torch.any(quantized_tensor > self.config.DTYPE_MAX):\n",
        "            raise ValueError(f\"Quantized values must be in range [{self.config.DTYPE_MIN}, {self.config.DTYPE_MAX}]\")\n",
        "\n",
        "        # Compute absmax if not provided\n",
        "        if absmax_tensor is None:\n",
        "            absmax_tensor = self.compute_absmax(quantized_tensor)\n",
        "\n",
        "        return self._dequantize_compiled(quantized_tensor, absmax_tensor, double_quant_scale)\n",
        "\n",
        "def benchmark_dequantizer(\n",
        "    shapes: list[Tuple[int, int]] = None,\n",
        "    num_warmup: int = 5,\n",
        "    num_runs: int = 100\n",
        "):\n",
        "    \"\"\"Benchmark the NF4Dequantizer with various matrix shapes.\"\"\"\n",
        "    if shapes is None:\n",
        "        shapes = [\n",
        "            (10, 10),      # Small square matrix\n",
        "            (1024, 32),    # Tall matrix\n",
        "            (32, 1024),    # Wide matrix\n",
        "            (1024, 1024),  # Large square matrix\n",
        "            (4096, 4096),  # Very large square matrix\n",
        "        ]\n",
        "\n",
        "    # Create BitsAndBytes config\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    # Create dequantizers with different configurations\n",
        "    print(\"\\nInitializing dequantizers...\")\n",
        "    dequantizer_compiled = NF4Dequantizer(\n",
        "        bnb_config=bnb_config,\n",
        "        compile_mode=\"reduce-overhead\"\n",
        "    )\n",
        "    dequantizer_normal = NF4Dequantizer(\n",
        "        bnb_config=bnb_config\n",
        "    )\n",
        "\n",
        "    print(\"\\nBenchmarking NF4 Dequantization with BitsAndBytes config:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Config: {bnb_config}\")\n",
        "    print(f\"Using compilation: {dequantizer_compiled.use_compilation}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Shape':>12} | {'Normal (ms)':>12} | {'Compiled (ms)':>12} | {'Speedup':>8}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for M, N in shapes:\n",
        "        try:\n",
        "            # Generate test data\n",
        "            quantized = torch.randint(0, 16, (M, N), dtype=torch.int32, device='cuda')\n",
        "            absmax = torch.rand(M, device='cuda') * 10\n",
        "            double_quant_scale = torch.rand(M, device='cuda') * 2\n",
        "\n",
        "            # Convert to appropriate dtype\n",
        "            absmax = absmax.to(bnb_config.bnb_4bit_compute_dtype)\n",
        "            double_quant_scale = double_quant_scale.to(bnb_config.bnb_4bit_compute_dtype)\n",
        "\n",
        "            # Warmup\n",
        "            for _ in range(num_warmup):\n",
        "                _ = dequantizer_normal.dequantize(quantized, absmax, double_quant_scale)\n",
        "                _ = dequantizer_compiled.dequantize(quantized, absmax, double_quant_scale)\n",
        "\n",
        "            # Benchmark normal version\n",
        "            start = torch.cuda.Event(enable_timing=True)\n",
        "            end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start.record()\n",
        "            for _ in range(num_runs):\n",
        "                _ = dequantizer_normal.dequantize(quantized, absmax, double_quant_scale)\n",
        "            end.record()\n",
        "            torch.cuda.synchronize()\n",
        "            normal_time = start.elapsed_time(end) / num_runs\n",
        "\n",
        "            # Benchmark compiled version\n",
        "            start = torch.cuda.Event(enable_timing=True)\n",
        "            end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start.record()\n",
        "            for _ in range(num_runs):\n",
        "                _ = dequantizer_compiled.dequantize(quantized, absmax, double_quant_scale)\n",
        "            end.record()\n",
        "            torch.cuda.synchronize()\n",
        "            compiled_time = start.elapsed_time(end) / num_runs\n",
        "\n",
        "            # Calculate speedup\n",
        "            speedup = normal_time / compiled_time\n",
        "\n",
        "            print(f\"{M}x{N:>7} | {normal_time:>10.3f} | {compiled_time:>10.3f} | {speedup:>7.2f}x\")\n",
        "        except Exception as e:\n",
        "            print(f\"{M}x{N:>7} | Error: {str(e)}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Running NF4 dequantization benchmarks with BitsAndBytes config...\")\n",
        "    benchmark_dequantizer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vFR0KUToZ6Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPN89+7X750Ve/V4GM4Tkkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}